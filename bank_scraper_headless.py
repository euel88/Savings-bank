# bank_scraper_headless_simplified.py
"""
ì €ì¶•ì€í–‰ ì¤‘ì•™íšŒ í†µì¼ê²½ì˜ê³µì‹œ ë°ì´í„° ìë™ ìŠ¤í¬ë˜í•‘ ë„êµ¬ (ë‹¨ìˆœí™” ë²„ì „)
ëª©ì : GitHub Actionsì—ì„œ ì•ˆì •ì  ì‹¤í–‰, Colab ì„±ê³µ êµ¬ì¡° ê¸°ë°˜
ì‘ì„±ì¼: 2025-03-31 (ìµœì¢… ìˆ˜ì •ì¼: 2025-05-28)
ê°œì„ ì‚¬í•­:
- Colab ì„±ê³µ êµ¬ì¡° ê¸°ë°˜ìœ¼ë¡œ ë‹¨ìˆœí™”
- ì•ˆì •ì„± ìš°ì„  ì„¤ê³„
- ì¹´í…Œê³ ë¦¬ë³„ ë‹¨ì¼ ì‹œíŠ¸ ìƒì„±
"""

import os
import sys
import time
import random
import json
import re
import asyncio
import concurrent.futures
import zipfile
from datetime import datetime, date, timedelta
import calendar
from io import StringIO
import argparse
import logging
from pathlib import Path
import queue
import traceback
from typing import Union, Dict, Tuple

# ì´ë©”ì¼ ì „ì†¡ ê´€ë ¨ ì„í¬íŠ¸
import smtplib
from email.mime.multipart import MIMEMultipart
from email.mime.text import MIMEText
from email.mime.base import MIMEBase
from email import encoders

# Selenium ê´€ë ¨ ì„í¬íŠ¸
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import WebDriverException, TimeoutException, NoSuchElementException, StaleElementReferenceException
from selenium.webdriver.chrome.options import Options

# ë°ì´í„° ì²˜ë¦¬ ê´€ë ¨ ì„í¬íŠ¸
from bs4 import BeautifulSoup
import pandas as pd
from tqdm import tqdm
import warnings
warnings.filterwarnings("ignore")

# --- ë¡œê¹… ì„¤ì • ---
def setup_logging(log_file_path, log_level="INFO"):
    for handler in logging.root.handlers[:]: logging.root.removeHandler(handler)
    logging.basicConfig(
        level=getattr(logging, log_level.upper(), logging.INFO),
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S',
        handlers=[logging.StreamHandler(sys.stdout), logging.FileHandler(log_file_path, encoding='utf-8')]
    )
    logging.getLogger('selenium.webdriver.remote.remote_connection').setLevel(logging.WARNING)
    logging.getLogger('urllib3.connectionpool').setLevel(logging.WARNING)
    return logging.getLogger(__name__)

logger = None

# --- ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ---
def normalize_datestr_for_comparison(datestr: str) -> Union[str, None]:
    if not datestr or datestr in ["ë‚ ì§œ ì •ë³´ ì—†ìŒ", "ë‚ ì§œ ì¶”ì¶œ ì‹¤íŒ¨"]: return None 
    match = re.search(r'(\d{4})ë…„\s*(\d{1,2})ì›”ë§', datestr)
    if match: return f"{int(match.group(1))}ë…„{int(match.group(2))}ì›”ë§"
    if logger: logger.warning(f"ë‚ ì§œ ë¬¸ìì—´ ì •ê·œí™” ì‹¤íŒ¨(íŒ¨í„´ ë¶ˆì¼ì¹˜): '{datestr}'")
    return "ì•Œ ìˆ˜ ì—†ëŠ” í˜•ì‹"

def get_quarter_string_from_period(period_str: str) -> str:
    if not period_str or not isinstance(period_str, str): return "ë¶„ê¸°ì •ë³´ ë¶ˆëª…í™•"
    match = re.search(r'(\d{4})ë…„(\d{1,2})ì›”ë§', period_str)
    if match:
        year, month = match.group(1), int(match.group(2))
        q_map = {3: "1ë¶„ê¸°", 6: "2ë¶„ê¸°", 9: "3ë¶„ê¸°", 12: "4ë¶„ê¸°"}
        return f"{year}ë…„ {q_map.get(month, f'{month}ì›”')}"
    return period_str

# --- ë‚ ì§œ ê²€ì¦ í´ë˜ìŠ¤ ---
class DateVerifier:
    def get_last_weekday(self, year: int, month: int) -> date:
        _, last_day_num = calendar.monthrange(year, month)
        d = date(year, month, last_day_num)
        while d.weekday() >= 5: d -= timedelta(days=1)
        return d
    
    def get_relevant_disclosure_periods(self, current_processing_date: date) -> Dict[str, str]:
        year = current_processing_date.year
        lw_may_curr = self.get_last_weekday(year, 5)
        lw_aug_curr = self.get_last_weekday(year, 8)
        lw_nov_curr = self.get_last_weekday(year, 11)
        res = {"latest_due_period": "ê²°ì • ë¶ˆê°€", "latest_due_reason": "", "next_imminent_period": "ê²°ì • ë¶ˆê°€", "next_imminent_reason": ""}
        base_reason = f"í˜„ì¬ ì²˜ë¦¬ì¼ì {current_processing_date} ê¸°ì¤€"
        if current_processing_date >= lw_nov_curr:
            res["latest_due_period"] = f"{year}ë…„9ì›”ë§"
            res["latest_due_reason"] = f"{base_reason}: {year}ë…„ 11ì›” ë§ˆì§€ë§‰ í‰ì¼({lw_nov_curr}) ì´í›„ì´ë¯€ë¡œ {res['latest_due_period']} ë°ì´í„°ê°€ ê³µì‹ì ìœ¼ë¡œ ìµœì‹ ì´ì–´ì•¼ í•¨."
        elif current_processing_date >= lw_aug_curr:
            res["latest_due_period"] = f"{year}ë…„6ì›”ë§"
            res["latest_due_reason"] = f"{base_reason}: {year}ë…„ 8ì›” ë§ˆì§€ë§‰ í‰ì¼({lw_aug_curr}) ì´í›„ì´ë¯€ë¡œ {res['latest_due_period']} ë°ì´í„°ê°€ ê³µì‹ì ìœ¼ë¡œ ìµœì‹ ì´ì–´ì•¼ í•¨."
        elif current_processing_date >= lw_may_curr:
            res["latest_due_period"] = f"{year}ë…„3ì›”ë§"
            res["latest_due_reason"] = f"{base_reason}: {year}ë…„ 5ì›” ë§ˆì§€ë§‰ í‰ì¼({lw_may_curr}) ì´í›„ì´ë¯€ë¡œ {res['latest_due_period']} ë°ì´í„°ê°€ ê³µì‹ì ìœ¼ë¡œ ìµœì‹ ì´ì–´ì•¼ í•¨."
        else:
            res["latest_due_period"] = f"{year-1}ë…„9ì›”ë§"
            res["latest_due_reason"] = f"{base_reason}: {year}ë…„ 5ì›” ë§ˆì§€ë§‰ í‰ì¼({lw_may_curr}) ì´ì „ì´ë¯€ë¡œ ì „ë…„ë„ ê¸°ì¤€ ì ìš©, {res['latest_due_period']} ë°ì´í„°ê°€ ê³µì‹ì ìœ¼ë¡œ ìµœì‹ ì´ì–´ì•¼ í•¨."
        if current_processing_date <= lw_may_curr:
            res["next_imminent_period"] = f"{year}ë…„3ì›”ë§"
            res["next_imminent_reason"] = f"{base_reason}: {year}ë…„ 5ì›” ë§ˆì§€ë§‰ í‰ì¼({lw_may_curr})ê¹Œì§€ {res['next_imminent_period']} ìë£Œ ì—…ë¡œë“œ ê¸°ê°„/ì„ë°•."
        elif current_processing_date <= lw_aug_curr:
            res["next_imminent_period"] = f"{year}ë…„6ì›”ë§"
            res["next_imminent_reason"] = f"{base_reason}: {year}ë…„ 8ì›” ë§ˆì§€ë§‰ í‰ì¼({lw_aug_curr})ê¹Œì§€ {res['next_imminent_period']} ìë£Œ ì—…ë¡œë“œ ê¸°ê°„/ì„ë°•."
        elif current_processing_date <= lw_nov_curr:
            res["next_imminent_period"] = f"{year}ë…„9ì›”ë§"
            res["next_imminent_reason"] = f"{base_reason}: {year}ë…„ 11ì›” ë§ˆì§€ë§‰ í‰ì¼({lw_nov_curr})ê¹Œì§€ {res['next_imminent_period']} ìë£Œ ì—…ë¡œë“œ ê¸°ê°„/ì„ë°•."
        else: 
            res["next_imminent_period"] = f"{year+1}ë…„3ì›”ë§"
            res["next_imminent_reason"] = f"{base_reason}: {year}ë…„ 11ì›” ë§ˆì§€ë§‰ í‰ì¼({lw_nov_curr}) ì´í›„ì´ë¯€ë¡œ, ë‹¤ìŒ ëŒ€ìƒì€ {res['next_imminent_period']} (ì—…ë¡œë“œ: {year+1}ë…„ 5ì›” ë§ˆì§€ë§‰ í‰ì¼)."
        return res

# --- ì´ë©”ì¼ ì „ì†¡ í´ë˜ìŠ¤ ---
class EmailSender:
    def __init__(self):
        self.smtp_server = "smtp.gmail.com"; self.smtp_port = 587
        self.sender_email = os.getenv('GMAIL_ADDRESS'); self.sender_password = os.getenv('GMAIL_APP_PASSWORD')
        self.recipient_emails = [e.strip() for e in os.getenv('RECIPIENT_EMAILS', '').split(',') if e.strip()]
        self.enabled = bool(self.sender_email and self.sender_password and self.recipient_emails)
        log_msg = "ì´ë©”ì¼ ì„¤ì • ìœ íš¨X. ì „ì†¡X." if not self.enabled else f"ì´ë©”ì¼ ì„¤ì •OK. ìˆ˜ì‹ ì: {self.recipient_emails}"
        if logger: (logger.warning if not self.enabled else logger.info)(log_msg)
    
    def send_email_with_attachment(self, subject, body, attachment_path=None):
        if not self.enabled:
            if logger: logger.info("ì´ë©”ì¼ ì „ì†¡ ë¹„í™œì„±í™”ë¨."); return False
        try:
            msg = MIMEMultipart(); msg['From'] = self.sender_email; msg['To'] = ', '.join(self.recipient_emails); msg['Subject'] = subject
            msg.attach(MIMEText(body, 'html', 'utf-8'))
            if attachment_path and Path(attachment_path).exists():
                p_attach = Path(attachment_path)
                if p_attach.suffix.lower() == '.zip': part = MIMEBase('application', 'zip')
                elif p_attach.suffix.lower() == '.xlsx': part = MIMEBase('application', 'vnd.openxmlformats-officedocument.spreadsheetml.sheet')
                else: part = MIMEBase('application', 'octet-stream')
                with open(p_attach, 'rb') as af: part.set_payload(af.read())
                encoders.encode_base64(part)
                base_filename = p_attach.name
                try: part.add_header('Content-Disposition', 'attachment', filename=encoders.encode_rfc2231(base_filename))
                except: part.add_header('Content-Disposition', f'attachment; filename="{base_filename}"')
                msg.attach(part)
                if logger: logger.info(f"ì²¨ë¶€íŒŒì¼ ì¶”ê°€: {p_attach.name} (Type: {part.get_content_type()})")
            with smtplib.SMTP(self.smtp_server, self.smtp_port) as server:
                server.ehlo(); server.starttls(); server.ehlo()
                server.login(self.sender_email, self.sender_password); server.send_message(msg)
            if logger: logger.info(f"ì´ë©”ì¼ ì „ì†¡ ì„±ê³µ: {self.recipient_emails}"); return True
        except Exception as e:
            if logger: logger.error(f"ì´ë©”ì¼ ì „ì†¡ ì‹¤íŒ¨: {e}", exc_info=True); return False
        return False

# --- ì„¤ì • í´ë˜ìŠ¤ ---
class Config:
    def __init__(self):
        self.VERSION = "2.12.0-simplified" 
        self.BASE_URL = "https://www.fsb.or.kr/busmagequar_0100.act"
        self.MAX_RETRIES = int(os.getenv('MAX_RETRIES', '2')) 
        # Colab ìˆ˜ì¤€ì˜ ì„±ëŠ¥ ì„¤ì •
        self.PAGE_LOAD_TIMEOUT = int(os.getenv('PAGE_LOAD_TIMEOUT', '8'))
        self.WAIT_TIMEOUT = int(os.getenv('WAIT_TIMEOUT', '4'))
        self.MAX_WORKERS = int(os.getenv('MAX_WORKERS', '5'))

        self.today = datetime.now().strftime("%Y%m%d")
        self.output_dir_base = Path(os.getenv('OUTPUT_DIR', "./output"))
        self.output_dir = self.output_dir_base / f"ì €ì¶•ì€í–‰_ë°ì´í„°_{self.today}"
        self.output_dir.mkdir(parents=True, exist_ok=True)

        self.progress_file = self.output_dir / 'progress.json'
        self.log_file_path = self.output_dir / f'scraping_log_{self.today}.log'

        global logger
        if logger is None: 
            logger = setup_logging(self.log_file_path, os.getenv('LOG_LEVEL', 'INFO'))
        
        try: self.processing_date_kst = datetime.now().date() 
        except Exception as e: logger.error(f"KST ë‚ ì§œ ì–»ê¸° ì‹¤íŒ¨: {e}. UTCë¡œ ëŒ€ì²´."); self.processing_date_kst = datetime.utcnow().date()

        self.date_verifier = DateVerifier()
        self.date_expectations = self.date_verifier.get_relevant_disclosure_periods(self.processing_date_kst)
        self.latest_due_period = self.date_expectations["latest_due_period"]
        self.next_imminent_period = self.date_expectations["next_imminent_period"]

        self.BANKS = [
            "ë‹¤ì˜¬", "ëŒ€ì‹ ", "ë”ì¼€ì´", "ë¯¼êµ­", "ë°”ë¡œ", "ìŠ¤ì¹´ì´", "ì‹ í•œ", "ì• íì˜¨", "ì˜ˆê°€ëŒ", "ì›°ì»´", "ìœ ì•ˆíƒ€", "ì¡°ì€", "í‚¤ì›€YES", "í‘¸ë¥¸", "í•˜ë‚˜", "DB", "HB", "JT", "ì¹œì• ", "KB", "NH", "OK", "OSB", "SBI", "ê¸ˆí™”", "ë‚¨ì–‘", "ëª¨ì•„", "ë¶€ë¦¼", "ì‚¼ì •", "ìƒìƒì¸", "ì„¸ëŒ", "ì•ˆêµ­", "ì•ˆì–‘", "ì˜ì§„", "ìœµì°½", "ì¸ì„±", "ì¸ì²œ", "í‚¤ì›€", "í˜í¼", "í‰íƒ", "í•œêµ­íˆ¬ì", "í•œí™”", "ê³ ë ¤", "êµ­ì œ", "ë™ì›ì œì¼", "ì†”ë¸Œë ˆì¸", "ì—ìŠ¤ì•¤í‹°", "ìš°ë¦¬", "ì¡°í¥", "ì§„ì£¼", "í¥êµ­", "BNK", "DH", "IBK", "ëŒ€ë°±", "ëŒ€ì•„", "ëŒ€ì›", "ë“œë¦¼", "ë¼ì˜¨", "ë¨¸ìŠ¤íŠ¸ì‚¼ì¼", "ì— ì—ìŠ¤", "ì˜¤ì„±", "ìœ ë‹ˆì˜¨", "ì°¸", "CK", "ëŒ€í•œ", "ë”ë¸”", "ë™ì–‘", "ì‚¼í˜¸", "ì„¼íŠ¸ëŸ´", "ìŠ¤ë§ˆíŠ¸", "ìŠ¤íƒ€", "ëŒ€ëª…", "ìƒìƒì¸í”ŒëŸ¬ìŠ¤", "ì•„ì‚°", "ì˜¤íˆ¬", "ìš°ë¦¬ê¸ˆìœµ", "ì²­ì£¼", "í•œì„±"
        ]
        self.CATEGORIES = ["ì˜ì—…ê°œí™©", "ì¬ë¬´í˜„í™©", "ì†ìµí˜„í™©", "ê¸°íƒ€"]
        
        logger.info(f"--- ì„¤ì • ì´ˆê¸°í™” (v{self.VERSION}) ---")
        logger.info(f"ì²˜ë¦¬ì¼ì(KST ê°€ì •): {self.processing_date_kst}")
        logger.info(f"ì˜ˆìƒ (ê¸°í•œ ì§€ë‚œ) ìµœì‹  ê³µì‹œì¼: '{self.latest_due_period}' (ê·¼ê±°: {self.date_expectations['latest_due_reason']})")
        logger.info(f"ì˜ˆìƒ (ë‹¤ìŒ/í˜„ì¬) ê³µì‹œì¼: '{self.next_imminent_period}' (ê·¼ê±°: {self.date_expectations['next_imminent_reason']})")

# --- DriverManager ---
class DriverManager:
    def __init__(self, config):
        self.config = config; self.driver_pool = queue.Queue(maxsize=self.config.MAX_WORKERS); self._initialize_pool()
    
    def _create_new_driver(self):
        logger.debug("ìƒˆ WebDriver ìƒì„±..."); options = Options()
        options.add_argument('--headless'); options.add_argument('--no-sandbox'); options.add_argument('--disable-dev-shm-usage')
        options.add_argument('--disable-gpu'); options.add_argument('--window-size=1920,1080')
        options.add_argument('user-agent=Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
        options.add_argument('--disable-extensions'); options.add_argument('--disable-browser-side-navigation')
        options.add_argument('--disable-infobars'); options.add_argument('--disable-notifications')
        options.add_argument('--disable-popup-blocking'); options.add_argument('--blink-settings=imagesEnabled=false')
        options.add_experimental_option('excludeSwitches', ['enable-logging', 'enable-automation']); options.add_experimental_option('useAutomationExtension', False)
        try:
            driver = webdriver.Chrome(options=options); driver.set_page_load_timeout(self.config.PAGE_LOAD_TIMEOUT)
            logger.debug("ìƒˆ WebDriver ìƒì„± ì™„ë£Œ."); return driver
        except WebDriverException as e:
            logger.error(f"WebDriver ìƒì„± ì‹¤íŒ¨: {e}", exc_info=True)
            if any(s in str(e).lower() for s in ["executable needs to be in path", "unable to find driver", "cannot find chrome binary"]):
                logger.error(f"WebDriverException: ChromeDriver/Chrome ê²½ë¡œ ë¬¸ì œ ì¶”ì •. PATH: {os.getenv('PATH')}")
            raise
        except Exception as e: logger.error(f"WebDriver ìƒì„± ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}", exc_info=True); raise
    
    def _initialize_pool(self):
        logger.info(f"ë“œë¼ì´ë²„ í’€ ì´ˆê¸°í™” ì‹œì‘ (ìµœëŒ€ {self.config.MAX_WORKERS}ê°œ)...")
        for i in range(self.config.MAX_WORKERS):
            try: self.driver_pool.put_nowait(self._create_new_driver())
            except queue.Full: logger.warning(f"ë“œë¼ì´ë²„ {i+1} ì¶”ê°€ ì¤‘ í’€ ê½‰ ì°¸."); break 
            except Exception as e: logger.error(f"ì´ˆê¸° ë“œë¼ì´ë²„ {i+1} ìƒì„± ì‹¤íŒ¨ ({type(e).__name__}).")
        logger.info(f"ë“œë¼ì´ë²„ í’€ ì´ˆê¸°í™” ì™„ë£Œ. ì‚¬ìš© ê°€ëŠ¥: {self.driver_pool.qsize()}ê°œ.")
    
    def get_driver(self):
        try: return self.driver_pool.get(block=True, timeout=30)
        except queue.Empty: raise TimeoutError(f"30ì´ˆ ëŒ€ê¸° í›„ì—ë„ í’€ì—ì„œ ë“œë¼ì´ë²„ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í•¨ (MAX_WORKERS: {self.config.MAX_WORKERS}).")
    
    def return_driver(self, driver): 
        if not driver: return
        returned = False
        try:
            _ = driver.title 
            if self.driver_pool.qsize() < self.config.MAX_WORKERS: self.driver_pool.put_nowait(driver); returned = True
            else: logger.warning(f"í’€({self.driver_pool.qsize()}) ê½‰ ì°¸, ë°˜í™˜ ë“œë¼ì´ë²„ ì¢…ë£Œ."); driver.quit()
        except queue.Full: logger.warning(f"ë°˜ë‚© ì‹œ í’€ ê½‰ ì°¸. ë“œë¼ì´ë²„ ì¢…ë£Œ."); driver.quit()
        except Exception as e:
            logger.warning(f"ì†ìƒëœ ë“œë¼ì´ë²„ ë°˜í™˜ ì‹œë„ ({type(e).__name__}). ë“œë¼ì´ë²„ ì¢…ë£Œ.")
            try: driver.quit()
            except: pass 
            if not returned: self._add_new_driver_to_pool_if_needed()
    
    def _add_new_driver_to_pool_if_needed(self): 
        if self.driver_pool.qsize() < self.config.MAX_WORKERS:
            try: logger.info("ì†ìƒ ë“œë¼ì´ë²„ ëŒ€ì²´ìš© ìƒˆ ë“œë¼ì´ë²„ ìƒì„±..."); self.driver_pool.put_nowait(self._create_new_driver())
            except Exception as e: logger.error(f"ëŒ€ì²´ ë“œë¼ì´ë²„ ìƒì„±/ì¶”ê°€ ì‹¤íŒ¨: {e}", exc_info=True)
    
    def quit_all(self): 
        logger.info("ëª¨ë“  ë“œë¼ì´ë²„ ì¢…ë£Œ ì‹œì‘..."); drained = 0
        while not self.driver_pool.empty():
            try: driver = self.driver_pool.get_nowait(); driver.quit(); drained += 1
            except: break 
        logger.info(f"ì´ {drained}ê°œ ë“œë¼ì´ë²„ ì¢…ë£Œ ì‹œë„ ì™„ë£Œ.")

class ProgressManager:
    def __init__(self, config):
        self.config=config; self.progress_file_path=config.progress_file; self.progress=self._load()
    
    def _load(self):
        default = {'banks': {}, 'stats': {'last_run':None,'success_count':0,'failure_count':0}}
        if self.progress_file_path.exists():
            try:
                with open(self.progress_file_path,'r',encoding='utf-8') as f:
                    loaded=json.load(f)
                    if 'banks' not in loaded: loaded['banks']={}
                    if 'stats' not in loaded: loaded['stats']=default['stats']
                    return loaded
            except Exception as e: logger.warning(f"ì§„í–‰ íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜({self.progress_file_path}): {e}. ìƒˆë¡œ ì‹œì‘.")
        return default
    
    def save(self):
        self.progress['stats']['last_run']=datetime.now().isoformat(); s,f=0,0
        for info in self.progress.get('banks',{}).values():
            if info.get('status')=='completed': s+=1
            elif info.get('status')=='failed': f+=1
        self.progress['stats']['success_count']=s; self.progress['stats']['failure_count']=f
        try:
            with open(self.progress_file_path,'w',encoding='utf-8') as fo: json.dump(self.progress,fo,ensure_ascii=False,indent=2)
        except Exception as e: logger.error(f"ì§„í–‰ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}",exc_info=True)
    
    def mark_completed(self,bank_name,date_info):
        self.progress.setdefault('banks',{})[bank_name]={'status':'completed','date_info':date_info}; self.save()
    
    def mark_failed(self,bank_name):
        data=self.progress.setdefault('banks',{}).get(bank_name,{}); data['status']='failed'
        self.progress['banks'][bank_name]=data; self.save()
    
    def get_pending_banks(self):
        processed=self.progress.get('banks',{}); pending=[b for b in self.config.BANKS if b not in processed or processed[b].get('status')!='completed']
        logger.info(f"ë³´ë¥˜ ì€í–‰(ì¬ì‹œë„ í¬í•¨ ê°€ëŠ¥): {len(pending)}ê°œ"); return pending
    
    def get_bank_data(self,bank_name): return self.progress.get('banks',{}).get(bank_name)

# --- Colab ê¸°ë°˜ ìŠ¤í¬ë˜í•‘ í•¨ìˆ˜ë“¤ ---
def extract_date_information(driver):
    """ê°•í™”ëœ ë‚ ì§œ ì •ë³´ ì¶”ì¶œ ë° ê²€ì¦"""
    try:
        # 1ì°¨ ì¶”ì¶œ ì‹œë„
        js_script = """
        var allMatches = [];
        var datePattern = /(\d{4})ë…„\s*(\d{1,2})ì›”ë§/g;
        var bodyText = document.body.innerText || "";
        var match;
        datePattern.lastIndex = 0;
        
        // ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ ëª¨ë“  ë‚ ì§œ íŒ¨í„´ ì¶”ì¶œ
        while ((match = datePattern.exec(bodyText)) !== null) {
            allMatches.push({
                fullText: match[0],
                year: parseInt(match[1]),
                month: parseInt(match[2])
            });
        }
        
        // ìš°ì„ ìˆœìœ„ê°€ ë†’ì€ íƒœê·¸ì—ì„œ ë‚ ì§œ ê²€ìƒ‰
        var prioritySelectors = [
            'h1', 'h2', 'h3', 'caption', 'th[colspan]', 
            '.title', '.date', '#publishDate', '.disclosure-date'
        ];
        
        for (var i = 0; i < prioritySelectors.length; i++) {
            var elements;
            try { elements = document.querySelectorAll(prioritySelectors[i]); }
            catch(e) { continue; }
            
            for (var j = 0; j < elements.length; j++) {
                var elText = elements[j].innerText || "";
                if (elText.length > 500) elText = elText.substring(0, 500);
                datePattern.lastIndex = 0;
                
                while ((match = datePattern.exec(elText)) !== null) {
                    var year = parseInt(match[1]);
                    var month = parseInt(match[2]);
                    
                    // ì¤‘ë³µ ì œê±°
                    if (!allMatches.some(m => m.year === year && m.month === month)) {
                        allMatches.push({
                            fullText: match[0],
                            year: year,
                            month: month,
                            priority: true  // ìš°ì„ ìˆœìœ„ íƒœê·¸ì—ì„œ ì¶”ì¶œë¨
                        });
                    }
                }
            }
        }
        
        return allMatches;
        """
        
        date_matches = driver.execute_script(js_script)
        
        if not date_matches:
            return "ë‚ ì§œ ì •ë³´ ì—†ìŒ"
        
        # ë‚ ì§œ ê²€ì¦ ë° í•„í„°ë§
        current_year = datetime.now().year
        valid_dates = []
        
        for match in date_matches:
            year = match.get('year', 0)
            month = match.get('month', 0)
            
            # í•©ë¦¬ì ì¸ ë‚ ì§œ ë²”ìœ„ ê²€ì¦ (í˜„ì¬ë…„ë„ ê¸°ì¤€ -3ë…„ ~ +1ë…„, ë¶„ê¸°ë§ ì›” ìš°ì„ )
            if (current_year - 3) <= year <= (current_year + 1) and 1 <= month <= 12:
                # ë¶„ê¸°ë§ ì›”(3, 6, 9, 12) ìš°ì„ ìˆœìœ„ ë¶€ì—¬
                priority_score = 0
                if month in [3, 6, 9, 12]:
                    priority_score += 10
                if match.get('priority'):  # ìš°ì„ ìˆœìœ„ íƒœê·¸ì—ì„œ ì¶”ì¶œ
                    priority_score += 5
                if year >= current_year - 1:  # ìµœê·¼ ë°ì´í„° ìš°ì„ 
                    priority_score += year - (current_year - 2)
                
                valid_dates.append({
                    'text': match['fullText'],
                    'year': year,
                    'month': month,
                    'score': priority_score
                })
        
        if valid_dates:
            # ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ê°€ì¥ ì ì ˆí•œ ë‚ ì§œ ì„ íƒ
            valid_dates.sort(key=lambda x: x['score'], reverse=True)
            best_date = valid_dates[0]['text'].replace(' ', '')
            
            logger.debug(f"ë‚ ì§œ ì¶”ì¶œ ì„±ê³µ: {best_date} (ê²€ì¦ëœ {len(valid_dates)}ê°œ ì¤‘ ì„ íƒ)")
            return best_date
        
        # ê²€ì¦ ì‹¤íŒ¨ ì‹œ ê²½ê³  ë° ê¸°ë³¸ê°’ ë°˜í™˜
        logger.warning(f"ë‚ ì§œ ê²€ì¦ ì‹¤íŒ¨. ì¶”ì¶œëœ ëª¨ë“  ë‚ ì§œê°€ ìœ íš¨í•˜ì§€ ì•ŠìŒ: {[m.get('fullText', '') for m in date_matches[:3]]}")
        return "ë‚ ì§œ ê²€ì¦ ì‹¤íŒ¨"

    except Exception as e:
        logger.error(f"ë‚ ì§œ ì •ë³´ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
        return "ë‚ ì§œ ì¶”ì¶œ ì‹¤íŒ¨"

def select_bank(driver, bank_name, config):
    """ê°œì„ ëœ ì€í–‰ ì„ íƒ ë¡œì§ - ì •í™•í•œ ë§¤ì¹­"""
    try:
        driver.get(config.BASE_URL)
        WebDriverWait(driver, config.PAGE_LOAD_TIMEOUT).until(lambda d: d.execute_script('return document.readyState') == 'complete')
        time.sleep(random.uniform(0.5, 1))

        # ì •í™•í•œ ì€í–‰ëª… ë§¤ì¹­ì„ ìœ„í•œ JavaScript ë¡œì§
        js_script = f"""
        function selectExactBank(targetBankName) {{
            // 1ë‹¨ê³„: ì •í™•í•œ í…ìŠ¤íŠ¸ ë§¤ì¹­ ìš°ì„  ì‹œë„
            var allElements = document.querySelectorAll('a, td');
            var exactMatches = [];
            var partialMatches = [];
            
            for (var i = 0; i < allElements.length; i++) {{
                var element = allElements[i];
                var text = element.textContent.trim();
                
                if (text === targetBankName) {{
                    exactMatches.push(element);
                }} else if (text.includes(targetBankName)) {{
                    partialMatches.push({{
                        element: element,
                        text: text,
                        score: text.length - targetBankName.length  // ì§§ì„ìˆ˜ë¡ ë” ì •í™•í•œ ë§¤ì¹˜
                    }});
                }}
            }}
            
            // ì •í™•í•œ ë§¤ì¹˜ ìš°ì„  ì²˜ë¦¬
            if (exactMatches.length > 0) {{
                var target = exactMatches[0];
                target.scrollIntoView({{block: 'center'}});
                
                // td ë‚´ë¶€ì˜ ë§í¬ í™•ì¸
                if (target.tagName === 'TD') {{
                    var links = target.getElementsByTagName('a');
                    if (links.length > 0) {{
                        links[0].click();
                        return "exact_match_with_link";
                    }}
                }}
                
                target.click();
                return "exact_match";
            }}
            
            // ë¶€ë¶„ ë§¤ì¹˜ ì²˜ë¦¬ (ê°€ì¥ ì§§ì€ í…ìŠ¤íŠ¸ ìš°ì„ )
            if (partialMatches.length > 0) {{
                partialMatches.sort(function(a, b) {{ return a.score - b.score; }});
                
                // íƒ€ê²Ÿ ì€í–‰ëª…ì´ í¬í•¨ë˜ì–´ ìˆì§€ë§Œ ë„ˆë¬´ ê¸¸ì§€ ì•Šì€ ê²½ìš°ë§Œ ì„ íƒ
                for (var j = 0; j < partialMatches.length; j++) {{
                    var match = partialMatches[j];
                    
                    // ê¸¸ì´ ì°¨ì´ê°€ 5ê¸€ì ì´í•˜ì¸ ê²½ìš°ë§Œ í—ˆìš© (ì˜ˆ: "JT" vs "JTì¹œì• " êµ¬ë¶„)
                    if (match.score <= 5) {{
                        var target = match.element;
                        target.scrollIntoView({{block: 'center'}});
                        
                        if (target.tagName === 'TD') {{
                            var links = target.getElementsByTagName('a');
                            if (links.length > 0) {{
                                links[0].click();
                                return "partial_match_with_link: " + match.text;
                            }}
                        }}
                        
                        target.click();
                        return "partial_match: " + match.text;
                    }}
                }}
            }}
            
            return false;
        }}
        
        return selectExactBank('{bank_name}');
        """
        
        result = driver.execute_script(js_script)
        if result:
            logger.debug(f"{bank_name} ì€í–‰ ì„ íƒ: {result}")
            time.sleep(random.uniform(0.5, 1))
            return True

        logger.warning(f"{bank_name} ì€í–‰ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return False

    except Exception as e:
        logger.error(f"{bank_name} ì€í–‰ ì„ íƒ ì‹¤íŒ¨: {str(e)}")
        return False

def select_category(driver, category, config):
    """ì¹´í…Œê³ ë¦¬ ì„ íƒ (Colab ê¸°ë°˜ ë‹¨ìˆœí™”)"""
    try:
        time.sleep(random.uniform(0.1, 0.3))

        # JavaScriptë¡œ ì¹´í…Œê³ ë¦¬ íƒ­ í´ë¦­
        script = f"""
        var allElements = document.querySelectorAll('a, button, span, li, div');
        for (var k = 0; k < allElements.length; k++) {{
            if (allElements[k].innerText.trim() === '{category}') {{
                allElements[k].scrollIntoView({{block: 'center'}});
                allElements[k].click();
                return "exact_match";
            }}
        }}

        for (var j = 0; j < allElements.length; j++) {{
            if (allElements[j].innerText.includes('{category}')) {{
                allElements[j].scrollIntoView({{block: 'center'}});
                allElements[j].click();
                return "contains_match";
            }}
        }}
        return false;
        """

        result = driver.execute_script(script)
        if result:
            logger.debug(f"{category} íƒ­: {result} ì„±ê³µ")
            time.sleep(random.uniform(0.5, 1))
            return True

        logger.debug(f"{category} íƒ­ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return False

    except Exception as e:
        logger.debug(f"{category} íƒ­ í´ë¦­ ì‹¤íŒ¨: {str(e)}")
        return False

def extract_tables_from_page(driver, config):
    """í…Œì´ë¸” ì¶”ì¶œ (Colab ê¸°ë°˜)"""
    try:
        WebDriverWait(driver, config.PAGE_LOAD_TIMEOUT).until(lambda d: d.execute_script('return document.readyState') == 'complete')
        time.sleep(random.uniform(0.5, 1))

        try:
            html_source = driver.page_source
            dfs = pd.read_html(StringIO(html_source))

            if dfs:
                valid_dfs = []
                seen_shapes = set()

                for df in dfs:
                    if not df.empty and df.shape[0] > 0 and df.shape[1] > 0:
                        # MultiIndex ì»¬ëŸ¼ ì²˜ë¦¬
                        if isinstance(df.columns, pd.MultiIndex):
                            new_cols = []
                            for col in df.columns:
                                if isinstance(col, tuple):
                                    clean_col = [str(c).strip() for c in col if str(c).strip() and str(c).lower() != 'nan']
                                    new_cols.append('_'.join(clean_col) if clean_col else f"Column_{len(new_cols)+1}")
                                else:
                                    new_cols.append(str(col))
                            df.columns = new_cols

                        # ì¤‘ë³µ í…Œì´ë¸” ì œê±°
                        try:
                            shape_hash = f"{df.shape}"
                            headers_hash = f"{list(df.columns)}"
                            data_hash = ""
                            if len(df) > 0:
                                data_hash = f"{list(df.iloc[0].astype(str))}"

                            table_hash = f"{shape_hash}_{headers_hash}_{data_hash}"

                            if table_hash not in seen_shapes:
                                valid_dfs.append(df)
                                seen_shapes.add(table_hash)
                        except:
                            valid_dfs.append(df)

                return valid_dfs
        except Exception as e:
            logger.debug(f"pandas í…Œì´ë¸” ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")

        return []

    except Exception as e:
        logger.debug(f"í…Œì´ë¸” ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")
        return []

# --- ìŠ¤í¬ë˜í¼ í´ë˜ìŠ¤ (ë‹¨ìˆœí™”) ---
class BankScraper:
    def __init__(self, config, driver_manager, progress_manager):
        self.config = config; self.driver_manager = driver_manager; self.progress_manager = progress_manager
        self.email_sender = EmailSender()

    def classify_table_by_content(self, table_df):
        """í…Œì´ë¸” ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ì¹´í…Œê³ ë¦¬ ê²°ì •"""
        try:
            if table_df is None or table_df.empty:
                return "ê¸°íƒ€"
            
            # í…Œì´ë¸” í…ìŠ¤íŠ¸ ë‚´ìš© ì¶”ì¶œ
            table_text = ""
            
            # ì»¬ëŸ¼ëª…ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            try:
                if hasattr(table_df, 'columns'):
                    col_text = " ".join(str(col).lower() for col in table_df.columns if col is not None)
                    table_text += col_text + " "
            except:
                pass
            
            # ë°ì´í„° ë‚´ìš©ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ìƒìœ„ 3í–‰ë§Œ)
            try:
                max_rows = min(3, len(table_df))
                for i in range(max_rows):
                    for val in table_df.iloc[i].values:
                        try:
                            if pd.notna(val) and val is not None:
                                table_text += str(val).lower() + " "
                        except:
                            continue
            except:
                pass
            
            if not table_text.strip():
                return "ê¸°íƒ€"
            
            # ì¹´í…Œê³ ë¦¬ë³„ í‚¤ì›Œë“œ ì •ì˜
            category_keywords = {
                "ì˜ì—…ê°œí™©": ["ì˜ì—…ì ", "ì§ì›", "ì í¬", "ì§€ì ", "ì„ì§ì›", "ì¡°ì§", "ë³¸ì ", "ì í¬ìˆ˜", "ì§ì›ìˆ˜", "ì„ì›", "ì˜ì—…ë§", "ì§€ì—­ë³¸ë¶€", "ì˜ì—…ì†Œ"],
                "ì¬ë¬´í˜„í™©": ["ìì‚°", "ë¶€ì±„", "ìë³¸", "ì´ìì‚°", "ì´ë¶€ì±„", "ìê¸°ìë³¸", "ëŒ€ì°¨ëŒ€ì¡°í‘œ", "ì¬ë¬´ìƒíƒœí‘œ", "í˜„ê¸ˆ", "ì˜ˆê¸ˆ", "ëŒ€ì¶œ", "ìœ ê°€ì¦ê¶Œ", "ê³ ì •ìì‚°", "ìœ ë™ìì‚°", "ì°¨ì…ê¸ˆ"],
                "ì†ìµí˜„í™©": ["ìˆ˜ìµ", "ë¹„ìš©", "ì†ìµ", "ì´ìµ", "ì†ì‹¤", "ë§¤ì¶œ", "ì˜ì—…ì´ìµ", "ìˆœì´ìµ", "ì†ìµê³„ì‚°ì„œ", "ì´ììˆ˜ìµ", "ì´ìë¹„ìš©", "ë‹¹ê¸°ìˆœì´ìµ", "ì˜ì—…ìˆ˜ìµ", "ì˜ì—…ë¹„ìš©"],
                "ê¸°íƒ€": ["ê¸°íƒ€", "ë¶€ê°€ì •ë³´", "ì£¼ìš”ì‚¬í•­", "íŠ¹ê¸°ì‚¬í•­", "ê³µì‹œì‚¬í•­", "ì°¸ê³ ì‚¬í•­", "ë¹„ê³ ", "ì£¼ì„", "ì„¤ëª…"]
            }
            
            # ì¹´í…Œê³ ë¦¬ë³„ ì ìˆ˜ ê³„ì‚°
            category_scores = {}
            for category, keywords in category_keywords.items():
                score = 0
                for keyword in keywords:
                    try:
                        score += table_text.count(keyword)
                    except:
                        continue
                category_scores[category] = score
            
            # ìµœê³  ì ìˆ˜ ì¹´í…Œê³ ë¦¬ ì„ íƒ
            if category_scores and max(category_scores.values()) > 0:
                best_category = max(category_scores, key=category_scores.get)
                return best_category
            
            return "ê¸°íƒ€"
            
        except Exception as e:
            logger.debug(f"í…Œì´ë¸” ë¶„ë¥˜ ì¤‘ ì˜¤ë¥˜: {e}")
            return "ê¸°íƒ€"

    def scrape_single_bank(self, bank_name, driver):
        """ë‹¨ì¼ ì€í–‰ ìŠ¤í¬ë˜í•‘ - í…Œì´ë¸” ë‚´ìš© ê¸°ë°˜ ë¶„ë¥˜"""
        logger.info(f"[{bank_name}] ìŠ¤í¬ë˜í•‘ ì‹œì‘")

        try:
            # ì€í–‰ ì„ íƒ
            if not select_bank(driver, bank_name, self.config):
                logger.error(f"{bank_name} ì€í–‰ ì„ íƒ ì‹¤íŒ¨")
                return None

            # ë‚ ì§œ ì •ë³´ ì¶”ì¶œ
            date_info = extract_date_information(driver)
            logger.info(f"{bank_name} ì€í–‰ ë‚ ì§œ ì •ë³´: {date_info}")

            # ë‚ ì§œ ê²€ì¦
            normalized_date = normalize_datestr_for_comparison(date_info)
            if normalized_date == self.config.latest_due_period:
                logger.info(f"[{bank_name}] ë‚ ì§œ ì¼ì¹˜: ê³µì‹ì  ìµœì‹ ")
            elif normalized_date == self.config.next_imminent_period:
                logger.info(f"[{bank_name}] ë‚ ì§œ ì¼ì¹˜: ì„ ì œì  ì—…ë°ì´íŠ¸")
            elif normalized_date not in [None, "ì•Œ ìˆ˜ ì—†ëŠ” í˜•ì‹"]:
                logger.warning(f"[{bank_name}] ë‚ ì§œ ë¶ˆì¼ì¹˜: {normalized_date}")

            # ëª¨ë“  í…Œì´ë¸”ì„ ìˆ˜ì§‘í•œ í›„ ë‚´ìš©ë³„ë¡œ ë¶„ë¥˜
            all_collected_tables = []
            all_table_hashes = set()  # ì „ì—­ ì¤‘ë³µ ì œê±°ìš©

            # ê° ì¹´í…Œê³ ë¦¬ íƒ­ì—ì„œ í…Œì´ë¸” ìˆ˜ì§‘
            for category in self.config.CATEGORIES:
                try:
                    # ì¹´í…Œê³ ë¦¬ íƒ­ í´ë¦­
                    if not select_category(driver, category, self.config):
                        logger.debug(f"{bank_name} ì€í–‰ {category} íƒ­ í´ë¦­ ì‹¤íŒ¨")
                        continue

                    # í…Œì´ë¸” ì¶”ì¶œ
                    tables = extract_tables_from_page(driver, self.config)
                    if not tables:
                        logger.debug(f"{bank_name} ì€í–‰ {category} ì¹´í…Œê³ ë¦¬ì—ì„œ í…Œì´ë¸” ì—†ìŒ")
                        continue

                    # ì¤‘ë³µ ì œê±° ë° ìˆ˜ì§‘
                    for df in tables:
                        try:
                            shape_hash = f"{df.shape}"
                            headers_hash = f"{list(df.columns)}"
                            data_hash = ""
                            if len(df) > 0:
                                data_hash = f"{list(df.iloc[0].astype(str))}"

                            table_hash = f"{shape_hash}_{headers_hash}_{data_hash}"

                            if table_hash not in all_table_hashes:
                                all_collected_tables.append({
                                    'table': df,
                                    'source_category': category
                                })
                                all_table_hashes.add(table_hash)
                        except:
                            all_collected_tables.append({
                                'table': df,
                                'source_category': category
                            })

                    logger.debug(f"{bank_name} ì€í–‰ {category} ì¹´í…Œê³ ë¦¬ì—ì„œ {len(tables)}ê°œ í…Œì´ë¸” ìˆ˜ì§‘")

                except Exception as e:
                    logger.error(f"{bank_name} ì€í–‰ {category} ì¹´í…Œê³ ë¦¬ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")

            if not all_collected_tables:
                logger.error(f"{bank_name} ì€í–‰ì—ì„œ í…Œì´ë¸”ì„ ìˆ˜ì§‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return None

            # ìˆ˜ì§‘ëœ í…Œì´ë¸”ì„ ë‚´ìš© ê¸°ë°˜ìœ¼ë¡œ ë¶„ë¥˜
            categorized_tables = {category: [] for category in self.config.CATEGORIES}
            
            for table_info in all_collected_tables:
                table = table_info['table']
                source_category = table_info['source_category']
                
                # í…Œì´ë¸” ë‚´ìš© ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ì¹´í…Œê³ ë¦¬ ê²°ì •
                classified_category = self.classify_table_by_content(table)
                
                # ë¶„ë¥˜ëœ ì¹´í…Œê³ ë¦¬ì— í…Œì´ë¸” ì¶”ê°€
                categorized_tables[classified_category].append(table)
                
                # ì¬ë¶„ë¥˜ëœ ê²½ìš° ë¡œê·¸ ê¸°ë¡
                if classified_category != source_category:
                    logger.debug(f"[{bank_name}] í…Œì´ë¸” ì¬ë¶„ë¥˜: {source_category} â†’ {classified_category}")

            # ê²°ê³¼ ë°ì´í„° êµ¬ì„±
            result_data = {'ë‚ ì§œì •ë³´': date_info}
            
            # ë¶„ë¥˜ëœ í…Œì´ë¸”ë§Œ í¬í•¨ (ë¹ˆ ì¹´í…Œê³ ë¦¬ëŠ” ì œì™¸)
            for category, tables in categorized_tables.items():
                if tables:
                    result_data[category] = tables
                    logger.debug(f"[{bank_name}] {category}: {len(tables)}ê°œ í…Œì´ë¸” ë¶„ë¥˜ ì™„ë£Œ")

            # ë°ì´í„° ìˆ˜ì§‘ ì—¬ë¶€ í™•ì¸
            if not any(isinstance(data, list) and data for key, data in result_data.items() if key != 'ë‚ ì§œì •ë³´'):
                logger.error(f"{bank_name} ì€í–‰ì—ì„œ ë¶„ë¥˜ëœ ë°ì´í„°ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return None

            logger.info(f"[{bank_name}] ë°ì´í„° ìˆ˜ì§‘ ë° ë¶„ë¥˜ ì™„ë£Œ")
            return result_data

        except Exception as e:
            logger.error(f"{bank_name} ì€í–‰ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return None

    def save_bank_data(self, bank_name, data_dict):
        """ì€í–‰ ë°ì´í„° ì €ì¥ (ì¹´í…Œê³ ë¦¬ë³„ ë‹¨ì¼ ì‹œíŠ¸)"""
        if not data_dict:
            return False

        try:
            # ë‚ ì§œ ì •ë³´ ì¶”ì¶œ
            date_info = data_dict.get('ë‚ ì§œì •ë³´', 'ë‚ ì§œì •ë³´ì—†ìŒ')
            safe_date_info = re.sub(r'[^\w\-_.]', '', date_info)

            # íŒŒì¼ëª…ì— ë‚ ì§œ ì •ë³´ í¬í•¨
            excel_path = self.config.output_dir / f"{bank_name}_{safe_date_info}.xlsx"

            with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:
                # ì •ë³´ ì‹œíŠ¸ ìƒì„±
                info_df = pd.DataFrame({
                    'ì€í–‰ëª…': [bank_name],
                    'ê³µì‹œ ë‚ ì§œ': [date_info],
                    'ì¶”ì¶œ ì¼ì‹œ': [datetime.now().strftime("%Y-%m-%d %H:%M:%S")],
                    'ìŠ¤í¬ë˜í¼ ë²„ì „': [self.config.VERSION]
                })
                info_df.to_excel(writer, sheet_name='ì •ë³´', index=False)

                # ê° ì¹´í…Œê³ ë¦¬ë³„ ë°ì´í„° ì €ì¥ (ë‹¨ì¼ ì‹œíŠ¸)
                for category, tables in data_dict.items():
                    if category == 'ë‚ ì§œì •ë³´' or not tables:
                        continue

                    if len(tables) == 1:
                        # í…Œì´ë¸”ì´ í•˜ë‚˜ì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ì €ì¥
                        tables[0].to_excel(writer, sheet_name=category, index=False)
                    else:
                        # ì—¬ëŸ¬ í…Œì´ë¸”ì„ í•˜ë‚˜ì˜ ì‹œíŠ¸ì— í†µí•©
                        combined_df_list = []
                        
                        for i, table in enumerate(tables):
                            # MultiIndex ì²˜ë¦¬
                            if isinstance(table.columns, pd.MultiIndex):
                                new_cols = []
                                for col in table.columns:
                                    if isinstance(col, tuple):
                                        col_parts = [str(c).strip() for c in col 
                                                   if str(c).strip() and str(c).lower() != 'nan']
                                        new_cols.append('_'.join(col_parts) 
                                                       if col_parts else f"Column_{len(new_cols)+1}")
                                    else:
                                        new_cols.append(str(col))
                                table.columns = new_cols
                            
                            # í…Œì´ë¸” êµ¬ë¶„ì ì¶”ê°€ (ì²« ë²ˆì§¸ í…Œì´ë¸” ì œì™¸)
                            if i > 0:
                                separator_row = pd.DataFrame([[''] * len(table.columns)], 
                                                           columns=table.columns)
                                title_row = pd.DataFrame([[f'=== í…Œì´ë¸” {i+1} ==='] + 
                                                         [''] * (len(table.columns)-1)], 
                                                        columns=table.columns)
                                combined_df_list.extend([separator_row, title_row])
                            
                            combined_df_list.append(table)
                        
                        # ëª¨ë“  í…Œì´ë¸”ì„ ì„¸ë¡œë¡œ ì—°ê²°
                        if combined_df_list:
                            combined_df = pd.concat(combined_df_list, ignore_index=True)
                            combined_df.to_excel(writer, sheet_name=category, index=False)

            logger.info(f"{bank_name} ì€í–‰ ë°ì´í„° ì €ì¥ ì™„ë£Œ: {excel_path}")
            return True

        except Exception as e:
            logger.error(f"{bank_name} ì€í–‰ ë°ì´í„° ì €ì¥ ì˜¤ë¥˜: {str(e)}")
            return False

    async def worker_process_bank(self, bank_name, pbar, semaphore):
        async with semaphore:
            driver, success, date_info = None, False, None
            try:
                driver = await asyncio.get_event_loop().run_in_executor(None, self.driver_manager.get_driver)
                if not driver: 
                    self.progress_manager.mark_failed(bank_name)
                    return bank_name, False, date_info
                
                data = None
                for attempt in range(self.config.MAX_RETRIES):
                    try:
                        data = self.scrape_single_bank(bank_name, driver)
                        if data: 
                            date_info = data.get('ë‚ ì§œì •ë³´', 'ë¯¸í™•ì •')
                            break
                    except Exception as e: 
                        logger.warning(f"[{bank_name}] ì‹œë„ {attempt+1} ì¤‘ ì˜ˆì™¸: {type(e).__name__} - {e}")
                        if attempt < self.config.MAX_RETRIES-1:
                            await asyncio.get_event_loop().run_in_executor(None, self.driver_manager.return_driver, driver)
                            driver = None
                            driver = await asyncio.get_event_loop().run_in_executor(None, self.driver_manager.get_driver)
                            if not driver: 
                                logger.error(f"[{bank_name}] ì¬ì‹œë„ìš© ë“œë¼ì´ë²„ íšë“ ì‹¤íŒ¨.")
                                break
                        else: 
                            data = None
                            logger.error(f"[{bank_name}] ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨.")
                
                if data and self.save_bank_data(bank_name, data):
                    self.progress_manager.mark_completed(bank_name, date_info)
                    success = True
                else: 
                    self.progress_manager.mark_failed(bank_name)
                
                return bank_name, success, date_info
                
            except Exception as e: 
                logger.error(f"[{bank_name}] ì‘ì—…ì ì˜ˆì™¸: {type(e).__name__} - {e}", exc_info=True)
                self.progress_manager.mark_failed(bank_name)
                return bank_name, False, date_info
            finally:
                if driver: 
                    await asyncio.get_event_loop().run_in_executor(None, self.driver_manager.return_driver, driver)
                if pbar: 
                    pbar.update(1)
                logger.info(f"[{bank_name}] ì²˜ë¦¬: {'ì„±ê³µ' if success else 'ì‹¤íŒ¨'}, ê³µì‹œì¼: {date_info or 'ë¯¸í™•ì •'}")
    
    async def run(self):
        logger.info(f"==== ìŠ¤í¬ë˜í•‘ ì‹œì‘ (v{self.config.VERSION}) ====")
        start_time = time.monotonic()
        pending_banks = self.progress_manager.get_pending_banks()
        
        if not pending_banks: 
            logger.info("ì²˜ë¦¬í•  ì€í–‰ ì—†ìŒ.")
            self.generate_summary_and_send_email()
            return
        
        logger.info(f"ì´ {len(pending_banks)}ê°œ ì€í–‰ ì²˜ë¦¬ ì˜ˆì •: {pending_banks[:3]}{'...' if len(pending_banks)>3 else ''}")
        semaphore = asyncio.Semaphore(self.config.MAX_WORKERS)
        
        with tqdm(total=len(pending_banks), desc="ì€í–‰ ìŠ¤í¬ë˜í•‘", unit="ì€í–‰", dynamic_ncols=True, smoothing=0.1) as pbar:
            tasks = [self.worker_process_bank(bank_name, pbar, semaphore) for bank_name in pending_banks]
            results = await asyncio.gather(*tasks, return_exceptions=True)
        
        processed_count = sum(1 for r in results if not isinstance(r, Exception))
        logger.info(f"asyncio.gatherë¡œ {processed_count}/{len(pending_banks)}ê°œ ì‘ì—… ë°˜í™˜ ì™„ë£Œ.")
        logger.info(f"==== ì „ì²´ ìŠ¤í¬ë˜í•‘ ì™„ë£Œ. ì†Œìš”ì‹œê°„: {time.monotonic() - start_time:.2f}ì´ˆ ====")
        self.generate_summary_and_send_email()

    def generate_summary_and_send_email(self):
        logger.info("ìš”ì•½ ë³´ê³ ì„œ ë° ì´ë©”ì¼ ìƒì„± ì‹œì‘...")
        summary_data = []
        all_banks_in_config = self.config.BANKS
        processed_banks_data = self.progress_manager.progress.get('banks', {})
        expected_officially_due = self.config.latest_due_period
        expected_next_imminent = self.config.next_imminent_period
        completed_count, failed_count = 0, 0
        failed_banks_names = []

        for bank_name_iter in all_banks_in_config:
            bank_detail = processed_banks_data.get(bank_name_iter)
            status, original_disc_date, date_match_status = 'ë¯¸ì²˜ë¦¬', '', ''
            
            if bank_detail:
                current_status = bank_detail.get('status')
                original_disc_date = bank_detail.get('date_info', '') 
                normalized_disc_date = normalize_datestr_for_comparison(original_disc_date)
                
                if current_status == 'completed':
                    status, completed_count = 'ì™„ë£Œ', completed_count + 1
                    if normalized_disc_date is None: 
                        date_match_status = "âš ï¸ ì¶”ì¶œì‹¤íŒ¨"
                    elif normalized_disc_date == "ì•Œ ìˆ˜ ì—†ëŠ” í˜•ì‹": 
                        date_match_status = f"â“ í˜•ì‹ëª¨ë¦„ ({original_disc_date})"
                    elif normalized_disc_date == expected_officially_due: 
                        date_match_status = "âœ… ì¼ì¹˜ (ê¸°í•œë‚´ ìµœì‹ )"
                    elif normalized_disc_date == expected_next_imminent: 
                        date_match_status = "ğŸŸ¢ ì¼ì¹˜ (ì˜ˆì •ë¶„ ì„ ë°˜ì˜)"
                    else: 
                        date_match_status = f"âŒ ë¶ˆì¼ì¹˜! (ì˜ˆìƒ: {expected_officially_due} ë˜ëŠ” {expected_next_imminent})"
                elif current_status == 'failed':
                    status, failed_count = 'ì‹¤íŒ¨', failed_count + 1
                    failed_banks_names.append(bank_name_iter)
                    date_match_status = "N/A (ì‹¤íŒ¨)"
            
            summary_data.append({
                'ì€í–‰ëª…': bank_name_iter, 
                'ê³µì‹œ ë‚ ì§œ(ì›ë³¸)': original_disc_date, 
                'ë‚ ì§œ í™•ì¸': date_match_status, 
                'ì²˜ë¦¬ ìƒíƒœ': status, 
                'í™•ì¸ ì‹œê°„': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            })
        
        summary_df = pd.DataFrame(summary_data)
        summary_filename = f"ìŠ¤í¬ë˜í•‘_ìš”ì•½_{self.config.today}.xlsx"
        summary_file_path = self.config.output_dir / summary_filename
        
        try: 
            summary_df.to_excel(summary_file_path, index=False)
            logger.info(f"ìš”ì•½ ë³´ê³ ì„œ: {summary_file_path}")
        except Exception as e: 
            logger.error(f"ìš”ì•½ ë³´ê³ ì„œ ì €ì¥ ì‹¤íŒ¨: {e}", exc_info=True)

        zip_filename_str = f"ì €ì¶•ì€í–‰_ë°ì´í„°_{self.config.today}.zip"
        zip_file_path_obj = self.config.output_dir_base / zip_filename_str
        
        try:
            with zipfile.ZipFile(zip_file_path_obj, 'w', zipfile.ZIP_DEFLATED) as zf:
                for f_path in self.config.output_dir.rglob('*'):
                    if f_path.is_file(): 
                        zf.write(f_path, Path(self.config.output_dir.name) / f_path.relative_to(self.config.output_dir))
            logger.info(f"ê²°ê³¼ ì••ì¶• ì™„ë£Œ: {zip_file_path_obj}")
        except Exception as e: 
            logger.error(f"ê²°ê³¼ ì••ì¶• ì‹¤íŒ¨: {e}", exc_info=True)
            zip_file_path_obj = None

        processed_attempt_count = completed_count + failed_count
        success_rate = (completed_count / processed_attempt_count * 100) if processed_attempt_count > 0 else 0
        date_for_subject = self.config.processing_date_kst.strftime("%Y.%m.%d")
        quarter_info_for_subject = get_quarter_string_from_period(expected_officially_due)
        email_subject = f"ì €ì¶•ì€í–‰ ë¶„ê¸° ê³µì‹œ ì·¨í•©_{quarter_info_for_subject} ({date_for_subject})"
        
        failed_banks_display_html = "".join(f"<li>{b}</li>" for b in failed_banks_names[:10])
        if len(failed_banks_names) > 10:
            failed_banks_display_html += f"<p>...ì™¸ {len(failed_banks_names)-10}ê°œ.</p>"
        elif not failed_banks_names:
            failed_banks_display_html = "ì—†ìŒ"
        
        body_html = f"""
        <html><head><style>
        body {{ font-family: Arial, sans-serif; margin: 20px; }}
        .summary-box {{ background-color: #f0f8ff; padding: 15px; border-radius: 5px; margin: 10px 0; }}
        .status-completed {{ color: #28a745; font-weight: bold; }}
        .status-failed {{ color: #dc3545; font-weight: bold; }}
        table {{ border-collapse: collapse; width: 100%; margin-top: 10px; }}
        th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}
        th {{ background-color: #f2f2f2; }}
        </style></head><body>
        <h2>ì €ì¶•ì€í–‰ ìŠ¤í¬ë˜í•‘ ê²°ê³¼ ({self.config.today})</h2>
        <p><strong>ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ì¼:</strong> {self.config.processing_date_kst.strftime('%Y-%m-%d')}</p>
        <p><strong>ê³µì‹ì  ìµœì‹  ì˜ˆìƒì¼:</strong> {expected_officially_due}</p>
        <p><strong>ë‹¤ìŒ ì—…ë¡œë“œ ì˜ˆìƒì¼:</strong> {expected_next_imminent}</p>
        <div class="summary-box">
            <p>ì´ ëŒ€ìƒ: {len(all_banks_in_config)}ê°œ</p> 
            <p>ì²˜ë¦¬ ì‹œë„: {processed_attempt_count}ê°œ</p>
            <p><span class="status-completed">âœ… ì„±ê³µ: {completed_count}ê°œ</span></p> 
            <p><span class="status-failed">âŒ ì‹¤íŒ¨: {failed_count}ê°œ</span> (ì„±ê³µë¥ : {success_rate:.1f}%)</p>
            <p>ğŸ“‚ ë°ì´í„°: {self.config.output_dir.name} (ì••ì¶•: {zip_filename_str if zip_file_path_obj else 'ìƒì„±ì‹¤íŒ¨'})</p>
        </div>
        <h3>ì‹¤íŒ¨ ì€í–‰ (ìµœëŒ€ 10ê°œ):</h3><ul>{failed_banks_display_html}</ul>
        <p>ì„¸ë¶€ ê²°ê³¼ëŠ” ì²¨ë¶€íŒŒì¼ í™•ì¸.</p> 
        <h3>ì€í–‰ë³„ ì²˜ë¦¬ í˜„í™©:</h3>
        {summary_df.to_html(index=False, border=1, na_rep='').replace('<td>','<td style="word-break:normal;">') if not summary_df.empty else "<p>ìš”ì•½ ë°ì´í„° ì—†ìŒ.</p>"}
        <br><p><small>ìë™ ë°œì†¡ (v{self.config.VERSION})</small></p>
        </body></html>"""
        
        attachment_to_send = str(zip_file_path_obj) if zip_file_path_obj and zip_file_path_obj.exists() else (str(summary_file_path) if summary_file_path.exists() else None)
        self.email_sender.send_email_with_attachment(email_subject, body_html, attachment_to_send)

# --- ë©”ì¸ ì‹¤í–‰ ë¡œì§ ---
def main():
    config = Config() 
    driver_mgr = None 
    try:
        logger.info(f"ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰: {sys.argv[0]}")
        driver_mgr = DriverManager(config)
        progress_mgr = ProgressManager(config)
        scraper = BankScraper(config, driver_mgr, progress_mgr)
        asyncio.run(scraper.run()) 
        logger.info("ëª¨ë“  ìŠ¤í¬ë˜í•‘ ì •ìƒ ì™„ë£Œ.")
    except Exception as e:
        if logger: 
            logger.critical(f"ìµœìƒìœ„ ì˜¤ë¥˜: {e}", exc_info=True)
        else: 
            print(f"ìµœìƒìœ„ ì˜¤ë¥˜ (ë¡œê±° ë¯¸ì„¤ì •): {e}\n{traceback.format_exc()}")
        sys.exit(1) 
    finally:
        if driver_mgr: 
            driver_mgr.quit_all() 
        if logger: 
            logger.info("ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì¢…ë£Œ.")
        else: 
            print("ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì¢…ë£Œ (ë¡œê±° ë¯¸ì„¤ì •).")

if __name__ == "__main__":
    main()
