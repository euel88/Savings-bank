#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ì €ì¶•ì€í–‰ ì¤‘ì•™íšŒ í†µì¼ê²½ì˜ê³µì‹œ ë°ì´í„° ìë™ ìŠ¤í¬ë˜í•‘ ìŠ¤í¬ë¦½íŠ¸ (GitHub Actions ë²„ì „)
ëª©ì : 79ê°œ ì €ì¶•ì€í–‰ì˜ ì¬ë¬´ì •ë³´ë¥¼ ë¹ ë¥´ê³  íš¨ìœ¨ì ìœ¼ë¡œ ìŠ¤í¬ë˜í•‘
ì‘ì„±ì¼: 2025-05-28
GitHub Actions í™˜ê²½ìš© ê°œì„ ì‚¬í•­:
- Colab ì¢…ì†ì„± ì œê±°
- í™˜ê²½ ë³€ìˆ˜ ê¸°ë°˜ ì„¤ì •
- ì´ë©”ì¼ ì•Œë¦¼ ê¸°ëŠ¥ ì¶”ê°€
- ë°ì´í„° ë‚ ì§œ ê²€ì¦ ë¡œì§ ì¶”ê°€
- ìƒëŒ€ ê²½ë¡œ ì‚¬ìš©
"""

import os
import sys
import time
import random
import json
import re
import asyncio
import concurrent.futures
import smtplib
import zipfile
from datetime import datetime, timedelta
from dateutil.relativedelta import relativedelta
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from email.mime.base import MIMEBase
from email import encoders
from io import StringIO
from tqdm import tqdm
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException, StaleElementReferenceException
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from bs4 import BeautifulSoup
import pandas as pd

# =============================================================================
# ì„¤ì • ë° ìƒìˆ˜
# =============================================================================

# í™˜ê²½ ë³€ìˆ˜ì—ì„œ ì„¤ì •ê°’ ê°€ì ¸ì˜¤ê¸° (ê¸°ë³¸ê°’ í¬í•¨)
TODAY = datetime.now().strftime("%Y%m%d")
BASE_URL = "https://www.fsb.or.kr/busmagequar_0100.act"
MAX_RETRIES = int(os.getenv('MAX_RETRIES', '2'))
PAGE_LOAD_TIMEOUT = int(os.getenv('PAGE_LOAD_TIMEOUT', '25'))
WAIT_TIMEOUT = int(os.getenv('WAIT_TIMEOUT', '15'))
MAX_WORKERS = int(os.getenv('MAX_WORKERS', '2'))

# ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì • (í™˜ê²½ ë³€ìˆ˜ ë˜ëŠ” ê¸°ë³¸ê°’)
OUTPUT_BASE_DIR = os.getenv('OUTPUT_DIR', './output')
OUTPUT_DIR = os.path.join(OUTPUT_BASE_DIR, f'ì €ì¶•ì€í–‰_ë°ì´í„°_{TODAY}')

# ì´ë©”ì¼ ì„¤ì •
GMAIL_ADDRESS = os.getenv('GMAIL_ADDRESS')
GMAIL_APP_PASSWORD = os.getenv('GMAIL_APP_PASSWORD')
RECIPIENT_EMAILS = os.getenv('RECIPIENT_EMAILS', '').split(',') if os.getenv('RECIPIENT_EMAILS') else []

# ì „ì²´ 79ê°œ ì €ì¶•ì€í–‰ ëª©ë¡ (ì—…ë°ì´íŠ¸: ë¨¸ìŠ¤íŠ¸ì‚¼ì¼ í†µí•©)
BANKS = [
    "ë‹¤ì˜¬", "ëŒ€ì‹ ", "ë”ì¼€ì´", "ë¯¼êµ­", "ë°”ë¡œ", "ìŠ¤ì¹´ì´", "ì‹ í•œ", "ì• íì˜¨", "ì˜ˆê°€ëŒ", "ì›°ì»´",
    "ìœ ì•ˆíƒ€", "ì¡°ì€", "í‚¤ì›€YES", "í‘¸ë¥¸", "í•˜ë‚˜", "DB", "HB", "JT", "ì¹œì• ", "KB",
    "NH", "OK", "OSB", "SBI", "ê¸ˆí™”", "ë‚¨ì–‘", "ëª¨ì•„", "ë¶€ë¦¼", "ì‚¼ì •", "ìƒìƒì¸",
    "ì„¸ëŒ", "ì•ˆêµ­", "ì•ˆì–‘", "ì˜ì§„", "ìœµì°½", "ì¸ì„±", "ì¸ì²œ", "í‚¤ì›€", "í˜í¼", "í‰íƒ",
    "í•œêµ­íˆ¬ì", "í•œí™”", "ê³ ë ¤", "êµ­ì œ", "ë™ì›ì œì¼", "ì†”ë¸Œë ˆì¸", "ì—ìŠ¤ì•¤í‹°", "ìš°ë¦¬", "ì¡°í¥", "ì§„ì£¼",
    "í¥êµ­", "BNK", "DH", "IBK", "ëŒ€ë°±", "ëŒ€ì•„", "ëŒ€ì›", "ë“œë¦¼", "ë¼ì˜¨", "ë¨¸ìŠ¤íŠ¸ì‚¼ì¼",
    "ì— ì—ìŠ¤", "ì˜¤ì„±", "ìœ ë‹ˆì˜¨", "ì°¸", "CK", "ëŒ€í•œ", "ë”ë¸”", "ë™ì–‘", "ì‚¼í˜¸",
    "ì„¼íŠ¸ëŸ´", "ìŠ¤ë§ˆíŠ¸", "ìŠ¤íƒ€", "ëŒ€ëª…", "ìƒìƒì¸í”ŒëŸ¬ìŠ¤", "ì•„ì‚°", "ì˜¤íˆ¬", "ìš°ë¦¬ê¸ˆìœµ", "ì²­ì£¼", "í•œì„±"
]

# ì¹´í…Œê³ ë¦¬ ëª©ë¡
CATEGORIES = ["ì˜ì—…ê°œí™©", "ì¬ë¬´í˜„í™©", "ì†ìµí˜„í™©", "ê¸°íƒ€"]

# íŒŒì¼ ê²½ë¡œ ì„¤ì •
PROGRESS_FILE = os.path.join(OUTPUT_DIR, 'bank_scraping_progress.json')
LOG_FILE = os.path.join(OUTPUT_DIR, f'scraping_log_{TODAY}.log')

# ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
os.makedirs(OUTPUT_DIR, exist_ok=True)

# =============================================================================
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
# =============================================================================

def log_message(message, print_to_console=True, verbose=True):
    """ë¡œê·¸ ë©”ì‹œì§€ë¥¼ íŒŒì¼ì— ê¸°ë¡í•˜ê³  í•„ìš”í•œ ê²½ìš° ì½˜ì†”ì— ì¶œë ¥í•©ë‹ˆë‹¤."""
    if not verbose:
        return

    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    log_entry = f"[{timestamp}] {message}"

    # ë¡œê·¸ íŒŒì¼ì— ê¸°ë¡
    try:
        with open(LOG_FILE, 'a', encoding='utf-8') as f:
            f.write(log_entry + '\n')
    except Exception as e:
        print(f"ë¡œê·¸ íŒŒì¼ ì“°ê¸° ì‹¤íŒ¨: {e}")

    # ì½˜ì†”ì— ì¶œë ¥
    if print_to_console:
        print(message)

def validate_data_freshness():
    """
    í˜„ì¬ ë‚ ì§œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì˜ˆìƒë˜ëŠ” ìµœì‹  ë°ì´í„° ë¶„ê¸°ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    ê° ë¶„ê¸°ë§(3ì›”ë§, 6ì›”ë§, 9ì›”ë§, 12ì›”ë§) ì¢…ë£Œ í›„ 2ê°œì›” í›„ ë§ˆì§€ë§‰ í‰ì¼ì— ì—…ë¡œë“œë¨.
    
    ì—…ë¡œë“œ ìŠ¤ì¼€ì¤„:
    - 3ì›”ë§ ë°ì´í„° â†’ 5ì›” ë§ˆì§€ë§‰ í‰ì¼
    - 6ì›”ë§ ë°ì´í„° â†’ 8ì›” ë§ˆì§€ë§‰ í‰ì¼
    - 9ì›”ë§ ë°ì´í„° â†’ 11ì›” ë§ˆì§€ë§‰ í‰ì¼
    - 12ì›”ë§ ë°ì´í„° â†’ 2ì›” ë§ˆì§€ë§‰ í‰ì¼
    """
    try:
        current_date = datetime.now()
        current_year = current_date.year
        current_month = current_date.month
        current_day = current_date.day
        
        # ë§ˆì§€ë§‰ í‰ì¼ ê³„ì‚°ì„ ìœ„í•œ í•¨ìˆ˜
        def get_last_weekday_of_month(year, month):
            import calendar
            last_day = calendar.monthrange(year, month)[1]
            for day in range(last_day, 0, -1):
                if datetime(year, month, day).weekday() < 5:  # ì›”ìš”ì¼(0) ~ ê¸ˆìš”ì¼(4)
                    return day
            return last_day
        
        # í˜„ì¬ ì›”ì˜ ë§ˆì§€ë§‰ í‰ì¼ì´ ì§€ë‚¬ëŠ”ì§€ í™•ì¸
        last_weekday_current_month = get_last_weekday_of_month(current_year, current_month)
        is_past_last_weekday = current_day > last_weekday_current_month
        
        # ë¶„ê¸°ë³„ ì˜ˆìƒ ì—…ë¡œë“œ ì›”ê³¼ ë°ì´í„° ë¶„ê¸° ê³„ì‚°
        if current_month == 11 or (current_month == 12) or (current_month == 1) or (current_month == 2 and not is_past_last_weekday):
            # 11ì›”, 12ì›”, 1ì›”, 2ì›” ë§ˆì§€ë§‰í‰ì¼ ì „ â†’ 9ì›”ë§ ë°ì´í„°ê°€ ìµœì‹ 
            expected_quarter_end = f"{current_year if current_month >= 11 else current_year-1}ë…„9ì›”ë§"
            next_expected_quarter_end = f"{current_year if current_month <= 2 else current_year-1}ë…„12ì›”ë§"
        elif current_month == 2 and is_past_last_weekday:
            # 2ì›” ë§ˆì§€ë§‰í‰ì¼ í›„ â†’ 12ì›”ë§ ë°ì´í„°ê°€ ì—…ë¡œë“œë¨
            expected_quarter_end = f"{current_year-1}ë…„12ì›”ë§"
            next_expected_quarter_end = f"{current_year}ë…„3ì›”ë§"
        elif current_month in [3, 4] or (current_month == 5 and not is_past_last_weekday):
            # 3ì›”, 4ì›”, 5ì›” ë§ˆì§€ë§‰í‰ì¼ ì „ â†’ 12ì›”ë§ ë°ì´í„°ê°€ ìµœì‹ 
            expected_quarter_end = f"{current_year-1}ë…„12ì›”ë§"
            next_expected_quarter_end = f"{current_year}ë…„3ì›”ë§"
        elif current_month == 5 and is_past_last_weekday:
            # 5ì›” ë§ˆì§€ë§‰í‰ì¼ í›„ â†’ 3ì›”ë§ ë°ì´í„°ê°€ ì—…ë¡œë“œë¨
            expected_quarter_end = f"{current_year}ë…„3ì›”ë§"
            next_expected_quarter_end = f"{current_year}ë…„6ì›”ë§"
        elif current_month in [6, 7] or (current_month == 8 and not is_past_last_weekday):
            # 6ì›”, 7ì›”, 8ì›” ë§ˆì§€ë§‰í‰ì¼ ì „ â†’ 3ì›”ë§ ë°ì´í„°ê°€ ìµœì‹ 
            expected_quarter_end = f"{current_year}ë…„3ì›”ë§"
            next_expected_quarter_end = f"{current_year}ë…„6ì›”ë§"
        elif current_month == 8 and is_past_last_weekday:
            # 8ì›” ë§ˆì§€ë§‰í‰ì¼ í›„ â†’ 6ì›”ë§ ë°ì´í„°ê°€ ì—…ë¡œë“œë¨
            expected_quarter_end = f"{current_year}ë…„6ì›”ë§"
            next_expected_quarter_end = f"{current_year}ë…„9ì›”ë§"
        elif current_month in [9, 10] or (current_month == 11 and not is_past_last_weekday):
            # 9ì›”, 10ì›”, 11ì›” ë§ˆì§€ë§‰í‰ì¼ ì „ â†’ 6ì›”ë§ ë°ì´í„°ê°€ ìµœì‹ 
            expected_quarter_end = f"{current_year}ë…„6ì›”ë§"
            next_expected_quarter_end = f"{current_year}ë…„9ì›”ë§"
        else:
            # ê¸°ë³¸ê°’ (ì˜ˆì™¸ ìƒí™©)
            expected_quarter_end = f"{current_year-1}ë…„12ì›”ë§"
            next_expected_quarter_end = f"{current_year}ë…„3ì›”ë§"
        
        # í˜„ì¬ê°€ 5ì›”ì´ê³  ì•„ì§ ë§ˆì§€ë§‰ í‰ì¼ì´ ì§€ë‚˜ì§€ ì•Šì•˜ë‹¤ë©´, 2024ë…„ 9ì›”ë§ì´ ìµœì‹ 
        if current_month == 5 and not is_past_last_weekday:
            expected_quarter_end = f"{current_year-1}ë…„9ì›”ë§"
            next_expected_quarter_end = f"{current_year}ë…„3ì›”ë§"
        
        possible_dates = [expected_quarter_end, next_expected_quarter_end]
        
        log_message(f"í˜„ì¬ ë‚ ì§œ: {current_date.strftime('%Yë…„ %mì›” %dì¼')}")
        log_message(f"ì´ë²ˆ ë‹¬ ë§ˆì§€ë§‰ í‰ì¼: {current_month}ì›” {last_weekday_current_month}ì¼")
        log_message(f"ë§ˆì§€ë§‰ í‰ì¼ ê²½ê³¼ ì—¬ë¶€: {'ì˜ˆ' if is_past_last_weekday else 'ì•„ë‹ˆì˜¤'}")
        log_message(f"ì˜ˆìƒ ìµœì‹  ë°ì´í„° ë¶„ê¸°: {expected_quarter_end}")
        log_message(f"ì¡°ê¸° ì—…ë¡œë“œ ê°€ëŠ¥ ë¶„ê¸°: {next_expected_quarter_end}")
        
        return possible_dates
        
    except Exception as e:
        log_message(f"ë°ì´í„° ì‹ ì„ ë„ ê²€ì¦ ì˜¤ë¥˜: {str(e)}")
        return [f"{current_year-1}ë…„9ì›”ë§", f"{current_year}ë…„3ì›”ë§"]

def send_email_notification(subject, body, bank_details=None, attachment_paths=None, is_success=True):
    """Gmail SMTPë¥¼ í†µí•´ ì´ë©”ì¼ ì•Œë¦¼ì„ ë°œì†¡í•©ë‹ˆë‹¤."""
    if not GMAIL_ADDRESS or not GMAIL_APP_PASSWORD or not RECIPIENT_EMAILS:
        log_message("ì´ë©”ì¼ ì„¤ì •ì´ ë¶ˆì™„ì „í•˜ì—¬ ì•Œë¦¼ì„ ë°œì†¡í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return False
    
    try:
        # ì´ë©”ì¼ ë©”ì‹œì§€ êµ¬ì„±
        msg = MIMEMultipart()
        msg['From'] = GMAIL_ADDRESS
        msg['To'] = ', '.join(RECIPIENT_EMAILS)
        msg['Subject'] = subject
        
        # ì€í–‰ë³„ ìƒì„¸ ì •ë³´ë¥¼ ë³¸ë¬¸ì— ì¶”ê°€
        enhanced_body = body
        if bank_details:
            enhanced_body += "\n\n===== ì€í–‰ë³„ ìƒì„¸ ê²°ê³¼ =====\n"
            
            # ì„±ê³µí•œ ì€í–‰ë“¤
            successful_banks = [bank for bank in bank_details if bank['status'] == 'success']
            if successful_banks:
                enhanced_body += f"\nâœ… ì„±ê³µí•œ ì€í–‰ ({len(successful_banks)}ê°œ):\n"
                for bank in successful_banks:
                    enhanced_body += f"  â€¢ {bank['name']}: {bank['date_info']}\n"
            
            # ë¶€ë¶„ ì„±ê³µí•œ ì€í–‰ë“¤  
            partial_banks = [bank for bank in bank_details if bank['status'] == 'partial']
            if partial_banks:
                enhanced_body += f"\nâš ï¸ ë¶€ë¶„ ì„±ê³µí•œ ì€í–‰ ({len(partial_banks)}ê°œ):\n"
                for bank in partial_banks:
                    enhanced_body += f"  â€¢ {bank['name']}: {bank['date_info']} (ì¼ë¶€ ì¹´í…Œê³ ë¦¬ ëˆ„ë½)\n"
            
            # ì‹¤íŒ¨í•œ ì€í–‰ë“¤
            failed_banks = [bank for bank in bank_details if bank['status'] == 'failed']
            if failed_banks:
                enhanced_body += f"\nâŒ ì‹¤íŒ¨í•œ ì€í–‰ ({len(failed_banks)}ê°œ):\n"
                for bank in failed_banks:
                    enhanced_body += f"  â€¢ {bank['name']}: {bank.get('error_reason', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}\n"
            
            # ë°ì´í„° ì‹ ì„ ë„ë³„ ë¶„ë¥˜
            enhanced_body += "\n\n===== ë°ì´í„° ì‹ ì„ ë„ë³„ ë¶„ë¥˜ =====\n"
            fresh_banks = [bank for bank in bank_details if bank.get('is_fresh', False)]
            old_banks = [bank for bank in bank_details if not bank.get('is_fresh', False) and bank['status'] in ['success', 'partial']]
            
            if fresh_banks:
                enhanced_body += f"\nğŸŸ¢ ìµœì‹  ë°ì´í„° ì€í–‰ ({len(fresh_banks)}ê°œ):\n"
                for bank in fresh_banks:
                    enhanced_body += f"  â€¢ {bank['name']}: {bank['date_info']}\n"
            
            if old_banks:
                enhanced_body += f"\nğŸŸ¡ êµ¬ë²„ì „ ë°ì´í„° ì€í–‰ ({len(old_banks)}ê°œ):\n"
                for bank in old_banks:
                    enhanced_body += f"  â€¢ {bank['name']}: {bank['date_info']}\n"
        
        # ë³¸ë¬¸ ì¶”ê°€
        msg.attach(MIMEText(enhanced_body, 'plain', 'utf-8'))
        
        # ì²¨ë¶€ íŒŒì¼ ì¶”ê°€
        if attachment_paths:
            for file_path in attachment_paths:
                if os.path.exists(file_path):
                    try:
                        with open(file_path, "rb") as attachment:
                            part = MIMEBase('application', 'octet-stream')
                            part.set_payload(attachment.read())
                        
                        encoders.encode_base64(part)
                        filename = os.path.basename(file_path)
                        part.add_header(
                            'Content-Disposition',
                            f'attachment; filename= {filename}',
                        )
                        msg.attach(part)
                        log_message(f"ì²¨ë¶€ íŒŒì¼ ì¶”ê°€: {filename}")
                    except Exception as e:
                        log_message(f"ì²¨ë¶€ íŒŒì¼ ì¶”ê°€ ì‹¤íŒ¨ ({file_path}): {str(e)}")
        
        # Gmail SMTP ì„œë²„ ì—°ê²° ë° ë°œì†¡
        with smtplib.SMTP('smtp.gmail.com', 587) as server:
            server.starttls()
            server.login(GMAIL_ADDRESS, GMAIL_APP_PASSWORD)
            server.send_message(msg)
        
        log_message(f"ì´ë©”ì¼ ì•Œë¦¼ ë°œì†¡ ì™„ë£Œ: {', '.join(RECIPIENT_EMAILS)}")
        return True
        
    except Exception as e:
        log_message(f"ì´ë©”ì¼ ë°œì†¡ ì‹¤íŒ¨: {str(e)}")
        return False

# =============================================================================
# ë“œë¼ì´ë²„ ê´€ë¦¬ í´ë˜ìŠ¤
# =============================================================================

class DriverManager:
    """ì›¹ ë“œë¼ì´ë²„ í’€ì„ ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤ì…ë‹ˆë‹¤."""
    
    def __init__(self, max_drivers=MAX_WORKERS):
        self.max_drivers = max_drivers
        self.drivers = []
        self.available_drivers = []
        self.initialize_drivers()

    def initialize_drivers(self):
        """ë“œë¼ì´ë²„ í’€ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
        log_message(f"{self.max_drivers}ê°œì˜ Chrome ë“œë¼ì´ë²„ ì´ˆê¸°í™” ì¤‘...")
        for _ in range(self.max_drivers):
            driver = self.create_driver()
            if driver:
                self.drivers.append(driver)
                self.available_drivers.append(driver)
        log_message(f"ì´ {len(self.drivers)}ê°œì˜ ë“œë¼ì´ë²„ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.")

    def create_driver(self):
        """GitHub Actions í™˜ê²½ì— ìµœì í™”ëœ Chrome ì›¹ë“œë¼ì´ë²„ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        try:
            options = Options()
            
            # Headless ëª¨ë“œ (GitHub Actions í™˜ê²½ì—ì„œ í•„ìˆ˜)
            options.add_argument('--headless=new')
            options.add_argument('--no-sandbox')
            options.add_argument('--disable-dev-shm-usage')
            options.add_argument('--disable-gpu')
            options.add_argument('--window-size=1920,1080')
            
            # User-Agent ì„¤ì •
            options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
            
            # ì„±ëŠ¥ ìµœì í™” ì˜µì…˜
            options.add_argument('--disable-extensions')
            options.add_argument('--disable-browser-side-navigation')
            options.add_argument('--disable-infobars')
            options.add_argument('--disable-notifications')
            options.add_argument('--disable-popup-blocking')
            options.add_argument('--disable-background-networking')
            options.add_argument('--disable-background-timer-throttling')
            options.add_argument('--disable-backgrounding-occluded-windows')
            options.add_argument('--disable-renderer-backgrounding')
            
            # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”
            options.add_argument('--memory-pressure-off')
            options.add_argument('--max_old_space_size=4096')
            
            # ë³´ì•ˆ ê´€ë ¨ ì˜µì…˜ (CI í™˜ê²½ì—ì„œ í•„ìš”)
            options.add_argument('--disable-web-security')
            options.add_argument('--allow-running-insecure-content')
            
            # Chrome í™˜ê²½ì„¤ì •
            prefs = {
                'profile.default_content_setting_values': {
                    'images': 1,          # ì´ë¯¸ì§€ ë¡œë”© í—ˆìš©
                    'plugins': 2,         # í”ŒëŸ¬ê·¸ì¸ ì°¨ë‹¨
                    'javascript': 1,      # JavaScript í—ˆìš© (í•„ìˆ˜)
                    'notifications': 2,   # ì•Œë¦¼ ì°¨ë‹¨
                    'media_stream': 2,    # ë¯¸ë””ì–´ ìŠ¤íŠ¸ë¦¼ ì°¨ë‹¨
                },
                'disk-cache-size': 4096,
            }
            options.add_experimental_option('prefs', prefs)
            
            # Chrome ë“œë¼ì´ë²„ ìƒì„±
            driver = webdriver.Chrome(options=options)
            driver.set_page_load_timeout(PAGE_LOAD_TIMEOUT)
            driver.implicitly_wait(WAIT_TIMEOUT)
            
            return driver
            
        except Exception as e:
            log_message(f"Chrome ë“œë¼ì´ë²„ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            return None

    def get_driver(self):
        """ì‚¬ìš© ê°€ëŠ¥í•œ ë“œë¼ì´ë²„ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
        while not self.available_drivers:
            log_message("ëª¨ë“  ë“œë¼ì´ë²„ê°€ ì‚¬ìš© ì¤‘ì…ë‹ˆë‹¤. ì ì‹œ ëŒ€ê¸°...", verbose=False)
            time.sleep(1)
            
        driver = self.available_drivers.pop(0)
        return driver

    def return_driver(self, driver):
        """ë“œë¼ì´ë²„ë¥¼ í’€ì— ë°˜í™˜í•©ë‹ˆë‹¤."""
        if driver in self.drivers and driver not in self.available_drivers:
            try:
                # ë“œë¼ì´ë²„ ìƒíƒœ í™•ì¸
                driver.current_url  # ì ‘ê·¼ ê°€ëŠ¥ì„± í…ŒìŠ¤íŠ¸
                self.available_drivers.append(driver)
            except:
                # ì˜¤ë¥˜ ë°œìƒ ì‹œ ë“œë¼ì´ë²„ë¥¼ êµì²´
                try:
                    driver.quit()
                except:
                    pass
                
                self.drivers.remove(driver)
                new_driver = self.create_driver()
                if new_driver:
                    self.drivers.append(new_driver)
                    self.available_drivers.append(new_driver)

    def close_all(self):
        """ëª¨ë“  ë“œë¼ì´ë²„ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤."""
        for driver in self.drivers:
            try:
                driver.quit()
            except:
                pass
        self.drivers = []
        self.available_drivers = []

# =============================================================================
# ì§„í–‰ ìƒí™© ê´€ë¦¬ í´ë˜ìŠ¤
# =============================================================================

class ProgressManager:
    """ìŠ¤í¬ë˜í•‘ ì§„í–‰ ìƒí™©ì„ ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤ì…ë‹ˆë‹¤."""
    
    def __init__(self, file_path=None):
        self.file_path = file_path or PROGRESS_FILE
        self.progress = self.load()

    def load(self):
        """ì €ì¥ëœ ì§„í–‰ ìƒí™©ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
        if os.path.exists(self.file_path):
            try:
                with open(self.file_path, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except (json.JSONDecodeError, FileNotFoundError):
                log_message(f"ì§„í–‰ íŒŒì¼ ì†ìƒ ë˜ëŠ” ì—†ìŒ: {self.file_path}, ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤.")

        return {
            'completed': [],
            'failed': [],
            'data_validation': [],
            'stats': {
                'last_run': None,
                'success_count': 0,
                'failure_count': 0,
                'validation_count': 0
            }
        }

    def is_completed(self, bank_name):
        """íŠ¹ì • ì€í–‰ì˜ ìŠ¤í¬ë˜í•‘ì´ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤."""
        return bank_name in self.progress.get('completed', [])

    def mark_completed(self, bank_name):
        """ì€í–‰ì„ ì™„ë£Œ ëª©ë¡ì— ì¶”ê°€í•©ë‹ˆë‹¤."""
        if bank_name not in self.progress.get('completed', []):
            self.progress.setdefault('completed', []).append(bank_name)
            self.progress['stats']['success_count'] = len(self.progress.get('completed', []))

        # ì‹¤íŒ¨ ëª©ë¡ì—ì„œ ì œê±° (ì¬ì‹œë„ í›„ ì„±ê³µí•œ ê²½ìš°)
        if bank_name in self.progress.get('failed', []):
            self.progress['failed'].remove(bank_name)

        self.save()

    def mark_failed(self, bank_name):
        """ì€í–‰ì„ ì‹¤íŒ¨ ëª©ë¡ì— ì¶”ê°€í•©ë‹ˆë‹¤."""
        if bank_name not in self.progress.get('failed', []) and bank_name not in self.progress.get('completed', []):
            self.progress.setdefault('failed', []).append(bank_name)
            self.progress['stats']['failure_count'] = len(self.progress.get('failed', []))
            self.save()

    def mark_data_validated(self, bank_name, date_info, is_fresh):
        """ì€í–‰ì˜ ë°ì´í„° ê²€ì¦ ê²°ê³¼ë¥¼ ê¸°ë¡í•©ë‹ˆë‹¤."""
        validation_entry = {
            'bank_name': bank_name,
            'date_info': date_info,
            'is_fresh': is_fresh,
            'validated_at': datetime.now().isoformat()
        }
        
        self.progress.setdefault('data_validation', []).append(validation_entry)
        self.progress['stats']['validation_count'] = len(self.progress.get('data_validation', []))
        self.save()

    def save(self):
        """ì§„í–‰ ìƒí™©ì„ íŒŒì¼ì— ì €ì¥í•©ë‹ˆë‹¤."""
        self.progress['stats']['last_run'] = datetime.now().isoformat()
        try:
            with open(self.file_path, 'w', encoding='utf-8') as f:
                json.dump(self.progress, f, ensure_ascii=False, indent=2)
        except Exception as e:
            log_message(f"ì§„í–‰ ìƒí™© ì €ì¥ ì‹¤íŒ¨: {str(e)}")

    def get_pending_banks(self, all_banks=BANKS):
        """ì²˜ë¦¬í•  ì€í–‰ ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        completed = set(self.progress.get('completed', []))
        return [bank for bank in all_banks if bank not in completed]

# =============================================================================
# ì›¹ ìŠ¤í¬ë˜í•‘ ìœ í‹¸ë¦¬í‹° í´ë˜ìŠ¤
# =============================================================================

class WaitUtils:
    """ëª…ì‹œì  ëŒ€ê¸°ë¥¼ ìœ„í•œ ìœ í‹¸ë¦¬í‹° í´ë˜ìŠ¤ì…ë‹ˆë‹¤."""
    
    @staticmethod
    def wait_for_element(driver, locator, timeout=WAIT_TIMEOUT):
        """ìš”ì†Œê°€ ë‚˜íƒ€ë‚  ë•Œê¹Œì§€ ëª…ì‹œì ìœ¼ë¡œ ëŒ€ê¸°í•©ë‹ˆë‹¤."""
        try:
            element = WebDriverWait(driver, timeout).until(
                EC.presence_of_element_located(locator)
            )
            return element
        except TimeoutException:
            return None

    @staticmethod
    def wait_for_clickable(driver, locator, timeout=WAIT_TIMEOUT):
        """ìš”ì†Œê°€ í´ë¦­ ê°€ëŠ¥í•  ë•Œê¹Œì§€ ëª…ì‹œì ìœ¼ë¡œ ëŒ€ê¸°í•©ë‹ˆë‹¤."""
        try:
            element = WebDriverWait(driver, timeout).until(
                EC.element_to_be_clickable(locator)
            )
            return element
        except TimeoutException:
            return None

    @staticmethod
    def wait_for_page_load(driver, timeout=PAGE_LOAD_TIMEOUT):
        """í˜ì´ì§€ê°€ ì™„ì „íˆ ë¡œë“œë  ë•Œê¹Œì§€ ëŒ€ê¸°í•©ë‹ˆë‹¤."""
        try:
            WebDriverWait(driver, timeout).until(
                lambda d: d.execute_script('return document.readyState') == 'complete'
            )
            return True
        except TimeoutException:
            return False

    @staticmethod
    def wait_with_random(min_time=0.5, max_time=1.5):
        """ë¬´ì‘ìœ„ ì‹œê°„ ë™ì•ˆ ëŒ€ê¸°í•©ë‹ˆë‹¤ (ë´‡ íƒì§€ ë°©ì§€)."""
        time.sleep(random.uniform(min_time, max_time))

# =============================================================================
# ë°ì´í„° ì¶”ì¶œ ë° ê²€ì¦ í•¨ìˆ˜ë“¤
# =============================================================================

def extract_date_information(driver):
    """ì›¹í˜ì´ì§€ì—ì„œ ê³µì‹œ ë‚ ì§œ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    try:
        # ë‚ ì§œ ì •ë³´ê°€ í¬í•¨ëœ ìš”ì†Œë“¤ì„ ë‹¤ì–‘í•œ ë°©ë²•ìœ¼ë¡œ ì°¾ê¸°
        date_selectors = [
            "//*[contains(text(), 'ê¸°ë§') and contains(text(), 'ë…„')]",
            "//h1 | //h2 | //h3 | //h4 | //h5 | //th[contains(text(), 'ë…„')]",
            "//*[contains(text(), 'ë…„') and contains(text(), 'ì›”ë§')]"
        ]
        
        for selector in date_selectors:
            try:
                date_elements = driver.find_elements(By.XPATH, selector)
                for element in date_elements:
                    text = element.text
                    # ì •ê·œì‹ìœ¼ë¡œ ë‚ ì§œ íŒ¨í„´ ì¶”ì¶œ (XXXXë…„XXì›”ë§)
                    date_pattern = re.compile(r'\d{4}ë…„\s*\d{1,2}ì›”ë§')
                    matches = date_pattern.findall(text)
                    
                    if matches:
                        # ê³µë°± ì œê±°í•˜ì—¬ í‘œì¤€í™”
                        return matches[0].replace(' ', '')
            except Exception:
                continue
        
        # JavaScriptë¡œ ì „ì²´ í˜ì´ì§€ í…ìŠ¤íŠ¸ì—ì„œ ë‚ ì§œ ì¶”ì¶œ ì‹œë„
        try:
            js_script = """
            var allText = document.body.innerText;
            var match = allText.match(/\\d{4}ë…„\\s*\\d{1,2}ì›”ë§/);
            return match ? match[0].replace(/\\s+/g, '') : '';
            """
            date_text = driver.execute_script(js_script)
            if date_text:
                return date_text
        except Exception:
            pass

        return "ë‚ ì§œ ì •ë³´ ì—†ìŒ"

    except Exception as e:
        log_message(f"ë‚ ì§œ ì •ë³´ ì¶”ì¶œ ì˜¤ë¥˜: {str(e)}", verbose=False)
        return "ë‚ ì§œ ì¶”ì¶œ ì‹¤íŒ¨"

def validate_extracted_date(extracted_date, expected_dates):
    """ì¶”ì¶œëœ ë‚ ì§œê°€ ì˜ˆìƒ ë‚ ì§œì™€ ì¼ì¹˜í•˜ëŠ”ì§€ ê²€ì¦í•©ë‹ˆë‹¤."""
    if not extracted_date or extracted_date in ["ë‚ ì§œ ì •ë³´ ì—†ìŒ", "ë‚ ì§œ ì¶”ì¶œ ì‹¤íŒ¨"]:
        return False, "ë‚ ì§œ ì •ë³´ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŒ"
    
    # ì¶”ì¶œëœ ë‚ ì§œ ì •ê·œí™”
    normalized_extracted = extracted_date.replace(' ', '')
    
    for expected_date in expected_dates:
        normalized_expected = expected_date.replace(' ', '')
        if normalized_extracted == normalized_expected:
            return True, f"ìµœì‹  ë°ì´í„° í™•ì¸: {extracted_date}"
    
    # ë¶€ë¶„ ì¼ì¹˜ í™•ì¸ (ë…„ë„ì™€ ì›” í™•ì¸)
    try:
        # ì¶”ì¶œëœ ë‚ ì§œì—ì„œ ë…„ë„ì™€ ì›” ì¶”ì¶œ
        match = re.search(r'(\d{4})ë…„(\d{1,2})ì›”ë§', normalized_extracted)
        if match:
            year, month = match.groups()
            for expected_date in expected_dates:
                exp_match = re.search(r'(\d{4})ë…„(\d{1,2})ì›”ë§', expected_date)
                if exp_match:
                    exp_year, exp_month = exp_match.groups()
                    if year == exp_year and month.zfill(2) == exp_month.zfill(2):
                        return True, f"ì˜ˆìƒë³´ë‹¤ ë¹ ë¥¸ ì—…ë¡œë“œ: {extracted_date}"
    except Exception:
        pass
    
    return False, f"ì˜ˆìƒ ë‚ ì§œì™€ ë¶ˆì¼ì¹˜: {extracted_date} (ì˜ˆìƒ: {', '.join(expected_dates)})"

def select_bank(driver, bank_name):
    """ë‹¤ì–‘í•œ ë°©ë²•ìœ¼ë¡œ ì€í–‰ì„ ì„ íƒí•©ë‹ˆë‹¤."""
    try:
        # ë©”ì¸ í˜ì´ì§€ë¡œ ì ‘ì†
        driver.get(BASE_URL)
        WaitUtils.wait_for_page_load(driver)
        WaitUtils.wait_with_random(1, 2)

        # JavaScriptë¥¼ ì‚¬ìš©í•œ ì€í–‰ ì„ íƒ (ê°€ì¥ í™•ì‹¤í•œ ë°©ë²•)
        js_script = f"""
        // ëª¨ë“  ë§í¬ì™€ í…Œì´ë¸” ì…€ì—ì„œ ì€í–‰ëª… ê²€ìƒ‰
        var allElements = document.querySelectorAll('a, td, th, span, div');
        var targetBank = '{bank_name}';
        
        for(var i = 0; i < allElements.length; i++) {{
            var element = allElements[i];
            var text = element.textContent.trim();
            
            // ì •í™•í•œ ì¼ì¹˜ ìš°ì„ 
            if(text === targetBank) {{
                element.scrollIntoView({{block: 'center'}});
                if(element.tagName.toLowerCase() === 'a') {{
                    element.click();
                    return 'exact_link_click';
                }}
                // ë§í¬ê°€ ì•„ë‹ˆë©´ ë‚´ë¶€ ë§í¬ ì°¾ê¸°
                var links = element.querySelectorAll('a');
                if(links.length > 0) {{
                    links[0].click();
                    return 'exact_nested_link_click';
                }}
                element.click();
                return 'exact_element_click';
            }}
            
            // ë¶€ë¶„ ì¼ì¹˜
            if(text.includes(targetBank) && text.length < targetBank.length + 10) {{
                element.scrollIntoView({{block: 'center'}});
                if(element.tagName.toLowerCase() === 'a') {{
                    element.click();
                    return 'partial_link_click';
                }}
                var links = element.querySelectorAll('a');
                if(links.length > 0) {{
                    links[0].click();
                    return 'partial_nested_link_click';
                }}
                element.click();
                return 'partial_element_click';
            }}
        }}
        
        return false;
        """
        
        result = driver.execute_script(js_script)
        if result:
            log_message(f"{bank_name} ì€í–‰: JavaScript {result} ì„±ê³µ", verbose=False)
            WaitUtils.wait_with_random(1, 2)
            return True

        # Seleniumì„ ì‚¬ìš©í•œ ëŒ€ì²´ ë°©ë²•ë“¤
        bank_xpaths = [
            f"//td[text()='{bank_name}']//a | //a[text()='{bank_name}']",
            f"//td[contains(text(), '{bank_name}')]//a | //a[contains(text(), '{bank_name}')]",
            f"//*[contains(text(), '{bank_name}') and (self::a or descendant::a)]"
        ]

        for xpath in bank_xpaths:
            try:
                elements = driver.find_elements(By.XPATH, xpath)
                for element in elements:
                    if element.is_displayed():
                        driver.execute_script("arguments[0].scrollIntoView({block: 'center'});", element)
                        WaitUtils.wait_with_random(0.5, 1)
                        driver.execute_script("arguments[0].click();", element)
                        WaitUtils.wait_with_random(1, 2)
                        return True
            except Exception:
                continue

        log_message(f"{bank_name} ì€í–‰ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return False

    except Exception as e:
        log_message(f"{bank_name} ì€í–‰ ì„ íƒ ì‹¤íŒ¨: {str(e)}")
        return False

def select_category(driver, category):
    """íŠ¹ì • ì¹´í…Œê³ ë¦¬ íƒ­ì„ í´ë¦­í•©ë‹ˆë‹¤."""
    try:
        # JavaScriptë¥¼ ì‚¬ìš©í•œ ì¹´í…Œê³ ë¦¬ ì„ íƒ
        js_script = f"""
        var targetCategory = '{category}';
        var allElements = document.querySelectorAll('a, button, span, li, div, tab');
        
        // ì •í™•í•œ í…ìŠ¤íŠ¸ ë§¤ì¹­ ìš°ì„ 
        for(var i = 0; i < allElements.length; i++) {{
            var element = allElements[i];
            var text = element.textContent.trim();
            
            if(text === targetCategory && element.offsetParent !== null) {{
                element.scrollIntoView({{block: 'center'}});
                element.click();
                return 'exact_match';
            }}
        }}
        
        // í¬í•¨ ê²€ìƒ‰
        for(var i = 0; i < allElements.length; i++) {{
            var element = allElements[i];
            var text = element.textContent.trim();
            
            if(text.includes(targetCategory) && element.offsetParent !== null) {{
                element.scrollIntoView({{block: 'center'}});
                element.click();
                return 'contains_match';
            }}
        }}
        
        // íƒ­ ì»¨í…Œì´ë„ˆì—ì„œ ì¸ë±ìŠ¤ ê¸°ë°˜ ê²€ìƒ‰
        var categoryIndex = {{'ì˜ì—…ê°œí™©': 0, 'ì¬ë¬´í˜„í™©': 1, 'ì†ìµí˜„í™©': 2, 'ê¸°íƒ€': 3}};
        var index = categoryIndex[targetCategory];
        
        if(index !== undefined) {{
            var tabContainers = document.querySelectorAll('ul.tabs, .tab-container, nav, .tab-list, ul');
            for(var i = 0; i < tabContainers.length; i++) {{
                var tabs = tabContainers[i].querySelectorAll('a, li, button, span');
                if(tabs.length > index && tabs[index].offsetParent !== null) {{
                    tabs[index].scrollIntoView({{block: 'center'}});
                    tabs[index].click();
                    return 'index_match';
                }}
            }}
        }}
        
        return false;
        """
        
        result = driver.execute_script(js_script)
        if result:
            log_message(f"{category} íƒ­: JavaScript {result} ì„±ê³µ", verbose=False)
            WaitUtils.wait_with_random(1, 2)
            return True

        # Seleniumì„ ì‚¬ìš©í•œ ëŒ€ì²´ ë°©ë²•
        category_xpaths = [
            f"//a[normalize-space(text())='{category}']",
            f"//*[contains(text(), '{category}') and (self::a or self::button or self::span or self::li)]"
        ]

        for xpath in category_xpaths:
            try:
                elements = driver.find_elements(By.XPATH, xpath)
                for element in elements:
                    if element.is_displayed():
                        driver.execute_script("arguments[0].scrollIntoView({block: 'center'});", element)
                        WaitUtils.wait_with_random(0.5, 1)
                        driver.execute_script("arguments[0].click();", element)
                        WaitUtils.wait_with_random(1, 2)
                        return True
            except Exception:
                continue

        log_message(f"{category} íƒ­ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", verbose=False)
        return False

    except Exception as e:
        log_message(f"{category} íƒ­ í´ë¦­ ì‹¤íŒ¨: {str(e)}", verbose=False)
        return False

def extract_tables_from_page(driver):
    """í˜„ì¬ í˜ì´ì§€ì—ì„œ ëª¨ë“  í…Œì´ë¸”ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    try:
        WaitUtils.wait_for_page_load(driver)
        WaitUtils.wait_with_random(1, 2)

        # pandasë¥¼ ì‚¬ìš©í•œ í…Œì´ë¸” ì¶”ì¶œ ì‹œë„
        try:
            html_source = driver.page_source
            dfs = pd.read_html(StringIO(html_source))

            if dfs:
                valid_dfs = []
                seen_hashes = set()

                for df in dfs:
                    if not df.empty and df.shape[0] > 0 and df.shape[1] > 0:
                        # MultiIndex ì»¬ëŸ¼ ì²˜ë¦¬
                        if isinstance(df.columns, pd.MultiIndex):
                            new_cols = []
                            for col in df.columns:
                                if isinstance(col, tuple):
                                    clean_parts = [str(c).strip() for c in col if str(c).strip() and str(c).lower() != 'nan']
                                    new_cols.append('_'.join(clean_parts) if clean_parts else f"Column_{len(new_cols)+1}")
                                else:
                                    new_cols.append(str(col))
                            df.columns = new_cols

                        # ì¤‘ë³µ í…Œì´ë¸” ì œê±°ë¥¼ ìœ„í•œ í•´ì‹œ ìƒì„±
                        try:
                            df_hash = hash(str(df.shape) + str(list(df.columns)) + str(df.iloc[0].values) if len(df) > 0 else "")
                            if df_hash not in seen_hashes:
                                valid_dfs.append(df)
                                seen_hashes.add(df_hash)
                        except Exception:
                            valid_dfs.append(df)

                return valid_dfs
        except Exception as e:
            log_message(f"pandas í…Œì´ë¸” ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}", verbose=False)

        # BeautifulSoupì„ ì‚¬ìš©í•œ ëŒ€ì²´ ì¶”ì¶œ ë°©ë²•
        try:
            soup = BeautifulSoup(driver.page_source, 'html.parser')
            tables = soup.find_all('table')
            
            extracted_dfs = []
            seen_hashes = set()

            for table in tables:
                try:
                    # í—¤ë” ì¶”ì¶œ
                    headers = []
                    th_elements = table.select('thead th') or table.select('tr:first-child th')
                    if th_elements:
                        headers = [th.get_text(strip=True) for th in th_elements]

                    # í—¤ë”ê°€ ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ í–‰ì˜ tdë¥¼ í—¤ë”ë¡œ ì‚¬ìš©
                    if not headers:
                        first_row_tds = table.select('tr:first-child td')
                        if first_row_tds:
                            headers = [td.get_text(strip=True) or f"Column_{i+1}" for i, td in enumerate(first_row_tds)]

                    # ë°ì´í„° í–‰ ì¶”ì¶œ
                    rows = []
                    for tr in table.select('tbody tr') or table.select('tr')[1:]:
                        cells = tr.select('td')
                        if cells:
                            row_data = [td.get_text(strip=True) for td in cells]
                            if row_data:
                                rows.append(row_data)

                    # DataFrame ìƒì„±
                    if rows and headers:
                        # ì—´ ê°œìˆ˜ ë§ì¶”ê¸°
                        for i, row in enumerate(rows):
                            if len(row) < len(headers):
                                rows[i] = row + [''] * (len(headers) - len(row))
                            elif len(row) > len(headers):
                                rows[i] = row[:len(headers)]

                        df = pd.DataFrame(rows, columns=headers)
                        
                        if not df.empty:
                            # ì¤‘ë³µ ì œê±°ë¥¼ ìœ„í•œ í•´ì‹œ ìƒì„±
                            try:
                                df_hash = hash(str(df.shape) + str(df.iloc[0].values) if len(df) > 0 else "")
                                if df_hash not in seen_hashes:
                                    extracted_dfs.append(df)
                                    seen_hashes.add(df_hash)
                            except Exception:
                                extracted_dfs.append(df)
                                
                except Exception as e:
                    log_message(f"ê°œë³„ í…Œì´ë¸” íŒŒì‹± ì‹¤íŒ¨: {str(e)}", verbose=False)
                    continue

            return extracted_dfs

        except Exception as e:
            log_message(f"BeautifulSoup í…Œì´ë¸” ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}", verbose=False)

        return []

    except Exception as e:
        log_message(f"í˜ì´ì§€ì—ì„œ í…Œì´ë¸” ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")
        return []

# =============================================================================
# ë©”ì¸ ìŠ¤í¬ë˜í•‘ ë¡œì§
# =============================================================================

def scrape_bank_data(bank_name, driver, progress_manager, expected_dates):
    """ë‹¨ì¼ ì€í–‰ì˜ ë°ì´í„°ë¥¼ ìŠ¤í¬ë˜í•‘í•©ë‹ˆë‹¤."""
    log_message(f"[ì‹œì‘] {bank_name} ì€í–‰ ìŠ¤í¬ë˜í•‘ ì‹œì‘")

    try:
        # ì€í–‰ ì„ íƒ
        if not select_bank(driver, bank_name):
            log_message(f"{bank_name} ì€í–‰ ì„ íƒ ì‹¤íŒ¨")
            return None

        # í˜„ì¬ í˜ì´ì§€ URL í™•ì¸
        try:
            base_bank_url = driver.current_url
            log_message(f"{bank_name} ì€í–‰ í˜ì´ì§€ ì ‘ì† ì„±ê³µ", verbose=False)
        except Exception:
            log_message(f"{bank_name} ì€í–‰ í˜ì´ì§€ URL íšë“ ì‹¤íŒ¨")
            return None

        # ë‚ ì§œ ì •ë³´ ì¶”ì¶œ ë° ê²€ì¦
        date_info = extract_date_information(driver)
        is_fresh, validation_message = validate_extracted_date(date_info, expected_dates)
        
        # ë°ì´í„° ê²€ì¦ ê²°ê³¼ ê¸°ë¡
        progress_manager.mark_data_validated(bank_name, date_info, is_fresh)
        
        log_message(f"{bank_name} ì€í–‰ ë‚ ì§œ ê²€ì¦: {validation_message}")

        result_data = {
            'ë‚ ì§œì •ë³´': date_info,
            'ê²€ì¦ê²°ê³¼': validation_message,
            'ì‹ ì„ ë„': is_fresh
        }
        
        all_table_hashes = set()

        # ê° ì¹´í…Œê³ ë¦¬ ì²˜ë¦¬
        for category in CATEGORIES:
            try:
                # ì¹´í…Œê³ ë¦¬ íƒ­ í´ë¦­
                if not select_category(driver, category):
                    log_message(f"{bank_name} ì€í–‰ {category} íƒ­ í´ë¦­ ì‹¤íŒ¨, ë‹¤ìŒ ì¹´í…Œê³ ë¦¬ë¡œ ì§„í–‰")
                    continue

                # í…Œì´ë¸” ì¶”ì¶œ
                tables = extract_tables_from_page(driver)
                if not tables:
                    log_message(f"{bank_name} ì€í–‰ {category} ì¹´í…Œê³ ë¦¬ì—ì„œ í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    continue

                # ì¤‘ë³µ ì œê±°ëœ ìœ íš¨ í…Œì´ë¸” ì €ì¥
                valid_tables = []
                for df in tables:
                    try:
                        # í…Œì´ë¸” í•´ì‹œ ìƒì„± (ì „ì—­ ì¤‘ë³µ í™•ì¸ìš©)
                        df_hash = hash(str(df.shape) + str(list(df.columns)) + str(df.iloc[0].values) if len(df) > 0 else "")
                        
                        if df_hash not in all_table_hashes:
                            valid_tables.append(df)
                            all_table_hashes.add(df_hash)
                    except Exception:
                        valid_tables.append(df)

                # ìœ íš¨í•œ í…Œì´ë¸” ì €ì¥
                if valid_tables:
                    result_data[category] = valid_tables
                    log_message(f"{bank_name} ì€í–‰ {category} ì¹´í…Œê³ ë¦¬ì—ì„œ {len(valid_tables)}ê°œ í…Œì´ë¸” ì¶”ì¶œ")

            except Exception as e:
                log_message(f"{bank_name} ì€í–‰ {category} ì¹´í…Œê³ ë¦¬ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")

        # ë°ì´í„° ìˆ˜ì§‘ ì—¬ë¶€ í™•ì¸
        table_categories = [key for key, data in result_data.items() 
                          if key not in ['ë‚ ì§œì •ë³´', 'ê²€ì¦ê²°ê³¼', 'ì‹ ì„ ë„'] and isinstance(data, list) and data]
        
        if not table_categories:
            log_message(f"{bank_name} ì€í–‰ì—ì„œ í…Œì´ë¸” ë°ì´í„°ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None

        log_message(f"[ì™„ë£Œ] {bank_name} ì€í–‰ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ (ì¹´í…Œê³ ë¦¬: {', '.join(table_categories)})")
        return result_data

    except Exception as e:
        log_message(f"{bank_name} ì€í–‰ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

def save_bank_data(bank_name, data_dict):
    """ìˆ˜ì§‘ëœ ì€í–‰ ë°ì´í„°ë¥¼ ì—‘ì…€ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
    if not data_dict:
        return False

    try:
        # íŒŒì¼ëª… ìƒì„± (ë‚ ì§œ ì •ë³´ í¬í•¨)
        date_info = data_dict.get('ë‚ ì§œì •ë³´', 'ë‚ ì§œì •ë³´ì—†ìŒ')
        safe_date_info = re.sub(r'[^\w\-_ë…„ì›”ë§]', '_', date_info)
        excel_path = os.path.join(OUTPUT_DIR, f"{bank_name}_{safe_date_info}.xlsx")

        with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:
            # ê³µì‹œ ì •ë³´ ì‹œíŠ¸ ìƒì„±
            info_data = {
                'ì€í–‰ëª…': [bank_name],
                'ê³µì‹œ ë‚ ì§œ': [data_dict.get('ë‚ ì§œì •ë³´', '')],
                'ê²€ì¦ ê²°ê³¼': [data_dict.get('ê²€ì¦ê²°ê³¼', '')],
                'ë°ì´í„° ì‹ ì„ ë„': ['ìµœì‹ ' if data_dict.get('ì‹ ì„ ë„', False) else 'êµ¬ë²„ì „'],
                'ì¶”ì¶œ ì¼ì‹œ': [datetime.now().strftime("%Y-%m-%d %H:%M:%S")],
                'ìŠ¤í¬ë˜í•‘ ì‹œìŠ¤í…œ': ['GitHub Actions ì €ì¶•ì€í–‰ ìŠ¤í¬ë˜í¼ v1.0']
            }
            info_df = pd.DataFrame(info_data)
            info_df.to_excel(writer, sheet_name='ê³µì‹œì •ë³´', index=False)

            # ê° ì¹´í…Œê³ ë¦¬ë³„ ë°ì´í„° ì €ì¥
            for category, tables in data_dict.items():
                if category in ['ë‚ ì§œì •ë³´', 'ê²€ì¦ê²°ê³¼', 'ì‹ ì„ ë„'] or not isinstance(tables, list):
                    continue

                # ê° ì¹´í…Œê³ ë¦¬ì˜ í…Œì´ë¸”ì„ ë³„ë„ ì‹œíŠ¸ë¡œ ì €ì¥
                for i, df in enumerate(tables):
                    # ì‹œíŠ¸ëª… ìƒì„± (ì—‘ì…€ ì‹œíŠ¸ëª… ì œí•œ: 31ì)
                    if i == 0:
                        sheet_name = category[:31]
                    else:
                        sheet_name = f"{category}_{i+1}"[:31]

                    # MultiIndex ì»¬ëŸ¼ ì²˜ë¦¬
                    if isinstance(df.columns, pd.MultiIndex):
                        new_cols = []
                        for col in df.columns:
                            if isinstance(col, tuple):
                                col_parts = [str(c).strip() for c in col if str(c).strip() and str(c).lower() != 'nan']
                                new_cols.append('_'.join(col_parts) if col_parts else f"Column_{len(new_cols)+1}")
                            else:
                                new_cols.append(str(col))
                        df.columns = new_cols

                    # ë°ì´í„°í”„ë ˆì„ ì €ì¥
                    try:
                        df.to_excel(writer, sheet_name=sheet_name, index=False)
                        log_message(f"{bank_name} - {sheet_name} ì‹œíŠ¸ ì €ì¥ ì™„ë£Œ", verbose=False)
                    except Exception as e:
                        log_message(f"{bank_name} - {sheet_name} ì‹œíŠ¸ ì €ì¥ ì‹¤íŒ¨: {str(e)}")

        log_message(f"{bank_name} ì€í–‰ ë°ì´í„° ì €ì¥ ì™„ë£Œ: {excel_path}")
        return True

    except Exception as e:
        log_message(f"{bank_name} ì€í–‰ ë°ì´í„° ì €ì¥ ì˜¤ë¥˜: {str(e)}")
        return False

def worker_process_bank(bank_name, driver_manager, progress_manager, expected_dates):
    """ì›Œì»¤ ìŠ¤ë ˆë“œì—ì„œ ì€í–‰ ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
    driver = None
    
    try:
        driver = driver_manager.get_driver()
        
        # ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ë§Œí¼ ì‹œë„
        for attempt in range(MAX_RETRIES):
            try:
                # ì€í–‰ ë°ì´í„° ìŠ¤í¬ë˜í•‘
                result_data = scrape_bank_data(bank_name, driver, progress_manager, expected_dates)

                if result_data:
                    # ë°ì´í„° ì €ì¥
                    if save_bank_data(bank_name, result_data):
                        progress_manager.mark_completed(bank_name)
                        return bank_name, True, result_data.get('ê²€ì¦ê²°ê³¼', '')
                    else:
                        if attempt < MAX_RETRIES - 1:
                            log_message(f"{bank_name} ì€í–‰ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨, ì¬ì‹œë„ {attempt+1}/{MAX_RETRIES}...")
                            WaitUtils.wait_with_random(2, 4)
                        else:
                            log_message(f"{bank_name} ì€í–‰ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨, ìµœëŒ€ ì‹œë„ íšŸìˆ˜ ì´ˆê³¼")
                else:
                    if attempt < MAX_RETRIES - 1:
                        log_message(f"{bank_name} ì€í–‰ ë°ì´í„° ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨, ì¬ì‹œë„ {attempt+1}/{MAX_RETRIES}...")
                        WaitUtils.wait_with_random(2, 4)
                    else:
                        log_message(f"{bank_name} ì€í–‰ ë°ì´í„° ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨, ìµœëŒ€ ì‹œë„ íšŸìˆ˜ ì´ˆê³¼")

            except Exception as e:
                if attempt < MAX_RETRIES - 1:
                    log_message(f"{bank_name} ì€í–‰ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}, ì¬ì‹œë„ {attempt+1}/{MAX_RETRIES}...")
                    WaitUtils.wait_with_random(2, 4)
                else:
                    log_message(f"{bank_name} ì€í–‰ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}, ìµœëŒ€ ì‹œë„ íšŸìˆ˜ ì´ˆê³¼")

        # ëª¨ë“  ì‹œë„ ì‹¤íŒ¨
        progress_manager.mark_failed(bank_name)
        return bank_name, False, "ëª¨ë“  ì‹œë„ ì‹¤íŒ¨"

    except Exception as e:
        log_message(f"{bank_name} ì€í–‰ ì²˜ë¦¬ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}")
        progress_manager.mark_failed(bank_name)
        return bank_name, False, f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}"
    
    finally:
        if driver and driver_manager:
            driver_manager.return_driver(driver)

# =============================================================================
# ë¹„ë™ê¸° ì²˜ë¦¬ ë° ë©”ì¸ ì‹¤í–‰ ë¡œì§
# =============================================================================

async def process_banks_async(banks, driver_manager, progress_manager, expected_dates):
    """ì€í–‰ ëª©ë¡ì„ ë³‘ë ¬ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
    log_message(f"ë³‘ë ¬ ì²˜ë¦¬ ì‹œì‘: {len(banks)}ê°œ ì€í–‰, {MAX_WORKERS}ê°œ ì›Œì»¤")
    
    all_results = []
    
    # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±)
    batch_size = max(1, len(banks) // MAX_WORKERS) if len(banks) > MAX_WORKERS else len(banks)
    bank_batches = [banks[i:i + batch_size] for i in range(0, len(banks), batch_size)]

    for batch_idx, batch in enumerate(bank_batches):
        log_message(f"ë°°ì¹˜ {batch_idx+1}/{len(bank_batches)} ì²˜ë¦¬ ì¤‘ ({len(batch)}ê°œ ì€í–‰)")
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=min(MAX_WORKERS, len(batch))) as executor:
            # ë¹„ë™ê¸° ì‘ì—… ìƒì„±
            loop = asyncio.get_event_loop()
            futures = [
                loop.run_in_executor(
                    executor,
                    worker_process_bank,
                    bank,
                    driver_manager,
                    progress_manager,
                    expected_dates
                )
                for bank in batch
            ]

            # ì§„í–‰ë¥  í‘œì‹œ
            progress_desc = f"ë°°ì¹˜ {batch_idx+1}/{len(bank_batches)}"
            progress_bar = tqdm(asyncio.as_completed(futures), total=len(futures), desc=progress_desc)

            # ê²°ê³¼ ìˆ˜ì§‘
            batch_results = []
            for future in progress_bar:
                result = await future
                batch_results.append(result)
                
                # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
                success_count = len([r for r in batch_results if r[1]])
                progress_bar.set_postfix_str(f"ì™„ë£Œ: {success_count}/{len(batch_results)}")

            all_results.extend(batch_results)
            
            # ë°°ì¹˜ ê°„ íœ´ì‹
            if batch_idx < len(bank_batches) - 1:
                log_message(f"ë°°ì¹˜ {batch_idx+1} ì™„ë£Œ. ë‹¤ìŒ ë°°ì¹˜ ì „ ì ì‹œ ëŒ€ê¸°...")
                await asyncio.sleep(2)

    return all_results

def process_with_retry(banks, max_retries=1):
    """ì‹¤íŒ¨í•œ ì€í–‰ì„ ì¬ì‹œë„í•˜ëŠ” ë¡œì§ì„ í¬í•¨í•œ ë©”ì¸ ì²˜ë¦¬ í•¨ìˆ˜ì…ë‹ˆë‹¤."""
    # ì˜ˆìƒ ë°ì´í„° ë‚ ì§œ ê²€ì¦
    expected_dates = validate_data_freshness()
    
    # ë§¤ë‹ˆì € ì´ˆê¸°í™”
    driver_manager = DriverManager(max_drivers=MAX_WORKERS)
    progress_manager = ProgressManager()

    # ì²˜ë¦¬í•  ì€í–‰ ëª©ë¡ ê²°ì •
    pending_banks = progress_manager.get_pending_banks(banks)
    if not pending_banks:
        log_message("ëª¨ë“  ì€í–‰ ì²˜ë¦¬ ì™„ë£Œ! ì¼ë¶€ ì€í–‰ì„ ì¬ê²€ì¦í•©ë‹ˆë‹¤.")
        pending_banks = banks[:min(5, len(banks))]  # ê²€ì¦ìš©ìœ¼ë¡œ ì†Œìˆ˜ë§Œ ì¬ì²˜ë¦¬

    log_message(f"ì²˜ë¦¬í•  ì€í–‰ ìˆ˜: {len(pending_banks)}/{len(banks)}")

    try:
        # ë¹„ë™ê¸° ì´ë²¤íŠ¸ ë£¨í”„ ì‹¤í–‰
        if sys.version_info >= (3, 7):
            results = asyncio.run(process_banks_async(pending_banks, driver_manager, progress_manager, expected_dates))
        else:
            loop = asyncio.get_event_loop()
            results = loop.run_until_complete(process_banks_async(pending_banks, driver_manager, progress_manager, expected_dates))

        # ê²°ê³¼ ë¶„ì„
        successful_banks = [r[0] for r in results if r[1]]
        failed_banks = [r[0] for r in results if not r[1]]

        # ì‹¤íŒ¨í•œ ì€í–‰ ì¬ì‹œë„
        retry_count = 0
        while failed_banks and retry_count < max_retries:
            retry_count += 1
            log_message(f"ì¬ì‹œë„ {retry_count}/{max_retries}: {len(failed_banks)}ê°œ ì€í–‰ ì²˜ë¦¬ ì¤‘...")

            # ì¬ì‹œë„ ì‹¤í–‰
            if sys.version_info >= (3, 7):
                retry_results = asyncio.run(process_banks_async(failed_banks, driver_manager, progress_manager, expected_dates))
            else:
                loop = asyncio.get_event_loop()
                retry_results = loop.run_until_complete(process_banks_async(failed_banks, driver_manager, progress_manager, expected_dates))

            # ê²°ê³¼ ê°±ì‹ 
            newly_successful = [r[0] for r in retry_results if r[1]]
            failed_banks = [r[0] for r in retry_results if not r[1]]

            successful_banks.extend(newly_successful)
            log_message(f"ì¬ì‹œë„ {retry_count} ê²°ê³¼: {len(newly_successful)}ê°œ ì„±ê³µ, {len(failed_banks)}ê°œ ì‹¤íŒ¨")

        return successful_banks, failed_banks, results

    finally:
        # ë“œë¼ì´ë²„ ì •ë¦¬
        driver_manager.close_all()

def collect_bank_details():
    """ê° ì€í–‰ë³„ ìƒì„¸ ì •ë³´ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤."""
    bank_details = []
    progress_manager = ProgressManager()
    
    try:
        # ì§„í–‰ ìƒí™©ì—ì„œ ê²€ì¦ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        validation_data = progress_manager.progress.get('data_validation', [])
        validation_dict = {item['bank_name']: item for item in validation_data}
        
        for bank in BANKS:
            bank_info = {
                'name': bank,
                'status': 'failed',
                'date_info': 'ë°ì´í„° ì—†ìŒ',
                'is_fresh': False,
                'categories': [],
                'error_reason': 'ì²˜ë¦¬ë˜ì§€ ì•ŠìŒ'
            }
            
            # ê° ì€í–‰ì˜ ì—‘ì…€ íŒŒì¼ ì°¾ê¸°
            bank_files = [f for f in os.listdir(OUTPUT_DIR) if f.startswith(f"{bank}_") and f.endswith(".xlsx")]
            
            if bank_files:
                try:
                    # ê°€ì¥ ìµœê·¼ íŒŒì¼ ì„ íƒ
                    latest_file = sorted(bank_files)[-1]
                    file_path = os.path.join(OUTPUT_DIR, latest_file)
                    
                    # ì—‘ì…€ íŒŒì¼ ë¶„ì„
                    xls = pd.ExcelFile(file_path)
                    
                    # ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ
                    categories = []
                    for sheet in xls.sheet_names:
                        if sheet != 'ê³µì‹œì •ë³´':
                            category = sheet.split('_')[0] if '_' in sheet else sheet
                            categories.append(category)
                    
                    categories = sorted(list(set(categories)))
                    bank_info['categories'] = categories
                    
                    # ê³µì‹œ ì •ë³´ì—ì„œ ìƒì„¸ ë°ì´í„° ì¶”ì¶œ
                    if 'ê³µì‹œì •ë³´' in xls.sheet_names:
                        info_df = pd.read_excel(file_path, sheet_name='ê³µì‹œì •ë³´')
                        if 'ê³µì‹œ ë‚ ì§œ' in info_df.columns and not info_df['ê³µì‹œ ë‚ ì§œ'].empty:
                            bank_info['date_info'] = str(info_df['ê³µì‹œ ë‚ ì§œ'].iloc[0])
                        if 'ë°ì´í„° ì‹ ì„ ë„' in info_df.columns and not info_df['ë°ì´í„° ì‹ ì„ ë„'].empty:
                            bank_info['is_fresh'] = str(info_df['ë°ì´í„° ì‹ ì„ ë„'].iloc[0]) == 'ìµœì‹ '
                    
                    # ìƒíƒœ ê²°ì •
                    if set(categories) >= set(CATEGORIES):
                        bank_info['status'] = 'success'
                    elif categories:
                        bank_info['status'] = 'partial'
                        bank_info['error_reason'] = f"ëˆ„ë½ëœ ì¹´í…Œê³ ë¦¬: {', '.join(set(CATEGORIES) - set(categories))}"
                    else:
                        bank_info['status'] = 'failed'
                        bank_info['error_reason'] = 'í…Œì´ë¸” ì¶”ì¶œ ì‹¤íŒ¨'
                        
                except Exception as e:
                    bank_info['error_reason'] = f'íŒŒì¼ ë¶„ì„ ì˜¤ë¥˜: {str(e)}'
            else:
                # ê²€ì¦ ë°ì´í„°ì—ì„œ ì •ë³´ ì¶”ì¶œ ì‹œë„
                if bank in validation_dict:
                    validation_info = validation_dict[bank]
                    bank_info['date_info'] = validation_info.get('date_info', 'ë‚ ì§œ ì •ë³´ ì—†ìŒ')
                    bank_info['is_fresh'] = validation_info.get('is_fresh', False)
                    bank_info['error_reason'] = 'ë°ì´í„° ì¶”ì¶œ ì™„ë£Œë˜ì—ˆìœ¼ë‚˜ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨'
                else:
                    bank_info['error_reason'] = 'ì€í–‰ í˜ì´ì§€ ì ‘ê·¼ ì‹¤íŒ¨'
            
            bank_details.append(bank_info)
        
        return bank_details
        
    except Exception as e:
        log_message(f"ì€í–‰ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}")
        return []
    """ìŠ¤í¬ë˜í•‘ ê²°ê³¼ ìš”ì•½ ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    try:
        progress_manager = ProgressManager()
        completed_banks = progress_manager.progress.get('completed', [])
        failed_banks = progress_manager.progress.get('failed', [])
        validation_data = progress_manager.progress.get('data_validation', [])

        # ì€í–‰ë³„ ë°ì´í„° ìš”ì•½
        bank_summary = []
        validation_dict = {item['bank_name']: item for item in validation_data}

        for bank in BANKS:
            # ê° ì€í–‰ì˜ ì—‘ì…€ íŒŒì¼ ì°¾ê¸°
            bank_files = [f for f in os.listdir(OUTPUT_DIR) if f.startswith(f"{bank}_") and f.endswith(".xlsx")]

            if bank_files:
                try:
                    # ê°€ì¥ ìµœê·¼ íŒŒì¼ ì„ íƒ
                    latest_file = sorted(bank_files)[-1]
                    file_path = os.path.join(OUTPUT_DIR, latest_file)

                    # ì—‘ì…€ íŒŒì¼ ë¶„ì„
                    xls = pd.ExcelFile(file_path)
                    sheet_count = len(xls.sheet_names)

                    # ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ
                    categories = []
                    for sheet in xls.sheet_names:
                        if sheet != 'ê³µì‹œì •ë³´':
                            category = sheet.split('_')[0] if '_' in sheet else sheet
                            categories.append(category)

                    categories = sorted(list(set(categories)))

                    # ê³µì‹œ ì •ë³´ì—ì„œ ë‚ ì§œ ë° ê²€ì¦ ê²°ê³¼ ì¶”ì¶œ
                    date_info = "ë‚ ì§œ ì •ë³´ ì—†ìŒ"
                    validation_result = "ê²€ì¦ ì—†ìŒ"
                    data_freshness = "ì•Œ ìˆ˜ ì—†ìŒ"
                    
                    if 'ê³µì‹œì •ë³´' in xls.sheet_names:
                        info_df = pd.read_excel(file_path, sheet_name='ê³µì‹œì •ë³´')
                        if 'ê³µì‹œ ë‚ ì§œ' in info_df.columns and not info_df['ê³µì‹œ ë‚ ì§œ'].empty:
                            date_info = str(info_df['ê³µì‹œ ë‚ ì§œ'].iloc[0])
                        if 'ê²€ì¦ ê²°ê³¼' in info_df.columns and not info_df['ê²€ì¦ ê²°ê³¼'].empty:
                            validation_result = str(info_df['ê²€ì¦ ê²°ê³¼'].iloc[0])
                        if 'ë°ì´í„° ì‹ ì„ ë„' in info_df.columns and not info_df['ë°ì´í„° ì‹ ì„ ë„'].empty:
                            data_freshness = str(info_df['ë°ì´í„° ì‹ ì„ ë„'].iloc[0])

                    # ìƒíƒœ ê²°ì •
                    status = 'ì™„ë£Œ' if set(categories) >= set(CATEGORIES) else 'ë¶€ë¶„ ì™„ë£Œ'

                    bank_summary.append({
                        'ì€í–‰ëª…': bank,
                        'ìŠ¤í¬ë˜í•‘ ìƒíƒœ': status,
                        'ê³µì‹œ ë‚ ì§œ': date_info,
                        'ë°ì´í„° ì‹ ì„ ë„': data_freshness,
                        'ê²€ì¦ ê²°ê³¼': validation_result,
                        'ì‹œíŠ¸ ìˆ˜': sheet_count - 1,  # ê³µì‹œì •ë³´ ì‹œíŠ¸ ì œì™¸
                        'ìŠ¤í¬ë˜í•‘ëœ ì¹´í…Œê³ ë¦¬': ', '.join(categories)
                    })
                    
                except Exception as e:
                    bank_summary.append({
                        'ì€í–‰ëª…': bank,
                        'ìŠ¤í¬ë˜í•‘ ìƒíƒœ': 'íŒŒì¼ ì†ìƒ',
                        'ê³µì‹œ ë‚ ì§œ': 'í™•ì¸ ë¶ˆê°€',
                        'ë°ì´í„° ì‹ ì„ ë„': 'í™•ì¸ ë¶ˆê°€',
                        'ê²€ì¦ ê²°ê³¼': f'ì˜¤ë¥˜: {str(e)}',
                        'ì‹œíŠ¸ ìˆ˜': 'í™•ì¸ ë¶ˆê°€',
                        'ìŠ¤í¬ë˜í•‘ëœ ì¹´í…Œê³ ë¦¬': ''
                    })
            else:
                status = 'ì‹¤íŒ¨' if bank in failed_banks else 'ë¯¸ì²˜ë¦¬'
                validation_info = validation_dict.get(bank, {})
                
                bank_summary.append({
                    'ì€í–‰ëª…': bank,
                    'ìŠ¤í¬ë˜í•‘ ìƒíƒœ': status,
                    'ê³µì‹œ ë‚ ì§œ': validation_info.get('date_info', ''),
                    'ë°ì´í„° ì‹ ì„ ë„': 'ìµœì‹ ' if validation_info.get('is_fresh', False) else 'êµ¬ë²„ì „',
                    'ê²€ì¦ ê²°ê³¼': 'ê²€ì¦ ì™„ë£Œ' if bank in validation_dict else 'ê²€ì¦ ì•ˆë¨',
                    'ì‹œíŠ¸ ìˆ˜': 0,
                    'ìŠ¤í¬ë˜í•‘ëœ ì¹´í…Œê³ ë¦¬': ''
                })

        # ìš”ì•½ DataFrame ìƒì„± ë° ì •ë ¬
        summary_df = pd.DataFrame(bank_summary)
        status_order = {'ì™„ë£Œ': 0, 'ë¶€ë¶„ ì™„ë£Œ': 1, 'íŒŒì¼ ì†ìƒ': 2, 'ì‹¤íŒ¨': 3, 'ë¯¸ì²˜ë¦¬': 4}
        summary_df['ìƒíƒœìˆœì„œ'] = summary_df['ìŠ¤í¬ë˜í•‘ ìƒíƒœ'].map(status_order)
        summary_df = summary_df.sort_values(['ìƒíƒœìˆœì„œ', 'ì€í–‰ëª…']).drop('ìƒíƒœìˆœì„œ', axis=1)

        # ìš”ì•½ íŒŒì¼ ì €ì¥
        summary_file = os.path.join(OUTPUT_DIR, f"ìŠ¤í¬ë˜í•‘_ìš”ì•½_{TODAY}.xlsx")
        summary_df.to_excel(summary_file, index=False)

        # í†µê³„ ì •ë³´ ê³„ì‚°
        stats = {
            'ì „ì²´ ì€í–‰ ìˆ˜': len(BANKS),
            'ì™„ë£Œ ì€í–‰ ìˆ˜': len([r for r in bank_summary if r['ìŠ¤í¬ë˜í•‘ ìƒíƒœ'] == 'ì™„ë£Œ']),
            'ë¶€ë¶„ ì™„ë£Œ ì€í–‰ ìˆ˜': len([r for r in bank_summary if r['ìŠ¤í¬ë˜í•‘ ìƒíƒœ'] == 'ë¶€ë¶„ ì™„ë£Œ']),
            'ì‹¤íŒ¨ ì€í–‰ ìˆ˜': len([r for r in bank_summary if r['ìŠ¤í¬ë˜í•‘ ìƒíƒœ'] in ['ì‹¤íŒ¨', 'íŒŒì¼ ì†ìƒ']]),
            'ìµœì‹  ë°ì´í„° ì€í–‰ ìˆ˜': len([r for r in bank_summary if r['ë°ì´í„° ì‹ ì„ ë„'] == 'ìµœì‹ ']),
            'ì„±ê³µë¥ ': f"{len([r for r in bank_summary if r['ìŠ¤í¬ë˜í•‘ ìƒíƒœ'] in ['ì™„ë£Œ', 'ë¶€ë¶„ ì™„ë£Œ']]) / len(BANKS) * 100:.2f}%"
        }

        log_message("\n===== ìŠ¤í¬ë˜í•‘ ê²°ê³¼ ìš”ì•½ =====")
        for key, value in stats.items():
            log_message(f"{key}: {value}")

        log_message(f"ìš”ì•½ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {summary_file}")
        return summary_file, stats

    except Exception as e:
        log_message(f"ìš”ì•½ ë³´ê³ ì„œ ìƒì„± ì˜¤ë¥˜: {str(e)}")
        return None, {}

def create_zip_archive():
    """ê²°ê³¼ íŒŒì¼ë“¤ì„ ZIPìœ¼ë¡œ ì••ì¶•í•©ë‹ˆë‹¤."""
    try:
        zip_filename = f'ì €ì¶•ì€í–‰_ë°ì´í„°_{TODAY}.zip'
        zip_path = os.path.join(OUTPUT_BASE_DIR, zip_filename)
        
        with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
            # OUTPUT_DIR ë‚´ì˜ ëª¨ë“  íŒŒì¼ì„ ZIPì— ì¶”ê°€
            for root, dirs, files in os.walk(OUTPUT_DIR):
                for file in files:
                    file_path = os.path.join(root, file)
                    # ZIP ë‚´ì—ì„œì˜ ìƒëŒ€ ê²½ë¡œ ê³„ì‚°
                    arcname = os.path.relpath(file_path, OUTPUT_BASE_DIR)
                    zipf.write(file_path, arcname)
        
        log_message(f"ZIP ì•„ì¹´ì´ë¸Œ ìƒì„± ì™„ë£Œ: {zip_path}")
        return zip_path
        
    except Exception as e:
        log_message(f"ZIP ì•„ì¹´ì´ë¸Œ ìƒì„± ì‹¤íŒ¨: {str(e)}")
        return None

# =============================================================================
# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
# =============================================================================

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # ë¡œê·¸ íŒŒì¼ ì´ˆê¸°í™”
    try:
        with open(LOG_FILE, 'w', encoding='utf-8') as f:
            f.write("")
    except Exception as e:
        print(f"ë¡œê·¸ íŒŒì¼ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

    start_time = time.time()
    log_message(f"\n===== ì €ì¶•ì€í–‰ ì¤‘ì•™íšŒ í†µì¼ê²½ì˜ê³µì‹œ ë°ì´í„° ìŠ¤í¬ë˜í•‘ ì‹œì‘ (GitHub Actions ë²„ì „) [{TODAY}] =====\n")

    try:
        # í™˜ê²½ ì„¤ì • ë¡œê·¸
        log_message(f"ì„¤ì •ê°’:")
        log_message(f"- ìµœëŒ€ ì›Œì»¤ ìˆ˜: {MAX_WORKERS}")
        log_message(f"- ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜: {MAX_RETRIES}")
        log_message(f"- í˜ì´ì§€ ë¡œë“œ íƒ€ì„ì•„ì›ƒ: {PAGE_LOAD_TIMEOUT}ì´ˆ")
        log_message(f"- ëŒ€ê¸° íƒ€ì„ì•„ì›ƒ: {WAIT_TIMEOUT}ì´ˆ")
        log_message(f"- ì¶œë ¥ ë””ë ‰í† ë¦¬: {OUTPUT_DIR}")
        log_message(f"- ì´ë©”ì¼ ì•Œë¦¼: {'í™œì„±í™”' if GMAIL_ADDRESS and GMAIL_APP_PASSWORD else 'ë¹„í™œì„±í™”'}")

        # ì€í–‰ ì²˜ë¦¬ ì‹¤í–‰
        successful_banks, failed_banks, all_results = process_with_retry(BANKS, max_retries=MAX_RETRIES)

        # ê²°ê³¼ ìš”ì•½ ìƒì„±
        summary_file, stats = generate_summary_report()

        # ZIP ì•„ì¹´ì´ë¸Œ ìƒì„±
        zip_file = create_zip_archive()

        # ì‹¤í–‰ ì‹œê°„ ê³„ì‚°
        end_time = time.time()
        total_duration = end_time - start_time
        minutes, seconds = divmod(total_duration, 60)
        
        # ìµœì¢… ê²°ê³¼ ë¡œê·¸
        log_message(f"\n===== ìŠ¤í¬ë˜í•‘ ì™„ë£Œ =====")
        log_message(f"ì´ ì‹¤í–‰ ì‹œê°„: {int(minutes)}ë¶„ {int(seconds)}ì´ˆ")
        log_message(f"ì„±ê³µí•œ ì€í–‰: {len(successful_banks)}ê°œ")
        log_message(f"ì‹¤íŒ¨í•œ ì€í–‰: {len(failed_banks)}ê°œ")
        
        if failed_banks:
            log_message(f"ì‹¤íŒ¨í•œ ì€í–‰ ëª©ë¡: {', '.join(failed_banks)}")

        # ì´ë©”ì¼ ì•Œë¦¼ ë°œì†¡
        if GMAIL_ADDRESS and GMAIL_APP_PASSWORD and RECIPIENT_EMAILS:
            # ì€í–‰ë³„ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘
            bank_details = collect_bank_details()
            
            subject = f"ì €ì¶•ì€í–‰ ë°ì´í„° ìŠ¤í¬ë˜í•‘ {'ì™„ë£Œ' if not failed_banks else 'ë¶€ë¶„ì™„ë£Œ'} - {TODAY}"
            
            body = f"""ì €ì¶•ì€í–‰ ì¤‘ì•™íšŒ í†µì¼ê²½ì˜ê³µì‹œ ë°ì´í„° ìŠ¤í¬ë˜í•‘ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.

ì‹¤í–‰ ì •ë³´:
- ì‹¤í–‰ ë‚ ì§œ: {datetime.now().strftime('%Yë…„ %mì›” %dì¼ %Hì‹œ %Më¶„')}
- ì´ ì‹¤í–‰ ì‹œê°„: {int(minutes)}ë¶„ {int(seconds)}ì´ˆ
- ì²˜ë¦¬ í™˜ê²½: GitHub Actions

ê²°ê³¼ ìš”ì•½:
- ì „ì²´ ì€í–‰ ìˆ˜: {stats.get('ì „ì²´ ì€í–‰ ìˆ˜', len(BANKS))}ê°œ
- ì™„ë£Œ ì€í–‰ ìˆ˜: {stats.get('ì™„ë£Œ ì€í–‰ ìˆ˜', len(successful_banks))}ê°œ
- ë¶€ë¶„ ì™„ë£Œ ì€í–‰ ìˆ˜: {stats.get('ë¶€ë¶„ ì™„ë£Œ ì€í–‰ ìˆ˜', 0)}ê°œ
- ì‹¤íŒ¨ ì€í–‰ ìˆ˜: {stats.get('ì‹¤íŒ¨ ì€í–‰ ìˆ˜', len(failed_banks))}ê°œ
- ìµœì‹  ë°ì´í„° ì€í–‰ ìˆ˜: {stats.get('ìµœì‹  ë°ì´í„° ì€í–‰ ìˆ˜', 0)}ê°œ
- ì„±ê³µë¥ : {stats.get('ì„±ê³µë¥ ', '0.00%')}

ì²¨ë¶€ íŒŒì¼:
- ëª¨ë“  ì€í–‰ ë°ì´í„° (ZIP ì••ì¶•íŒŒì¼)
- ìš”ì•½ ë³´ê³ ì„œ (Excel)
- ì‹¤í–‰ ë¡œê·¸ íŒŒì¼
"""

            # ì²¨ë¶€ íŒŒì¼ ì¤€ë¹„ (ZIP íŒŒì¼ ìš°ì„ )
            attachments = []
            if zip_file and os.path.exists(zip_file):
                attachments.append(zip_file)
            if summary_file and os.path.exists(summary_file):
                attachments.append(summary_file)
            if os.path.exists(LOG_FILE):
                attachments.append(LOG_FILE)

            # ì´ë©”ì¼ ë°œì†¡
            is_success = len(failed_banks) == 0
            send_email_notification(subject, body, bank_details, attachments, is_success)

        log_message(f"\n===== ì €ì¶•ì€í–‰ ì¤‘ì•™íšŒ í†µì¼ê²½ì˜ê³µì‹œ ë°ì´í„° ìŠ¤í¬ë˜í•‘ ì™„ë£Œ [{TODAY}] =====")

    except KeyboardInterrupt:
        log_message("\nì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        log_message(f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        log_message(traceback.format_exc())
        
        # ì˜¤ë¥˜ ë°œìƒ ì‹œì—ë„ ì´ë©”ì¼ ì•Œë¦¼ ë°œì†¡
        if GMAIL_ADDRESS and GMAIL_APP_PASSWORD and RECIPIENT_EMAILS:
            error_subject = f"ì €ì¶•ì€í–‰ ë°ì´í„° ìŠ¤í¬ë˜í•‘ ì˜¤ë¥˜ ë°œìƒ - {TODAY}"
            error_body = f"""ì €ì¶•ì€í–‰ ë°ì´í„° ìŠ¤í¬ë˜í•‘ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.

ì˜¤ë¥˜ ì •ë³´:
- ë°œìƒ ì‹œê°„: {datetime.now().strftime('%Yë…„ %mì›” %dì¼ %Hì‹œ %Më¶„')}
- ì˜¤ë¥˜ ë‚´ìš©: {str(e)}

ìì„¸í•œ ë‚´ìš©ì€ ì²¨ë¶€ëœ ë¡œê·¸ íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.
"""
            attachments = [LOG_FILE] if os.path.exists(LOG_FILE) else []
            send_email_notification(error_subject, error_body, attachments, False)

if __name__ == "__main__":
    main()
