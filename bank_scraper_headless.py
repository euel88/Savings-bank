# bank_scraper_headless_improved.py
"""
ì €ì¶•ì€í–‰ ì¤‘ì•™íšŒ í†µì¼ê²½ì˜ê³µì‹œ ë°ì´í„° ìë™ ìŠ¤í¬ë˜í•‘ ë„êµ¬ (ê°œì„  ë²„ì „)
ëª©ì : GitHub Actionsì—ì„œ ìë™ ì‹¤í–‰, ì¹´í…Œê³ ë¦¬ë³„ ë°ì´í„° ì¤‘ë³µ ë°©ì§€, ì„±ëŠ¥ ìµœì í™”
ì‘ì„±ì¼: 2025-03-31 (ìµœì¢… ìˆ˜ì •ì¼: 2025-05-28)
ê°œì„ ì‚¬í•­:
- ì¹´í…Œê³ ë¦¬ë³„ ë°ì´í„° ì¤‘ë³µ ëˆ„ì  ë¬¸ì œ í•´ê²°
- í˜ì´ì§€ ìƒíƒœ ì´ˆê¸°í™” ë¡œì§ ì¶”ê°€
- ë‚ ì§œ ì¶”ì¶œ ë¡œì§ ê°•í™”
- ì„±ëŠ¥ ìµœì í™” (íƒ€ì„ì•„ì›ƒ ì¡°ì •, ë¶ˆí•„ìš”í•œ ëŒ€ê¸° ì œê±°)
"""

import os
import sys
import time
import random
import json
import re
import asyncio
import concurrent.futures
import zipfile
from datetime import datetime, date, timedelta
import calendar
from io import StringIO
import argparse
import logging
from pathlib import Path
import queue
import traceback
from typing import Union, Dict, Tuple

# ì´ë©”ì¼ ì „ì†¡ ê´€ë ¨ ì„í¬íŠ¸
import smtplib
from email.mime.multipart import MIMEMultipart
from email.mime.text import MIMEText
from email.mime.base import MIMEBase
from email import encoders

# Selenium ê´€ë ¨ ì„í¬íŠ¸
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import WebDriverException, TimeoutException, NoSuchElementException, StaleElementReferenceException
from selenium.webdriver.chrome.options import Options

# ë°ì´í„° ì²˜ë¦¬ ê´€ë ¨ ì„í¬íŠ¸
from bs4 import BeautifulSoup
import pandas as pd
from tqdm import tqdm
import warnings
warnings.filterwarnings("ignore")

# --- ë¡œê¹… ì„¤ì • ---
def setup_logging(log_file_path, log_level="INFO"):
    for handler in logging.root.handlers[:]: logging.root.removeHandler(handler)
    logging.basicConfig(
        level=getattr(logging, log_level.upper(), logging.INFO),
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S',
        handlers=[logging.StreamHandler(sys.stdout), logging.FileHandler(log_file_path, encoding='utf-8')]
    )
    logging.getLogger('selenium.webdriver.remote.remote_connection').setLevel(logging.WARNING)
    logging.getLogger('urllib3.connectionpool').setLevel(logging.WARNING)
    return logging.getLogger(__name__)

logger = None

# --- ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ---
def normalize_datestr_for_comparison(datestr: str) -> Union[str, None]:
    if not datestr or datestr in ["ë‚ ì§œ ì •ë³´ ì—†ìŒ", "ë‚ ì§œ ì¶”ì¶œ ì‹¤íŒ¨"]: return None 
    match = re.search(r'(\d{4})ë…„\s*(\d{1,2})ì›”ë§', datestr)
    if match: return f"{int(match.group(1))}ë…„{int(match.group(2))}ì›”ë§"
    if logger: logger.warning(f"ë‚ ì§œ ë¬¸ìì—´ ì •ê·œí™” ì‹¤íŒ¨(íŒ¨í„´ ë¶ˆì¼ì¹˜): '{datestr}'")
    return "ì•Œ ìˆ˜ ì—†ëŠ” í˜•ì‹"

def get_quarter_string_from_period(period_str: str) -> str:
    if not period_str or not isinstance(period_str, str): return "ë¶„ê¸°ì •ë³´ ë¶ˆëª…í™•"
    match = re.search(r'(\d{4})ë…„(\d{1,2})ì›”ë§', period_str)
    if match:
        year, month = match.group(1), int(match.group(2))
        q_map = {3: "1ë¶„ê¸°", 6: "2ë¶„ê¸°", 9: "3ë¶„ê¸°", 12: "4ë¶„ê¸°"}
        return f"{year}ë…„ {q_map.get(month, f'{month}ì›”')}"
    return period_str

# --- ë‚ ì§œ ê²€ì¦ í´ë˜ìŠ¤ ---
class DateVerifier:
    def get_last_weekday(self, year: int, month: int) -> date:
        _, last_day_num = calendar.monthrange(year, month)
        d = date(year, month, last_day_num)
        while d.weekday() >= 5: d -= timedelta(days=1)
        return d
    
    def get_relevant_disclosure_periods(self, current_processing_date: date) -> Dict[str, str]:
        year = current_processing_date.year
        lw_may_curr = self.get_last_weekday(year, 5)
        lw_aug_curr = self.get_last_weekday(year, 8)
        lw_nov_curr = self.get_last_weekday(year, 11)
        res = {"latest_due_period": "ê²°ì • ë¶ˆê°€", "latest_due_reason": "", "next_imminent_period": "ê²°ì • ë¶ˆê°€", "next_imminent_reason": ""}
        base_reason = f"í˜„ì¬ ì²˜ë¦¬ì¼ì {current_processing_date} ê¸°ì¤€"
        if current_processing_date >= lw_nov_curr:
            res["latest_due_period"] = f"{year}ë…„9ì›”ë§"
            res["latest_due_reason"] = f"{base_reason}: {year}ë…„ 11ì›” ë§ˆì§€ë§‰ í‰ì¼({lw_nov_curr}) ì´í›„ì´ë¯€ë¡œ {res['latest_due_period']} ë°ì´í„°ê°€ ê³µì‹ì ìœ¼ë¡œ ìµœì‹ ì´ì–´ì•¼ í•¨."
        elif current_processing_date >= lw_aug_curr:
            res["latest_due_period"] = f"{year}ë…„6ì›”ë§"
            res["latest_due_reason"] = f"{base_reason}: {year}ë…„ 8ì›” ë§ˆì§€ë§‰ í‰ì¼({lw_aug_curr}) ì´í›„ì´ë¯€ë¡œ {res['latest_due_period']} ë°ì´í„°ê°€ ê³µì‹ì ìœ¼ë¡œ ìµœì‹ ì´ì–´ì•¼ í•¨."
        elif current_processing_date >= lw_may_curr:
            res["latest_due_period"] = f"{year}ë…„3ì›”ë§"
            res["latest_due_reason"] = f"{base_reason}: {year}ë…„ 5ì›” ë§ˆì§€ë§‰ í‰ì¼({lw_may_curr}) ì´í›„ì´ë¯€ë¡œ {res['latest_due_period']} ë°ì´í„°ê°€ ê³µì‹ì ìœ¼ë¡œ ìµœì‹ ì´ì–´ì•¼ í•¨."
        else:
            res["latest_due_period"] = f"{year-1}ë…„9ì›”ë§"
            res["latest_due_reason"] = f"{base_reason}: {year}ë…„ 5ì›” ë§ˆì§€ë§‰ í‰ì¼({lw_may_curr}) ì´ì „ì´ë¯€ë¡œ ì „ë…„ë„ ê¸°ì¤€ ì ìš©, {res['latest_due_period']} ë°ì´í„°ê°€ ê³µì‹ì ìœ¼ë¡œ ìµœì‹ ì´ì–´ì•¼ í•¨."
        if current_processing_date <= lw_may_curr:
            res["next_imminent_period"] = f"{year}ë…„3ì›”ë§"
            res["next_imminent_reason"] = f"{base_reason}: {year}ë…„ 5ì›” ë§ˆì§€ë§‰ í‰ì¼({lw_may_curr})ê¹Œì§€ {res['next_imminent_period']} ìë£Œ ì—…ë¡œë“œ ê¸°ê°„/ì„ë°•."
        elif current_processing_date <= lw_aug_curr:
            res["next_imminent_period"] = f"{year}ë…„6ì›”ë§"
            res["next_imminent_reason"] = f"{base_reason}: {year}ë…„ 8ì›” ë§ˆì§€ë§‰ í‰ì¼({lw_aug_curr})ê¹Œì§€ {res['next_imminent_period']} ìë£Œ ì—…ë¡œë“œ ê¸°ê°„/ì„ë°•."
        elif current_processing_date <= lw_nov_curr:
            res["next_imminent_period"] = f"{year}ë…„9ì›”ë§"
            res["next_imminent_reason"] = f"{base_reason}: {year}ë…„ 11ì›” ë§ˆì§€ë§‰ í‰ì¼({lw_nov_curr})ê¹Œì§€ {res['next_imminent_period']} ìë£Œ ì—…ë¡œë“œ ê¸°ê°„/ì„ë°•."
        else: 
            res["next_imminent_period"] = f"{year+1}ë…„3ì›”ë§"
            res["next_imminent_reason"] = f"{base_reason}: {year}ë…„ 11ì›” ë§ˆì§€ë§‰ í‰ì¼({lw_nov_curr}) ì´í›„ì´ë¯€ë¡œ, ë‹¤ìŒ ëŒ€ìƒì€ {res['next_imminent_period']} (ì—…ë¡œë“œ: {year+1}ë…„ 5ì›” ë§ˆì§€ë§‰ í‰ì¼)."
        return res

# --- ì´ë©”ì¼ ì „ì†¡ í´ë˜ìŠ¤ ---
class EmailSender:
    def __init__(self):
        self.smtp_server = "smtp.gmail.com"; self.smtp_port = 587
        self.sender_email = os.getenv('GMAIL_ADDRESS'); self.sender_password = os.getenv('GMAIL_APP_PASSWORD')
        self.recipient_emails = [e.strip() for e in os.getenv('RECIPIENT_EMAILS', '').split(',') if e.strip()]
        self.enabled = bool(self.sender_email and self.sender_password and self.recipient_emails)
        log_msg = "ì´ë©”ì¼ ì„¤ì • ìœ íš¨X. ì „ì†¡X." if not self.enabled else f"ì´ë©”ì¼ ì„¤ì •OK. ìˆ˜ì‹ ì: {self.recipient_emails}"
        if logger: (logger.warning if not self.enabled else logger.info)(log_msg)
    
    def send_email_with_attachment(self, subject, body, attachment_path=None):
        if not self.enabled:
            if logger: logger.info("ì´ë©”ì¼ ì „ì†¡ ë¹„í™œì„±í™”ë¨."); return False
        try:
            msg = MIMEMultipart(); msg['From'] = self.sender_email; msg['To'] = ', '.join(self.recipient_emails); msg['Subject'] = subject
            msg.attach(MIMEText(body, 'html', 'utf-8'))
            if attachment_path and Path(attachment_path).exists():
                p_attach = Path(attachment_path)
                if p_attach.suffix.lower() == '.zip': part = MIMEBase('application', 'zip')
                elif p_attach.suffix.lower() == '.xlsx': part = MIMEBase('application', 'vnd.openxmlformats-officedocument.spreadsheetml.sheet')
                else: part = MIMEBase('application', 'octet-stream')
                with open(p_attach, 'rb') as af: part.set_payload(af.read())
                encoders.encode_base64(part)
                base_filename = p_attach.name
                try: part.add_header('Content-Disposition', 'attachment', filename=encoders.encode_rfc2231(base_filename))
                except: part.add_header('Content-Disposition', f'attachment; filename="{base_filename}"')
                msg.attach(part)
                if logger: logger.info(f"ì²¨ë¶€íŒŒì¼ ì¶”ê°€: {p_attach.name} (Type: {part.get_content_type()})")
            with smtplib.SMTP(self.smtp_server, self.smtp_port) as server:
                server.ehlo(); server.starttls(); server.ehlo()
                server.login(self.sender_email, self.sender_password); server.send_message(msg)
            if logger: logger.info(f"ì´ë©”ì¼ ì „ì†¡ ì„±ê³µ: {self.recipient_emails}"); return True
        except Exception as e:
            if logger: logger.error(f"ì´ë©”ì¼ ì „ì†¡ ì‹¤íŒ¨: {e}", exc_info=True); return False
        return False

# --- ì„¤ì • í´ë˜ìŠ¤ ---
class Config:
    def __init__(self):
        self.VERSION = "2.11.0-improved" 
        self.BASE_URL = "https://www.fsb.or.kr/busmagequar_0100.act"
        self.MAX_RETRIES = int(os.getenv('MAX_RETRIES', '2')) 
        # êµ¬ê¸€ ì½”ë© ìˆ˜ì¤€ì˜ ì„±ëŠ¥ ì„¤ì • ìœ ì§€
        self.PAGE_LOAD_TIMEOUT = int(os.getenv('PAGE_LOAD_TIMEOUT', '8'))
        self.WAIT_TIMEOUT = int(os.getenv('WAIT_TIMEOUT', '4'))
        self.MAX_WORKERS = int(os.getenv('MAX_WORKERS', '5'))

        self.today = datetime.now().strftime("%Y%m%d")
        self.output_dir_base = Path(os.getenv('OUTPUT_DIR', "./output"))
        self.output_dir = self.output_dir_base / f"ì €ì¶•ì€í–‰_ë°ì´í„°_{self.today}"
        self.output_dir.mkdir(parents=True, exist_ok=True)

        self.progress_file = self.output_dir / 'progress.json'
        self.log_file_path = self.output_dir / f'scraping_log_{self.today}.log'

        global logger
        if logger is None: 
            logger = setup_logging(self.log_file_path, os.getenv('LOG_LEVEL', 'INFO'))
        
        try: self.processing_date_kst = datetime.now().date() 
        except Exception as e: logger.error(f"KST ë‚ ì§œ ì–»ê¸° ì‹¤íŒ¨: {e}. UTCë¡œ ëŒ€ì²´."); self.processing_date_kst = datetime.utcnow().date()

        self.date_verifier = DateVerifier()
        self.date_expectations = self.date_verifier.get_relevant_disclosure_periods(self.processing_date_kst)
        self.latest_due_period = self.date_expectations["latest_due_period"]
        self.next_imminent_period = self.date_expectations["next_imminent_period"]

        self.BANKS = [
            "ë‹¤ì˜¬", "ëŒ€ì‹ ", "ë”ì¼€ì´", "ë¯¼êµ­", "ë°”ë¡œ", "ìŠ¤ì¹´ì´", "ì‹ í•œ", "ì• íì˜¨", "ì˜ˆê°€ëŒ", "ì›°ì»´", "ìœ ì•ˆíƒ€", "ì¡°ì€", "í‚¤ì›€YES", "í‘¸ë¥¸", "í•˜ë‚˜", "DB", "HB", "JT", "ì¹œì• ", "KB", "NH", "OK", "OSB", "SBI", "ê¸ˆí™”", "ë‚¨ì–‘", "ëª¨ì•„", "ë¶€ë¦¼", "ì‚¼ì •", "ìƒìƒì¸", "ì„¸ëŒ", "ì•ˆêµ­", "ì•ˆì–‘", "ì˜ì§„", "ìœµì°½", "ì¸ì„±", "ì¸ì²œ", "í‚¤ì›€", "í˜í¼", "í‰íƒ", "í•œêµ­íˆ¬ì", "í•œí™”", "ê³ ë ¤", "êµ­ì œ", "ë™ì›ì œì¼", "ì†”ë¸Œë ˆì¸", "ì—ìŠ¤ì•¤í‹°", "ìš°ë¦¬", "ì¡°í¥", "ì§„ì£¼", "í¥êµ­", "BNK", "DH", "IBK", "ëŒ€ë°±", "ëŒ€ì•„", "ëŒ€ì›", "ë“œë¦¼", "ë¼ì˜¨", "ë¨¸ìŠ¤íŠ¸ì‚¼ì¼", "ì— ì—ìŠ¤", "ì˜¤ì„±", "ìœ ë‹ˆì˜¨", "ì°¸", "CK", "ëŒ€í•œ", "ë”ë¸”", "ë™ì–‘", "ì‚¼í˜¸", "ì„¼íŠ¸ëŸ´", "ìŠ¤ë§ˆíŠ¸", "ìŠ¤íƒ€", "ëŒ€ëª…", "ìƒìƒì¸í”ŒëŸ¬ìŠ¤", "ì•„ì‚°", "ì˜¤íˆ¬", "ìš°ë¦¬ê¸ˆìœµ", "ì²­ì£¼", "í•œì„±"
        ]
        self.CATEGORIES = ["ì˜ì—…ê°œí™©", "ì¬ë¬´í˜„í™©", "ì†ìµí˜„í™©", "ê¸°íƒ€"]
        
        logger.info(f"--- ì„¤ì • ì´ˆê¸°í™” (v{self.VERSION}) ---")
        logger.info(f"ì²˜ë¦¬ì¼ì(KST ê°€ì •): {self.processing_date_kst}")
        logger.info(f"ì˜ˆìƒ (ê¸°í•œ ì§€ë‚œ) ìµœì‹  ê³µì‹œì¼: '{self.latest_due_period}' (ê·¼ê±°: {self.date_expectations['latest_due_reason']})")
        logger.info(f"ì˜ˆìƒ (ë‹¤ìŒ/í˜„ì¬) ê³µì‹œì¼: '{self.next_imminent_period}' (ê·¼ê±°: {self.date_expectations['next_imminent_reason']})")

# --- DriverManager ---
class DriverManager:
    def __init__(self, config):
        self.config = config; self.driver_pool = queue.Queue(maxsize=self.config.MAX_WORKERS); self._initialize_pool()
    
    def _create_new_driver(self):
        logger.debug("ìƒˆ WebDriver ìƒì„±..."); options = Options()
        options.add_argument('--headless'); options.add_argument('--no-sandbox'); options.add_argument('--disable-dev-shm-usage')
        options.add_argument('--disable-gpu'); options.add_argument('--window-size=1920,1080')
        options.add_argument('user-agent=Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
        options.add_argument('--disable-extensions'); options.add_argument('--disable-browser-side-navigation')
        options.add_argument('--disable-infobars'); options.add_argument('--disable-notifications')
        options.add_argument('--disable-popup-blocking'); options.add_argument('--blink-settings=imagesEnabled=false')
        options.add_experimental_option('excludeSwitches', ['enable-logging', 'enable-automation']); options.add_experimental_option('useAutomationExtension', False)
        try:
            driver = webdriver.Chrome(options=options); driver.set_page_load_timeout(self.config.PAGE_LOAD_TIMEOUT)
            logger.debug("ìƒˆ WebDriver ìƒì„± ì™„ë£Œ."); return driver
        except WebDriverException as e:
            logger.error(f"WebDriver ìƒì„± ì‹¤íŒ¨: {e}", exc_info=True)
            if any(s in str(e).lower() for s in ["executable needs to be in path", "unable to find driver", "cannot find chrome binary"]):
                logger.error(f"WebDriverException: ChromeDriver/Chrome ê²½ë¡œ ë¬¸ì œ ì¶”ì •. PATH: {os.getenv('PATH')}")
            raise
        except Exception as e: logger.error(f"WebDriver ìƒì„± ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}", exc_info=True); raise
    
    def _initialize_pool(self):
        logger.info(f"ë“œë¼ì´ë²„ í’€ ì´ˆê¸°í™” ì‹œì‘ (ìµœëŒ€ {self.config.MAX_WORKERS}ê°œ)...")
        for i in range(self.config.MAX_WORKERS):
            try: self.driver_pool.put_nowait(self._create_new_driver())
            except queue.Full: logger.warning(f"ë“œë¼ì´ë²„ {i+1} ì¶”ê°€ ì¤‘ í’€ ê½‰ ì°¸."); break 
            except Exception as e: logger.error(f"ì´ˆê¸° ë“œë¼ì´ë²„ {i+1} ìƒì„± ì‹¤íŒ¨ ({type(e).__name__}).")
        logger.info(f"ë“œë¼ì´ë²„ í’€ ì´ˆê¸°í™” ì™„ë£Œ. ì‚¬ìš© ê°€ëŠ¥: {self.driver_pool.qsize()}ê°œ.")
    
    def get_driver(self):
        try: return self.driver_pool.get(block=True, timeout=30)
        except queue.Empty: raise TimeoutError(f"30ì´ˆ ëŒ€ê¸° í›„ì—ë„ í’€ì—ì„œ ë“œë¼ì´ë²„ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í•¨ (MAX_WORKERS: {self.config.MAX_WORKERS}).")
    
    def return_driver(self, driver): 
        if not driver: return
        returned = False
        try:
            _ = driver.title 
            if self.driver_pool.qsize() < self.config.MAX_WORKERS: self.driver_pool.put_nowait(driver); returned = True
            else: logger.warning(f"í’€({self.driver_pool.qsize()}) ê½‰ ì°¸, ë°˜í™˜ ë“œë¼ì´ë²„ ì¢…ë£Œ."); driver.quit()
        except queue.Full: logger.warning(f"ë°˜ë‚© ì‹œ í’€ ê½‰ ì°¸. ë“œë¼ì´ë²„ ì¢…ë£Œ."); driver.quit()
        except Exception as e:
            logger.warning(f"ì†ìƒëœ ë“œë¼ì´ë²„ ë°˜í™˜ ì‹œë„ ({type(e).__name__}). ë“œë¼ì´ë²„ ì¢…ë£Œ.")
            try: driver.quit()
            except: pass 
            if not returned: self._add_new_driver_to_pool_if_needed()
    
    def _add_new_driver_to_pool_if_needed(self): 
        if self.driver_pool.qsize() < self.config.MAX_WORKERS:
            try: logger.info("ì†ìƒ ë“œë¼ì´ë²„ ëŒ€ì²´ìš© ìƒˆ ë“œë¼ì´ë²„ ìƒì„±..."); self.driver_pool.put_nowait(self._create_new_driver())
            except Exception as e: logger.error(f"ëŒ€ì²´ ë“œë¼ì´ë²„ ìƒì„±/ì¶”ê°€ ì‹¤íŒ¨: {e}", exc_info=True)
    
    def quit_all(self): 
        logger.info("ëª¨ë“  ë“œë¼ì´ë²„ ì¢…ë£Œ ì‹œì‘..."); drained = 0
        while not self.driver_pool.empty():
            try: driver = self.driver_pool.get_nowait(); driver.quit(); drained += 1
            except: break 
        logger.info(f"ì´ {drained}ê°œ ë“œë¼ì´ë²„ ì¢…ë£Œ ì‹œë„ ì™„ë£Œ.")

class ProgressManager:
    def __init__(self, config):
        self.config=config; self.progress_file_path=config.progress_file; self.progress=self._load()
    
    def _load(self):
        default = {'banks': {}, 'stats': {'last_run':None,'success_count':0,'failure_count':0}}
        if self.progress_file_path.exists():
            try:
                with open(self.progress_file_path,'r',encoding='utf-8') as f:
                    loaded=json.load(f)
                    if 'banks' not in loaded: loaded['banks']={}
                    if 'stats' not in loaded: loaded['stats']=default['stats']
                    return loaded
            except Exception as e: logger.warning(f"ì§„í–‰ íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜({self.progress_file_path}): {e}. ìƒˆë¡œ ì‹œì‘.")
        return default
    
    def save(self):
        self.progress['stats']['last_run']=datetime.now().isoformat(); s,f=0,0
        for info in self.progress.get('banks',{}).values():
            if info.get('status')=='completed': s+=1
            elif info.get('status')=='failed': f+=1
        self.progress['stats']['success_count']=s; self.progress['stats']['failure_count']=f
        try:
            with open(self.progress_file_path,'w',encoding='utf-8') as fo: json.dump(self.progress,fo,ensure_ascii=False,indent=2)
        except Exception as e: logger.error(f"ì§„í–‰ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}",exc_info=True)
    
    def mark_completed(self,bank_name,date_info):
        self.progress.setdefault('banks',{})[bank_name]={'status':'completed','date_info':date_info}; self.save()
    
    def mark_failed(self,bank_name):
        data=self.progress.setdefault('banks',{}).get(bank_name,{}); data['status']='failed'
        self.progress['banks'][bank_name]=data; self.save()
    
    def get_pending_banks(self):
        processed=self.progress.get('banks',{}); pending=[b for b in self.config.BANKS if b not in processed or processed[b].get('status')!='completed']
        logger.info(f"ë³´ë¥˜ ì€í–‰(ì¬ì‹œë„ í¬í•¨ ê°€ëŠ¥): {len(pending)}ê°œ"); return pending
    
    def get_bank_data(self,bank_name): return self.progress.get('banks',{}).get(bank_name)

# --- ìŠ¤í¬ë˜í¼ í´ë˜ìŠ¤ (ê°œì„ ë¨) ---
class BankScraper:
    def __init__(self, config, driver_manager, progress_manager):
        self.config = config; self.driver_manager = driver_manager; self.progress_manager = progress_manager
        self.email_sender = EmailSender()

    def _wait_for_element(self, driver, by, value, timeout=None):
        try: return WebDriverWait(driver, timeout or self.config.WAIT_TIMEOUT).until(EC.presence_of_element_located((by, value)))
        except TimeoutException: logger.debug(f"ìš”ì†Œ ëŒ€ê¸° ì‹œê°„ ì´ˆê³¼: ({by}, {value})"); return None

    def _robust_click(self, driver, element):
        try:
            driver.execute_script("arguments[0].scrollIntoView({block: 'center', inline: 'nearest'});", element); time.sleep(0.2)
            driver.execute_script("arguments[0].click();", element); return True
        except:
            try: element.click(); return True
            except Exception as e: logger.warning(f"Robust í´ë¦­ ì‹¤íŒ¨: {e}"); return False

    def extract_date_information(self, driver):
        """ê°•í™”ëœ ë‚ ì§œ ì •ë³´ ì¶”ì¶œ ë¡œì§"""
        logger.debug(f"ë‚ ì§œ ì •ë³´ ì¶”ì¶œ ì‹œë„ (v{self.config.VERSION})...")
        try:
            # ë‹¤ì¤‘ ë°©ë²•ìœ¼ë¡œ ë‚ ì§œ ì¶”ì¶œ ì‹œë„
            js_script = """
            var allMatches = []; 
            var datePattern = /(\d{4})ë…„\s*(\d{1,2})ì›”ë§/g;
            var bodyText = document.body.innerText || ""; 
            var match; datePattern.lastIndex = 0;
            
            // ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ ë‚ ì§œ íŒ¨í„´ ì¶”ì¶œ
            while ((match = datePattern.exec(bodyText)) !== null) { 
                allMatches.push({
                    fullText: match[0], 
                    year: parseInt(match[1]), 
                    month: parseInt(match[2]),
                    source: 'body'
                });
            }
            
            // íŠ¹ì • íƒœê·¸ì—ì„œ ë‚ ì§œ íŒ¨í„´ ê²€ìƒ‰ (ìš°ì„ ìˆœìœ„ê°€ ë†’ì€ íƒœê·¸ë“¤)
            var priorityTags = [
                'h1', 'h2', 'h3', 'caption', 'th[colspan]', 'td[colspan]',
                '.title', '.date', '#publishDate', '.disclosure-date',
                'span[class*="date"]', 'div[class*="date"]'
            ];
            
            for (var i = 0; i < priorityTags.length; i++) {
                var elements;
                try { elements = document.querySelectorAll(priorityTags[i]); }
                catch(e) { elements = []; }
                
                for (var j = 0; j < elements.length; j++) {
                    var elText = elements[j].innerText || "";
                    if (elText.length > 1000) elText = elText.substring(0, 1000);
                    datePattern.lastIndex = 0;
                    
                    while ((match = datePattern.exec(elText)) !== null) {
                        var cY = parseInt(match[1]), cM = parseInt(match[2]);
                        if (!allMatches.some(m => m.year === cY && m.month === cM)) {
                            allMatches.push({
                                fullText: match[0],
                                year: cY,
                                month: cM,
                                source: priorityTags[i]
                            });
                        }
                    }
                }
            }
            
            if (allMatches.length === 0) return 'ë‚ ì§œ ì •ë³´ ì—†ìŒ';
            
            // ë‚ ì§œ í•„í„°ë§ ë° ì •ë ¬ ë¡œì§ ê°œì„ 
            var currentYear = new Date().getFullYear();
            var validDates = allMatches.filter(function(m) {
                // í•©ë¦¬ì ì¸ ë‚ ì§œ ë²”ìœ„ (í˜„ì¬ë…„ë„ ê¸°ì¤€ -10ë…„ ~ +1ë…„)
                return m.year >= (currentYear - 10) && m.year <= (currentYear + 1) && 
                       m.month >= 1 && m.month <= 12;
            });
            
            if (validDates.length > 0) {
                // ìš°ì„ ìˆœìœ„ë³„ ì •ë ¬: ìµœì‹ ë…„ë„ > ë¶„ê¸°ë³„ ì›”(12,9,6,3) > ê¸°íƒ€
                validDates.sort(function(a, b) {
                    if (a.year !== b.year) return b.year - a.year; // ìµœì‹  ë…„ë„ ìš°ì„ 
                    
                    var quarterMonths = [12, 9, 6, 3];
                    var aIsQuarter = quarterMonths.indexOf(a.month) !== -1;
                    var bIsQuarter = quarterMonths.indexOf(b.month) !== -1;
                    
                    if (aIsQuarter && !bIsQuarter) return -1;
                    if (!aIsQuarter && bIsQuarter) return 1;
                    if (aIsQuarter && bIsQuarter) {
                        return quarterMonths.indexOf(a.month) - quarterMonths.indexOf(b.month);
                    }
                    
                    return b.month - a.month; // ìµœì‹  ì›” ìš°ì„ 
                });
                
                return validDates[0].fullText.replace(/\s+/g, '');
            }
            
            // ëª¨ë“  ë§¤ì¹˜ì—ì„œ ìµœì‹  ì„ íƒ
            if (allMatches.length > 0) {
                allMatches.sort((a, b) => (b.year !== a.year) ? (b.year - a.year) : (b.month - a.month));
                return allMatches[0].fullText.replace(/\s+/g, '');
            }
            
            return 'ë‚ ì§œ ì •ë³´ ì—†ìŒ';
            """
            date_info = driver.execute_script(js_script)
            logger.debug(f"ì¶”ì¶œëœ ìµœì¢… ë‚ ì§œ ì •ë³´: '{date_info}'")
            return date_info
        except Exception as e: 
            logger.error(f"ë‚ ì§œ ì •ë³´ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)
            return "ë‚ ì§œ ì¶”ì¶œ ì‹¤íŒ¨"

    def select_bank(self, driver, bank_name):
        logger.debug(f"[{bank_name}] ì€í–‰ ì„ íƒ...")
        driver.get(self.config.BASE_URL)
        WebDriverWait(driver, self.config.PAGE_LOAD_TIMEOUT).until(lambda d: d.execute_script('return document.readyState') == 'complete')
        time.sleep(random.uniform(0.3, 0.5))
        
        for xp in [f"//td[normalize-space(.)='{bank_name}']", f"//a[normalize-space(.)='{bank_name}']"]:
            try:
                for el in driver.find_elements(By.XPATH, xp):
                    if el.is_displayed() and self._robust_click(driver, el): 
                        time.sleep(random.uniform(0.3, 0.6))
                        return True
            except: pass
        
        js = f"""
        var els = Array.from(document.querySelectorAll('a,td'));
        var t = els.find(e => e.textContent && e.textContent.trim().includes('{bank_name}'));
        if (t) {{
            t.scrollIntoView({{block:'center'}});
            (t.tagName === 'TD' && t.querySelector('a') ? t.querySelector('a') : t).click();
            return true;
        }}
        return false;
        """
        try:
            if driver.execute_script(js): 
                time.sleep(random.uniform(0.3, 0.6))
                return True
        except: pass
        
        logger.warning(f"[{bank_name}] ì€í–‰ ì„ íƒ ìµœì¢… ì‹¤íŒ¨.")
        return False

    def select_category(self, driver, category_name):
        """ì„±ëŠ¥ ìµœì í™”ëœ ì¹´í…Œê³ ë¦¬ ì„ íƒ ë¡œì§"""
        logger.debug(f"ì¹´í…Œê³ ë¦¬ ì„ íƒ: '{category_name}'")
        
        # ì½”ë© ìˆ˜ì¤€ì˜ ë¹ ë¥¸ ì²˜ë¦¬ë¥¼ ìœ„í•œ ìµœì†Œ ëŒ€ê¸°
        time.sleep(random.uniform(0.1, 0.2))
        
        cat_norm = category_name.replace(' ', '')
        
        # ë°©ë²• 1: ì •í™•í•œ í…ìŠ¤íŠ¸ ë§¤ì¹­ (ë¹ ë¥¸ ì²˜ë¦¬)
        selectors = [
            (By.XPATH, f"//a[normalize-space(translate(text(),' \t\n\r',''))='{cat_norm}']"),
            (By.LINK_TEXT, category_name),
            (By.PARTIAL_LINK_TEXT, category_name)
        ]
        
        for by_type, val in selectors:
            try:
                for el in driver.find_elements(by_type, val):
                    if el.is_displayed() and el.is_enabled() and self._robust_click(driver, el): 
                        time.sleep(random.uniform(0.2, 0.3))
                        return True
            except: pass
        
        # ë°©ë²• 2: JavaScript ê¸°ë°˜ ì„ íƒ (ë‹¨ì¼ ì‹œë„)
        js = f"""
        var els = Array.from(document.querySelectorAll('a,li,button,span,div[role="tab"]'));
        var t = els.find(e => e.textContent && e.textContent.trim().includes('{category_name}'));
        if (t) {{
            t.scrollIntoView({{block:'center'}});
            t.click();
            return true;
        }}
        return false;
        """
        try:
            if driver.execute_script(js): 
                time.sleep(random.uniform(0.2, 0.3))
                return True
        except: pass
        
        logger.warning(f"'{category_name}' ì¹´í…Œê³ ë¦¬ ì„ íƒ ì‹¤íŒ¨.")
        return False
        
    def extract_tables_from_page(self, driver):
        """ê°œì„ ëœ í…Œì´ë¸” ì¶”ì¶œ - ì¤‘ë³µ ë°©ì§€ ê°•í™”"""
        WebDriverWait(driver, self.config.PAGE_LOAD_TIMEOUT).until(lambda d: d.execute_script('return document.readyState') == 'complete')
        time.sleep(random.uniform(0.2, 0.4))
        
        try:
            src = driver.page_source
            if not src or len(src) < 300 or "<table" not in src.lower(): 
                return []
            
            dfs = pd.read_html(StringIO(src), flavor='bs4', encoding='utf-8')
            valid = []
            seen_hashes = set()
            
            for df in dfs:
                if not isinstance(df, pd.DataFrame) or df.empty: 
                    continue
                
                # ë¹ˆ í–‰/ì—´ ì œê±°
                df.dropna(axis=0, how='all', inplace=True)
                df.dropna(axis=1, how='all', inplace=True)
                
                if df.empty: 
                    continue
                
                # MultiIndex ì»¬ëŸ¼ ì²˜ë¦¬
                if isinstance(df.columns, pd.MultiIndex):
                    new_cols = []
                    for col in df.columns:
                        if isinstance(col, tuple):
                            clean_col = [str(c).strip() for c in col if str(c).strip() and str(c).lower() != 'nan']
                            new_cols.append('_'.join(clean_col) if clean_col else f"Column_{len(new_cols)+1}")
                        else:
                            new_cols.append(str(col))
                    df.columns = new_cols
                else:
                    df.columns = ['_'.join(map(str, c)).strip('_ ') if isinstance(c, tuple) else str(c).strip() for c in df.columns]
                
                # ì¤‘ë³µ ì²´í¬ë¥¼ ìœ„í•œ í•´ì‹œ ìƒì„± (ë” ì •í™•í•œ ì¤‘ë³µ ê²€ì‚¬)
                try:
                    # í…Œì´ë¸” êµ¬ì¡°ì™€ ë°ì´í„°ë¥¼ ì¢…í•©í•œ í•´ì‹œ
                    shape_str = f"{df.shape[0]}x{df.shape[1]}"
                    cols_str = "|".join(str(col) for col in df.columns)
                    
                    if len(df) > 0:
                        # ì²« ë²ˆì§¸ì™€ ë§ˆì§€ë§‰ í–‰ì˜ ë°ì´í„°ë¥¼ í•´ì‹œì— í¬í•¨
                        first_row = "|".join(str(val) for val in df.iloc[0].values)
                        last_row = "|".join(str(val) for val in df.iloc[-1].values) if len(df) > 1 else first_row
                        data_str = f"{first_row}||{last_row}"
                    else:
                        data_str = "empty"
                    
                    table_hash = f"{shape_str}#{cols_str}#{data_str}"
                    
                    if table_hash not in seen_hashes:
                        valid.append(df.reset_index(drop=True))
                        seen_hashes.add(table_hash)
                    
                except Exception as hash_error:
                    logger.debug(f"í…Œì´ë¸” í•´ì‹œ ìƒì„± ì‹¤íŒ¨, ê·¸ëŒ€ë¡œ ì¶”ê°€: {hash_error}")
                    valid.append(df.reset_index(drop=True))
            
            return valid
            
        except ValueError as ve:
            logger.debug(f"pandas í…Œì´ë¸” ì¶”ì¶œ ì‹¤íŒ¨ (ValueError): {ve}")
            return []
        except Exception as e: 
            logger.error(f"í…Œì´ë¸” ì¶”ì¶œ ì˜¤ë¥˜: {e}", exc_info=True)
            return []

    def _scrape_single_bank_attempt(self, bank_name, driver):
        """ì„±ëŠ¥ ìµœì í™”ëœ ìŠ¤í¬ë˜í•‘ ë¡œì§ - ì¹´í…Œê³ ë¦¬ ì¤‘ë³µ ë°©ì§€"""
        logger.info(f"[{bank_name}] ìŠ¤í¬ë˜í•‘ ì‹œë„...")
        
        if not self.select_bank(driver, bank_name): 
            return None
        
        # ì€í–‰ í˜ì´ì§€ ìµœì†Œ ì•ˆì •í™”
        time.sleep(0.3)
        
        date_info_scraped = self.extract_date_information(driver)
        logger.info(f"[{bank_name}] ì¶”ì¶œ ê³µì‹œì¼(ì›ë³¸): '{date_info_scraped}'")
        
        normalized_scraped_date = normalize_datestr_for_comparison(date_info_scraped)
        expected_officially_due = self.config.latest_due_period
        expected_next_imminent = self.config.next_imminent_period
        
        # ë‚ ì§œ ê²€ì¦ ë¡œì§ì€ ìœ ì§€í•˜ë˜ ë¡œê¹… ê°„ì†Œí™”
        if normalized_scraped_date == expected_officially_due:
            logger.info(f"[{bank_name}] ë‚ ì§œ ì¼ì¹˜: ê³µì‹ì  ìµœì‹ ")
        elif normalized_scraped_date == expected_next_imminent:
            logger.info(f"[{bank_name}] ë‚ ì§œ ì¼ì¹˜: ì„ ì œì  ì—…ë°ì´íŠ¸")
        elif normalized_scraped_date not in [None, "ì•Œ ìˆ˜ ì—†ëŠ” í˜•ì‹"]:
            logger.warning(f"[{bank_name}] ë‚ ì§œ ë¶ˆì¼ì¹˜: {normalized_scraped_date}")
        
        data = {
            '_INFO_': pd.DataFrame([{
                'ì€í–‰ëª…': bank_name, 
                'ê³µì‹œë‚ ì§œ': date_info_scraped, 
                'ì¶”ì¶œì¼ì‹œ': datetime.now().strftime("%Y-%m-%d %H:%M:%S"), 
                'ìŠ¤í¬ë˜í¼ë²„ì „': self.config.VERSION
            }])
        }
        
        has_data = False
        base_url = driver.current_url
        
        # ì¹´í…Œê³ ë¦¬ë³„ ë°ì´í„° ìˆ˜ì§‘ (ê° ì¹´í…Œê³ ë¦¬ë‹¹ í•˜ë‚˜ì˜ ì‹œíŠ¸)
        for cat_name in self.config.CATEGORIES:
            # ì¹´í…Œê³ ë¦¬ ë³€ê²½ì„ ìœ„í•œ í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨ (ì¤‘ë³µ ë°©ì§€ìš©)
            if has_data:  # ì²« ë²ˆì§¸ ì¹´í…Œê³ ë¦¬ê°€ ì•„ë‹Œ ê²½ìš°ë§Œ ìƒˆë¡œê³ ì¹¨
                driver.refresh()
                WebDriverWait(driver, self.config.PAGE_LOAD_TIMEOUT).until(
                    lambda d: d.execute_script('return document.readyState') == 'complete'
                )
                time.sleep(0.2)
            
            if self.select_category(driver, cat_name):
                tables = self.extract_tables_from_page(driver)
                
                if tables:
                    # ì¹´í…Œê³ ë¦¬ë³„ë¡œ ëª¨ë“  í…Œì´ë¸”ì„ í•˜ë‚˜ì˜ ì‹œíŠ¸ì— í†µí•©
                    data[cat_name] = tables  # í…Œì´ë¸” ë¦¬ìŠ¤íŠ¸ë¥¼ ì €ì¥
                    has_data = True
                    logger.debug(f"[{bank_name}] '{cat_name}': {len(tables)}ê°œ í…Œì´ë¸”")
                else:
                    logger.debug(f"[{bank_name}] '{cat_name}': í…Œì´ë¸” ì—†ìŒ")
            else:
                logger.warning(f"[{bank_name}] '{cat_name}' ì„ íƒ ì‹¤íŒ¨")
        
    def classify_table_by_content(self, df, source_category=None):
        """í…Œì´ë¸” ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ (ì•ˆì •í™”ëœ ë²„ì „)"""
        try:
            if df is None or df.empty:
                return source_category
            
            # í…Œì´ë¸”ì˜ í…ìŠ¤íŠ¸ ë‚´ìš©ì„ ì•ˆì „í•˜ê²Œ ì¶”ì¶œ
            table_text = ""
            
            # ì»¬ëŸ¼ëª… í…ìŠ¤íŠ¸ ì¶”ê°€
            try:
                if hasattr(df, 'columns') and df.columns is not None:
                    col_text = " ".join(str(col) for col in df.columns if col is not None)
                    table_text += col_text + " "
            except Exception as e:
                logger.debug(f"ì»¬ëŸ¼ëª… í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            
            # ë°ì´í„° ë‚´ìš© í…ìŠ¤íŠ¸ ì¶”ê°€ (ì²˜ìŒ 3í–‰ë§Œ ë¶„ì„í•˜ì—¬ ì„±ëŠ¥ ìµœì í™”)
            try:
                max_rows = min(3, len(df))
                for i in range(max_rows):
                    row_values = []
                    for val in df.iloc[i].values:
                        try:
                            if pd.notna(val) and val is not None:
                                row_values.append(str(val))
                        except:
                            continue
                    if row_values:
                        table_text += " ".join(row_values) + " "
            except Exception as e:
                logger.debug(f"ë°ì´í„° ë‚´ìš© í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            
            if not table_text.strip():
                return source_category
            
            table_text = table_text.lower()
            
            # ì¹´í…Œê³ ë¦¬ë³„ í‚¤ì›Œë“œ ì •ì˜ (ê°„ì†Œí™”)
            category_keywords = {
                "ì˜ì—…ê°œí™©": ["ì˜ì—…ì ", "ì§ì›", "ì í¬", "ì§€ì ", "ì„ì§ì›", "ì¡°ì§", "ì˜ì—…ë§", "ë³¸ì ", "ì í¬ìˆ˜", "ì§ì›ìˆ˜"],
                "ì¬ë¬´í˜„í™©": ["ìì‚°", "ë¶€ì±„", "ìë³¸", "ìê¸°ìë³¸", "ì´ìì‚°", "ì´ë¶€ì±„", "ëŒ€ì°¨ëŒ€ì¡°í‘œ", "ì¬ë¬´ìƒíƒœí‘œ", "í˜„ê¸ˆ", "ì˜ˆê¸ˆ", "ëŒ€ì¶œ"],
                "ì†ìµí˜„í™©": ["ìˆ˜ìµ", "ë¹„ìš©", "ì†ìµ", "ì´ìµ", "ì†ì‹¤", "ë§¤ì¶œ", "ì˜ì—…ì´ìµ", "ìˆœì´ìµ", "ì†ìµê³„ì‚°ì„œ", "ì´ììˆ˜ìµ", "ì´ìë¹„ìš©"],
                "ê¸°íƒ€": ["ê¸°íƒ€", "ë¶€ê°€ì •ë³´", "ì£¼ìš”ì‚¬í•­", "íŠ¹ê¸°ì‚¬í•­", "ê³µì‹œì‚¬í•­", "ì°¸ê³ ì‚¬í•­", "ë¹„ê³ ", "ì£¼ì„"]
            }
            
            # ê° ì¹´í…Œê³ ë¦¬ë³„ ì ìˆ˜ ê³„ì‚°
            category_scores = {}
            for category, keywords in category_keywords.items():
                score = 0
                for keyword in keywords:
                    try:
                        score += table_text.count(keyword)
                    except:
                        continue
                category_scores[category] = score
            
            # ìµœê³  ì ìˆ˜ë¥¼ ë°›ì€ ì¹´í…Œê³ ë¦¬ ì„ íƒ
            if category_scores:
                best_category = max(category_scores, key=category_scores.get)
                max_score = category_scores[best_category]
                
                # ì ìˆ˜ê°€ 1 ì´ìƒì´ë©´ ë¶„ë¥˜ ê²°ê³¼ ë°˜ì˜, ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ ì›ë˜ ì¹´í…Œê³ ë¦¬ ìœ ì§€
                if max_score >= 1:
                    return best_category
            
            return source_category
            
        except Exception as e:
            logger.warning(f"í…Œì´ë¸” ë¶„ë¥˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}, ì›ë˜ ì¹´í…Œê³ ë¦¬ ìœ ì§€")
            return source_category

    def save_bank_data(self, bank_name, excel_data_dict):
        """ì¹´í…Œê³ ë¦¬ë³„ ë‹¨ì¼ ì‹œíŠ¸ë¡œ ë°ì´í„° ì €ì¥"""
        raw_date = excel_data_dict['_INFO_']['ê³µì‹œë‚ ì§œ'].iloc[0]
        match = re.search(r'(\d{4})ë…„(\d{1,2})ì›”', raw_date)
        date_fn = f"{match.group(1)}-{int(match.group(2)):02d}" if match else re.sub(r'[^\w\-_.]', '', raw_date or "ë‚ ì§œì •ë³´ì—†ìŒ")
        excel_path = self.config.output_dir / f"{bank_name}_{date_fn}.xlsx"
        
        try:
            with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:
                # ì •ë³´ ì‹œíŠ¸ ì €ì¥
                if '_INFO_' in excel_data_dict:
                    excel_data_dict['_INFO_'].to_excel(writer, sheet_name='ì •ë³´', index=False)
                
                # ê° ì¹´í…Œê³ ë¦¬ë³„ ì‹œíŠ¸ ìƒì„± (í…Œì´ë¸” í†µí•©)
                for category_name in self.config.CATEGORIES:
                    if category_name in excel_data_dict and excel_data_dict[category_name]:
                        tables = excel_data_dict[category_name]
                        
                        if len(tables) == 1:
                            # í…Œì´ë¸”ì´ í•˜ë‚˜ì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ì €ì¥
                            tables[0].to_excel(writer, sheet_name=category_name, index=False)
                        else:
                            # ì—¬ëŸ¬ í…Œì´ë¸”ì„ í•˜ë‚˜ì˜ ì‹œíŠ¸ì— í†µí•©
                            combined_df_list = []
                            
                            for i, table in enumerate(tables):
                                # í…Œì´ë¸” ì œëª© í–‰ ì¶”ê°€ (êµ¬ë¶„ìš©)
                                if i > 0:  # ì²« ë²ˆì§¸ í…Œì´ë¸”ì´ ì•„ë‹Œ ê²½ìš°
                                    separator_row = pd.DataFrame([[''] * len(table.columns)], columns=table.columns)
                                    title_row = pd.DataFrame([[f'=== í…Œì´ë¸” {i+1} ==='] + [''] * (len(table.columns)-1)], columns=table.columns)
                                    combined_df_list.extend([separator_row, title_row])
                                
                                combined_df_list.append(table)
                            
                            # ëª¨ë“  í…Œì´ë¸”ì„ ì„¸ë¡œë¡œ ì—°ê²°
                            if combined_df_list:
                                combined_df = pd.concat(combined_df_list, ignore_index=True)
                                combined_df.to_excel(writer, sheet_name=category_name, index=False)
                
            logger.info(f"[{bank_name}] ì €ì¥ ì™„ë£Œ: {excel_path.name} (ê²½ë¡œ: {excel_path})")
            return True
        except Exception as e: 
            logger.error(f"[{bank_name}] ì €ì¥ ì‹¤íŒ¨ ({excel_path.name}): {e}", exc_info=True)
            return False

    async def worker_process_bank(self, bank_name, pbar, semaphore):
        async with semaphore:
            driver, success, date_info = None, False, (d.get('date_info') if (d:=self.progress_manager.get_bank_data(bank_name)) else None)
            try:
                driver = await asyncio.get_event_loop().run_in_executor(None, self.driver_manager.get_driver)
                if not driver: 
                    self.progress_manager.mark_failed(bank_name)
                    return bank_name, False, date_info
                
                data = None
                for attempt in range(self.config.MAX_RETRIES):
                    try:
                        data = self._scrape_single_bank_attempt(bank_name, driver)
                        if data: 
                            date_info = data['_INFO_']['ê³µì‹œë‚ ì§œ'].iloc[0]
                            break
                    except Exception as e: 
                        logger.warning(f"[{bank_name}] ì‹œë„ {attempt+1} ì¤‘ ì˜ˆì™¸: {type(e).__name__} - {e}")
                        if attempt < self.config.MAX_RETRIES-1:
                            await asyncio.get_event_loop().run_in_executor(None, self.driver_manager.return_driver, driver)
                            driver = None
                            driver = await asyncio.get_event_loop().run_in_executor(None, self.driver_manager.get_driver)
                            if not driver: 
                                logger.error(f"[{bank_name}] ì¬ì‹œë„ìš© ë“œë¼ì´ë²„ íšë“ ì‹¤íŒ¨.")
                                break
                        else: 
                            data = None
                            logger.error(f"[{bank_name}] ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨.")
                
                if data and self.save_bank_data(bank_name, data):
                    self.progress_manager.mark_completed(bank_name, date_info)
                    success = True
                else: 
                    self.progress_manager.mark_failed(bank_name)
                
                return bank_name, success, date_info
                
            except TimeoutError as te: 
                logger.error(f"[{bank_name}] ë“œë¼ì´ë²„ íšë“ íƒ€ì„ì•„ì›ƒ: {te}")
                self.progress_manager.mark_failed(bank_name)
                return bank_name, False, date_info
            except Exception as e: 
                logger.error(f"[{bank_name}] ì‘ì—…ì ì˜ˆì™¸: {type(e).__name__} - {e}", exc_info=True)
                self.progress_manager.mark_failed(bank_name)
                return bank_name, False, date_info
            finally:
                if driver: 
                    await asyncio.get_event_loop().run_in_executor(None, self.driver_manager.return_driver, driver)
                if pbar: 
                    pbar.update(1)
                logger.info(f"[{bank_name}] ì²˜ë¦¬: {'ì„±ê³µ' if success else 'ì‹¤íŒ¨'}, ê³µì‹œì¼(ì›ë³¸): {date_info or 'ë¯¸í™•ì •'}")
    
    async def run(self):
        logger.info(f"==== ìŠ¤í¬ë˜í•‘ ì‹œì‘ (v{self.config.VERSION}) ====")
        start_time = time.monotonic()
        pending_banks = self.progress_manager.get_pending_banks()
        
        if not pending_banks: 
            logger.info("ì²˜ë¦¬í•  ì€í–‰ ì—†ìŒ.")
            self.generate_summary_and_send_email()
            return
        
        logger.info(f"ì´ {len(pending_banks)}ê°œ ì€í–‰ ì²˜ë¦¬ ì˜ˆì •: {pending_banks[:3]}{'...' if len(pending_banks)>3 else ''}")
        semaphore = asyncio.Semaphore(self.config.MAX_WORKERS)
        
        with tqdm(total=len(pending_banks), desc="ì€í–‰ ìŠ¤í¬ë˜í•‘", unit="ì€í–‰", dynamic_ncols=True, smoothing=0.1) as pbar:
            tasks = [self.worker_process_bank(bank_name, pbar, semaphore) for bank_name in pending_banks]
            results = await asyncio.gather(*tasks, return_exceptions=True)
        
        processed_count = sum(1 for r in results if not isinstance(r, Exception))
        logger.info(f"asyncio.gatherë¡œ {processed_count}/{len(pending_banks)}ê°œ ì‘ì—… ë°˜í™˜ ì™„ë£Œ.")
        logger.info(f"==== ì „ì²´ ìŠ¤í¬ë˜í•‘ ì™„ë£Œ. ì†Œìš”ì‹œê°„: {time.monotonic() - start_time:.2f}ì´ˆ ====")
        self.generate_summary_and_send_email()

    def generate_summary_and_send_email(self):
        logger.info("ìš”ì•½ ë³´ê³ ì„œ ë° ì´ë©”ì¼ ìƒì„± ì‹œì‘...")
        summary_data = []
        all_banks_in_config = self.config.BANKS
        processed_banks_data = self.progress_manager.progress.get('banks', {})
        expected_officially_due = self.config.latest_due_period
        expected_next_imminent = self.config.next_imminent_period
        completed_count, failed_count = 0, 0
        failed_banks_names = []

        for bank_name_iter in all_banks_in_config:
            bank_detail = processed_banks_data.get(bank_name_iter)
            status, original_disc_date, date_match_status = 'ë¯¸ì²˜ë¦¬', '', ''
            
            if bank_detail:
                current_status = bank_detail.get('status')
                original_disc_date = bank_detail.get('date_info', '') 
                normalized_disc_date = normalize_datestr_for_comparison(original_disc_date)
                
                if current_status == 'completed':
                    status, completed_count = 'ì™„ë£Œ', completed_count + 1
                    if normalized_disc_date is None: 
                        date_match_status = "âš ï¸ ì¶”ì¶œì‹¤íŒ¨"
                    elif normalized_disc_date == "ì•Œ ìˆ˜ ì—†ëŠ” í˜•ì‹": 
                        date_match_status = f"â“ í˜•ì‹ëª¨ë¦„ ({original_disc_date})"
                    elif normalized_disc_date == expected_officially_due: 
                        date_match_status = "âœ… ì¼ì¹˜ (ê¸°í•œë‚´ ìµœì‹ )"
                    elif normalized_disc_date == expected_next_imminent: 
                        date_match_status = "ğŸŸ¢ ì¼ì¹˜ (ì˜ˆì •ë¶„ ì„ ë°˜ì˜)"
                    else: 
                        date_match_status = f"âŒ ë¶ˆì¼ì¹˜! (ì˜ˆìƒ: {expected_officially_due} ë˜ëŠ” {expected_next_imminent})"
                elif current_status == 'failed':
                    status, failed_count = 'ì‹¤íŒ¨', failed_count + 1
                    failed_banks_names.append(bank_name_iter)
                    date_match_status = "N/A (ì‹¤íŒ¨)"
            
            summary_data.append({
                'ì€í–‰ëª…': bank_name_iter, 
                'ê³µì‹œ ë‚ ì§œ(ì›ë³¸)': original_disc_date, 
                'ë‚ ì§œ í™•ì¸': date_match_status, 
                'ì²˜ë¦¬ ìƒíƒœ': status, 
                'í™•ì¸ ì‹œê°„': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            })
        
        summary_df = pd.DataFrame(summary_data)
        summary_filename = f"ìŠ¤í¬ë˜í•‘_ìš”ì•½_{self.config.today}.xlsx"
        summary_file_path = self.config.output_dir / summary_filename
        
        try: 
            summary_df.to_excel(summary_file_path, index=False)
            logger.info(f"ìš”ì•½ ë³´ê³ ì„œ: {summary_file_path}")
        except Exception as e: 
            logger.error(f"ìš”ì•½ ë³´ê³ ì„œ ì €ì¥ ì‹¤íŒ¨: {e}", exc_info=True)

        zip_filename_str = f"ì €ì¶•ì€í–‰_ë°ì´í„°_{self.config.today}.zip"
        zip_file_path_obj = self.config.output_dir_base / zip_filename_str
        
        try:
            with zipfile.ZipFile(zip_file_path_obj, 'w', zipfile.ZIP_DEFLATED) as zf:
                for f_path in self.config.output_dir.rglob('*'):
                    if f_path.is_file(): 
                        zf.write(f_path, Path(self.config.output_dir.name) / f_path.relative_to(self.config.output_dir))
            logger.info(f"ê²°ê³¼ ì••ì¶• ì™„ë£Œ: {zip_file_path_obj}")
        except Exception as e: 
            logger.error(f"ê²°ê³¼ ì••ì¶• ì‹¤íŒ¨: {e}", exc_info=True)
            zip_file_path_obj = None

        processed_attempt_count = completed_count + failed_count
        success_rate = (completed_count / processed_attempt_count * 100) if processed_attempt_count > 0 else 0
        date_for_subject = self.config.processing_date_kst.strftime("%Y.%m.%d")
        quarter_info_for_subject = get_quarter_string_from_period(expected_officially_due)
        email_subject = f"ì €ì¶•ì€í–‰ ë¶„ê¸° ê³µì‹œ ì·¨í•©_{quarter_info_for_subject} ({date_for_subject})"
        
        failed_banks_display_html = "".join(f"<li>{b}</li>" for b in failed_banks_names[:10])
        if len(failed_banks_names) > 10:
            failed_banks_display_html += f"<p>...ì™¸ {len(failed_banks_names)-10}ê°œ.</p>"
        elif not failed_banks_names:
            failed_banks_display_html = "ì—†ìŒ"
        
        body_html = f"""
        <html><head><style>
        body {{ font-family: Arial, sans-serif; margin: 20px; }}
        .summary-box {{ background-color: #f0f8ff; padding: 15px; border-radius: 5px; margin: 10px 0; }}
        .status-completed {{ color: #28a745; font-weight: bold; }}
        .status-failed {{ color: #dc3545; font-weight: bold; }}
        table {{ border-collapse: collapse; width: 100%; margin-top: 10px; }}
        th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}
        th {{ background-color: #f2f2f2; }}
        </style></head><body>
        <h2>ì €ì¶•ì€í–‰ ìŠ¤í¬ë˜í•‘ ê²°ê³¼ ({self.config.today})</h2>
        <p><strong>ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ì¼:</strong> {self.config.processing_date_kst.strftime('%Y-%m-%d')}</p>
        <p><strong>ê³µì‹ì  ìµœì‹  ì˜ˆìƒì¼:</strong> {expected_officially_due} (ê·¼ê±°: {self.config.date_expectations['latest_due_reason']})</p>
        <p><strong>ë‹¤ìŒ ì—…ë¡œë“œ ì˜ˆìƒì¼:</strong> {expected_next_imminent} (ê·¼ê±°: {self.config.date_expectations['next_imminent_reason']})</p>
        <div class="summary-box">
            <p>ì´ ëŒ€ìƒ: {len(all_banks_in_config)}ê°œ</p> 
            <p>ì²˜ë¦¬ ì‹œë„: {processed_attempt_count}ê°œ</p>
            <p><span class="status-completed">âœ… ì„±ê³µ: {completed_count}ê°œ</span></p> 
            <p><span class="status-failed">âŒ ì‹¤íŒ¨: {failed_count}ê°œ</span> (ì„±ê³µë¥ : {success_rate:.1f}%)</p>
            <p>ğŸ“‚ ë°ì´í„°: {self.config.output_dir.name} (ì••ì¶•: {zip_filename_str if zip_file_path_obj else 'ìƒì„±ì‹¤íŒ¨'})</p>
        </div>
        <h3>ì‹¤íŒ¨ ì€í–‰ (ìµœëŒ€ 10ê°œ):</h3><ul>{failed_banks_display_html}</ul>
        <p>ì„¸ë¶€ ê²°ê³¼ëŠ” ì²¨ë¶€íŒŒì¼ í™•ì¸.</p> 
        <h3>ì€í–‰ë³„ ì²˜ë¦¬ í˜„í™©:</h3>
        {summary_df.to_html(index=False, border=1, na_rep='').replace('<td>','<td style="word-break:normal;">') if not summary_df.empty else "<p>ìš”ì•½ ë°ì´í„° ì—†ìŒ.</p>"}
        <br><p><small>ìë™ ë°œì†¡ (v{self.config.VERSION})</small></p>
        </body></html>"""
        
        attachment_to_send = str(zip_file_path_obj) if zip_file_path_obj and zip_file_path_obj.exists() else (str(summary_file_path) if summary_file_path.exists() else None)
        
        if attachment_to_send and Path(attachment_to_send).name == summary_filename and zip_file_path_obj is None: 
            logger.warning("ì••ì¶• íŒŒì¼ ìƒì„± ì‹¤íŒ¨. ìš”ì•½ ë³´ê³ ì„œë§Œ ì²¨ë¶€.")
        elif not attachment_to_send: 
            logger.warning("ì••ì¶• íŒŒì¼ ë° ìš”ì•½ ë³´ê³ ì„œ ëª¨ë‘ ëˆ„ë½. ì²¨ë¶€ íŒŒì¼ ì—†ì´ ë°œì†¡.")
        
        self.email_sender.send_email_with_attachment(email_subject, body_html, attachment_to_send)

# --- ë©”ì¸ ì‹¤í–‰ ë¡œì§ ---
def main():
    config = Config() 
    driver_mgr = None 
    try:
        logger.info(f"ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰: {sys.argv[0]}")
        driver_mgr = DriverManager(config)
        progress_mgr = ProgressManager(config)
        scraper = BankScraper(config, driver_mgr, progress_mgr)
        asyncio.run(scraper.run()) 
        logger.info("ëª¨ë“  ìŠ¤í¬ë˜í•‘ ì •ìƒ ì™„ë£Œ.")
    except Exception as e:
        if logger: 
            logger.critical(f"ìµœìƒìœ„ ì˜¤ë¥˜: {e}", exc_info=True)
        else: 
            print(f"ìµœìƒìœ„ ì˜¤ë¥˜ (ë¡œê±° ë¯¸ì„¤ì •): {e}\n{traceback.format_exc()}")
        sys.exit(1) 
    finally:
        if driver_mgr: 
            driver_mgr.quit_all() 
        if logger: 
            logger.info("ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì¢…ë£Œ.")
        else: 
            print("ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì¢…ë£Œ (ë¡œê±° ë¯¸ì„¤ì •).")

if __name__ == "__main__":
    main()
