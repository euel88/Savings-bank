#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ì €ì¶•ì€í–‰ ì¤‘ì•™íšŒ í†µì¼ê²½ì˜ê³µì‹œ ë°ì´í„° ìë™ ìŠ¤í¬ë˜í•‘ ìŠ¤í¬ë¦½íŠ¸ (ì—„ê²©í•œ ë‚ ì§œ ê²€ì¦ ë²„ì „)
ëª©ì : 79ê°œ ì €ì¶•ì€í–‰ì˜ ì¬ë¬´ì •ë³´ë¥¼ ë¹ ë¥´ê³  íš¨ìœ¨ì ìœ¼ë¡œ ìŠ¤í¬ë˜í•‘
ì‘ì„±ì¼: 2025-05-29
ìˆ˜ì • ì‚¬í•­:
1. ë‚ ì§œ ì¶”ì¶œ ë¡œì§ ê°•í™”: ì˜¤ì§ 2024ë…„9ì›”ë§ ë˜ëŠ” 2025ë…„3ì›”ë§ë§Œ í—ˆìš©
2. ì´ë©”ì¼ ë³¸ë¬¸ì— ìŠ¤í¬ë¦°ìƒ· í˜•íƒœì˜ ê²°ê³¼ í…Œì´ë¸” í¬í•¨
3. ì˜ëª»ëœ ë‚ ì§œ ì™„ì „ ë°°ì œ ë¡œì§ ì¶”ê°€
"""

import os
import sys
import time
import random
import json
import re
import asyncio
import concurrent.futures
import smtplib
import zipfile
from datetime import datetime, timedelta
from dateutil.relativedelta import relativedelta
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from email.mime.base import MIMEBase
from email import encoders
from io import StringIO
from tqdm import tqdm
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException, StaleElementReferenceException
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from bs4 import BeautifulSoup
import pandas as pd

# =============================================================================
# ì„¤ì • ë° ìƒìˆ˜
# =============================================================================

TODAY = datetime.now().strftime("%Y%m%d")
BASE_URL = "https://www.fsb.or.kr/busmagequar_0100.act"
MAX_RETRIES = int(os.getenv('MAX_RETRIES', '2'))
PAGE_LOAD_TIMEOUT = int(os.getenv('PAGE_LOAD_TIMEOUT', '25'))
WAIT_TIMEOUT = int(os.getenv('WAIT_TIMEOUT', '15'))
MAX_WORKERS = int(os.getenv('MAX_WORKERS', '2'))

OUTPUT_BASE_DIR = os.getenv('OUTPUT_DIR', './output')
OUTPUT_DIR = os.path.join(OUTPUT_BASE_DIR, f'ì €ì¶•ì€í–‰_ë°ì´í„°_{TODAY}')

GMAIL_ADDRESS = os.getenv('GMAIL_ADDRESS')
GMAIL_APP_PASSWORD = os.getenv('GMAIL_APP_PASSWORD')
RECIPIENT_EMAILS = os.getenv('RECIPIENT_EMAILS', '').split(',') if os.getenv('RECIPIENT_EMAILS') else []

BANKS = [
    "ë‹¤ì˜¬", "ëŒ€ì‹ ", "ë”ì¼€ì´", "ë¯¼êµ­", "ë°”ë¡œ", "ìŠ¤ì¹´ì´", "ì‹ í•œ", "ì• íì˜¨", "ì˜ˆê°€ëŒ", "ì›°ì»´",
    "ìœ ì•ˆíƒ€", "ì¡°ì€", "í‚¤ì›€YES", "í‘¸ë¥¸", "í•˜ë‚˜", "DB", "HB", "JT", "ì¹œì• ", "KB",
    "NH", "OK", "OSB", "SBI", "ê¸ˆí™”", "ë‚¨ì–‘", "ëª¨ì•„", "ë¶€ë¦¼", "ì‚¼ì •", "ìƒìƒì¸",
    "ì„¸ëŒ", "ì•ˆêµ­", "ì•ˆì–‘", "ì˜ì§„", "ìœµì°½", "ì¸ì„±", "ì¸ì²œ", "í‚¤ì›€", "í˜í¼", "í‰íƒ",
    "í•œêµ­íˆ¬ì", "í•œí™”", "ê³ ë ¤", "êµ­ì œ", "ë™ì›ì œì¼", "ì†”ë¸Œë ˆì¸", "ì—ìŠ¤ì•¤í‹°", "ìš°ë¦¬", "ì¡°í¥", "ì§„ì£¼",
    "í¥êµ­", "BNK", "DH", "IBK", "ëŒ€ë°±", "ëŒ€ì•„", "ëŒ€ì›", "ë“œë¦¼", "ë¼ì˜¨", "ë¨¸ìŠ¤íŠ¸ì‚¼ì¼",
    "ì— ì—ìŠ¤", "ì˜¤ì„±", "ìœ ë‹ˆì˜¨", "ì°¸", "CK", "ëŒ€í•œ", "ë”ë¸”", "ë™ì–‘", "ì‚¼í˜¸",
    "ì„¼íŠ¸ëŸ´", "ìŠ¤ë§ˆíŠ¸", "ìŠ¤íƒ€", "ëŒ€ëª…", "ìƒìƒì¸í”ŒëŸ¬ìŠ¤", "ì•„ì‚°", "ì˜¤íˆ¬", "ìš°ë¦¬ê¸ˆìœµ", "ì²­ì£¼", "í•œì„±"
]

CATEGORIES = ["ì˜ì—…ê°œí™©", "ì¬ë¬´í˜„í™©", "ì†ìµí˜„í™©", "ê¸°íƒ€"]

# í—ˆìš©ë˜ëŠ” ë‚ ì§œ íŒ¨í„´ (2025ë…„ 5ì›” 29ì¼ ê¸°ì¤€)
ALLOWED_DATE_PATTERNS = [
    "2024ë…„9ì›”ë§", "2024ë…„09ì›”ë§", "2024ë…„ 9ì›”ë§", "2024ë…„ 09ì›”ë§",
    "2025ë…„3ì›”ë§", "2025ë…„03ì›”ë§", "2025ë…„ 3ì›”ë§", "2025ë…„ 03ì›”ë§"
]

# ì •ê·œí™”ëœ í—ˆìš© ë‚ ì§œ (ê³µë°± ì œê±°)
NORMALIZED_ALLOWED_DATES = [re.sub(r'\s+', '', pattern) for pattern in ALLOWED_DATE_PATTERNS]

PROGRESS_FILE = os.path.join(OUTPUT_DIR, 'bank_scraping_progress.json')
LOG_FILE = os.path.join(OUTPUT_DIR, f'scraping_log_{TODAY}.log')

os.makedirs(OUTPUT_DIR, exist_ok=True)

# =============================================================================
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
# =============================================================================

def log_message(message, print_to_console=True, verbose=True):
    """ë¡œê·¸ ë©”ì‹œì§€ë¥¼ íŒŒì¼ì— ê¸°ë¡í•˜ê³  í•„ìš”í•œ ê²½ìš° ì½˜ì†”ì— ì¶œë ¥í•©ë‹ˆë‹¤."""
    if not verbose:
        return

    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    log_entry = f"[{timestamp}] {message}"

    try:
        with open(LOG_FILE, 'a', encoding='utf-8') as f:
            f.write(log_entry + '\n')
    except Exception as e:
        print(f"ë¡œê·¸ íŒŒì¼ ì“°ê¸° ì‹¤íŒ¨: {e}")

    if print_to_console:
        print(message)

def validate_data_freshness():
    """í˜„ì¬ ë‚ ì§œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì˜ˆìƒë˜ëŠ” ìµœì‹  ë°ì´í„° ë¶„ê¸°ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
    # 2025ë…„ 5ì›” 29ì¼ ê¸°ì¤€ìœ¼ë¡œ ê³ ì •ëœ ì˜ˆìƒ ë‚ ì§œ ë°˜í™˜
    expected_dates = ["2024ë…„9ì›”ë§", "2025ë…„3ì›”ë§"]
    log_message(f"í˜„ì¬ ë‚ ì§œ: {datetime.now().strftime('%Yë…„ %mì›” %dì¼')}")
    log_message(f"í—ˆìš©ë˜ëŠ” ë°ì´í„° ë¶„ê¸°: {', '.join(expected_dates)}")
    return expected_dates

def is_date_allowed(date_string):
    """ì£¼ì–´ì§„ ë‚ ì§œ ë¬¸ìì—´ì´ í—ˆìš©ë˜ëŠ” ë‚ ì§œì¸ì§€ ì—„ê²©í•˜ê²Œ ê²€ì¦í•©ë‹ˆë‹¤."""
    if not date_string:
        return False
    
    # ê³µë°±ì„ ì œê±°í•˜ì—¬ ì •ê·œí™”
    normalized_date = re.sub(r'\s+', '', date_string)
    
    # í—ˆìš©ëœ ë‚ ì§œ ëª©ë¡ê³¼ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸
    return normalized_date in NORMALIZED_ALLOWED_DATES

def extract_and_validate_date(text):
    """í…ìŠ¤íŠ¸ì—ì„œ ë‚ ì§œë¥¼ ì¶”ì¶œí•˜ê³  í—ˆìš©ëœ ë‚ ì§œë§Œ ë°˜í™˜í•©ë‹ˆë‹¤."""
    if not text:
        return None
    
    # ëª¨ë“  ë‚ ì§œ íŒ¨í„´ ì¶”ì¶œ
    date_patterns = re.findall(r'\d{4}ë…„\s*\d{1,2}ì›”ë§', text)
    
    # í—ˆìš©ëœ ë‚ ì§œë§Œ í•„í„°ë§
    valid_dates = []
    for date_pattern in date_patterns:
        if is_date_allowed(date_pattern):
            valid_dates.append(re.sub(r'\s+', '', date_pattern))  # ì •ê·œí™”í•˜ì—¬ ì €ì¥
    
    # ì¤‘ë³µ ì œê±°
    valid_dates = list(set(valid_dates))
    
    # ìš°ì„ ìˆœìœ„: 2024ë…„9ì›”ë§ > 2025ë…„3ì›”ë§
    if "2024ë…„9ì›”ë§" in valid_dates:
        return "2024ë…„9ì›”ë§"
    elif "2025ë…„3ì›”ë§" in valid_dates:
        return "2025ë…„3ì›”ë§"
    elif valid_dates:
        return valid_dates[0]
    else:
        return None

# =============================================================================
# ë“œë¼ì´ë²„ ê´€ë¦¬ í´ë˜ìŠ¤ (ê¸°ì¡´ê³¼ ë™ì¼)
# =============================================================================

class DriverManager:
    """ì›¹ ë“œë¼ì´ë²„ í’€ì„ ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤ì…ë‹ˆë‹¤."""
    
    def __init__(self, max_drivers=MAX_WORKERS):
        self.max_drivers = max_drivers
        self.drivers = []
        self.available_drivers = []
        self.initialize_drivers()

    def initialize_drivers(self):
        """ë“œë¼ì´ë²„ í’€ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
        log_message(f"{self.max_drivers}ê°œì˜ Chrome ë“œë¼ì´ë²„ ì´ˆê¸°í™” ì¤‘...")
        for _ in range(self.max_drivers):
            driver = self.create_driver()
            if driver:
                self.drivers.append(driver)
                self.available_drivers.append(driver)
        log_message(f"ì´ {len(self.drivers)}ê°œì˜ ë“œë¼ì´ë²„ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.")

    def create_driver(self):
        """GitHub Actions í™˜ê²½ì— ìµœì í™”ëœ Chrome ì›¹ë“œë¼ì´ë²„ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        try:
            options = Options()
            
            # Headless ëª¨ë“œ (GitHub Actions í™˜ê²½ì—ì„œ í•„ìˆ˜)
            options.add_argument('--headless=new')
            options.add_argument('--no-sandbox')
            options.add_argument('--disable-dev-shm-usage')
            options.add_argument('--disable-gpu')
            options.add_argument('--window-size=1920,1080')
            
            # User-Agent ì„¤ì •
            options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
            
            # ì„±ëŠ¥ ìµœì í™” ì˜µì…˜
            options.add_argument('--disable-extensions')
            options.add_argument('--disable-browser-side-navigation')
            options.add_argument('--disable-infobars')
            options.add_argument('--disable-notifications')
            options.add_argument('--disable-popup-blocking')
            options.add_argument('--disable-background-networking')
            options.add_argument('--disable-background-timer-throttling')
            options.add_argument('--disable-backgrounding-occluded-windows')
            options.add_argument('--disable-renderer-backgrounding')
            
            # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”
            options.add_argument('--memory-pressure-off')
            options.add_argument('--max_old_space_size=4096')
            
            # ë³´ì•ˆ ê´€ë ¨ ì˜µì…˜ (CI í™˜ê²½ì—ì„œ í•„ìš”)
            options.add_argument('--disable-web-security')
            options.add_argument('--allow-running-insecure-content')
            
            # Chrome í™˜ê²½ì„¤ì •
            prefs = {
                'profile.default_content_setting_values': {
                    'images': 1,          # ì´ë¯¸ì§€ ë¡œë”© í—ˆìš©
                    'plugins': 2,         # í”ŒëŸ¬ê·¸ì¸ ì°¨ë‹¨
                    'javascript': 1,      # JavaScript í—ˆìš© (í•„ìˆ˜)
                    'notifications': 2,   # ì•Œë¦¼ ì°¨ë‹¨
                    'media_stream': 2,    # ë¯¸ë””ì–´ ìŠ¤íŠ¸ë¦¼ ì°¨ë‹¨
                },
                'disk-cache-size': 4096,
            }
            options.add_experimental_option('prefs', prefs)
            
            # Chrome ë“œë¼ì´ë²„ ìƒì„±
            driver = webdriver.Chrome(options=options)
            driver.set_page_load_timeout(PAGE_LOAD_TIMEOUT)
            driver.implicitly_wait(WAIT_TIMEOUT)
            
            return driver
            
        except Exception as e:
            log_message(f"Chrome ë“œë¼ì´ë²„ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            return None

    def get_driver(self):
        """ì‚¬ìš© ê°€ëŠ¥í•œ ë“œë¼ì´ë²„ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
        while not self.available_drivers:
            log_message("ëª¨ë“  ë“œë¼ì´ë²„ê°€ ì‚¬ìš© ì¤‘ì…ë‹ˆë‹¤. ì ì‹œ ëŒ€ê¸°...", verbose=False)
            time.sleep(1)
            
        driver = self.available_drivers.pop(0)
        return driver

    def return_driver(self, driver):
        """ë“œë¼ì´ë²„ë¥¼ í’€ì— ë°˜í™˜í•©ë‹ˆë‹¤."""
        if driver in self.drivers and driver not in self.available_drivers:
            try:
                # ë“œë¼ì´ë²„ ìƒíƒœ í™•ì¸
                driver.current_url  # ì ‘ê·¼ ê°€ëŠ¥ì„± í…ŒìŠ¤íŠ¸
                self.available_drivers.append(driver)
            except:
                # ì˜¤ë¥˜ ë°œìƒ ì‹œ ë“œë¼ì´ë²„ë¥¼ êµì²´
                try:
                    driver.quit()
                except:
                    pass
                
                self.drivers.remove(driver)
                new_driver = self.create_driver()
                if new_driver:
                    self.drivers.append(new_driver)
                    self.available_drivers.append(new_driver)

    def close_all(self):
        """ëª¨ë“  ë“œë¼ì´ë²„ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤."""
        for driver in self.drivers:
            try:
                driver.quit()
            except:
                pass
        self.drivers = []
        self.available_drivers = []

# =============================================================================
# ì§„í–‰ ìƒí™© ê´€ë¦¬ í´ë˜ìŠ¤
# =============================================================================

class ProgressManager:
    """ìŠ¤í¬ë˜í•‘ ì§„í–‰ ìƒí™©ì„ ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤ì…ë‹ˆë‹¤."""
    
    def __init__(self, file_path=None):
        self.file_path = file_path or PROGRESS_FILE
        self.progress = self.load()

    def load(self):
        """ì €ì¥ëœ ì§„í–‰ ìƒí™©ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
        if os.path.exists(self.file_path):
            try:
                with open(self.file_path, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except (json.JSONDecodeError, FileNotFoundError):
                log_message(f"ì§„í–‰ íŒŒì¼ ì†ìƒ ë˜ëŠ” ì—†ìŒ: {self.file_path}, ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤.")

        return {
            'completed': [],
            'failed': [],
            'data_validation': [],
            'stats': {
                'last_run': None,
                'success_count': 0,
                'failure_count': 0,
                'validation_count': 0
            }
        }

    def mark_completed(self, bank_name):
        """ì€í–‰ì„ ì™„ë£Œ ëª©ë¡ì— ì¶”ê°€í•©ë‹ˆë‹¤."""
        if bank_name not in self.progress.get('completed', []):
            self.progress.setdefault('completed', []).append(bank_name)
            self.progress['stats']['success_count'] = len(self.progress.get('completed', []))

        # ì‹¤íŒ¨ ëª©ë¡ì—ì„œ ì œê±° (ì¬ì‹œë„ í›„ ì„±ê³µí•œ ê²½ìš°)
        if bank_name in self.progress.get('failed', []):
            self.progress['failed'].remove(bank_name)

        self.save()

    def mark_failed(self, bank_name):
        """ì€í–‰ì„ ì‹¤íŒ¨ ëª©ë¡ì— ì¶”ê°€í•©ë‹ˆë‹¤."""
        if bank_name not in self.progress.get('failed', []) and bank_name not in self.progress.get('completed', []):
            self.progress.setdefault('failed', []).append(bank_name)
            self.progress['stats']['failure_count'] = len(self.progress.get('failed', []))
            self.save()

    def mark_data_validated(self, bank_name, date_info, is_fresh):
        """ì€í–‰ì˜ ë°ì´í„° ê²€ì¦ ê²°ê³¼ë¥¼ ê¸°ë¡í•©ë‹ˆë‹¤."""
        validation_entry = {
            'bank_name': bank_name,
            'date_info': date_info,
            'is_fresh': is_fresh,
            'validated_at': datetime.now().isoformat()
        }
        
        self.progress.setdefault('data_validation', []).append(validation_entry)
        self.progress['stats']['validation_count'] = len(self.progress.get('data_validation', []))
        self.save()

    def save(self):
        """ì§„í–‰ ìƒí™©ì„ íŒŒì¼ì— ì €ì¥í•©ë‹ˆë‹¤."""
        self.progress['stats']['last_run'] = datetime.now().isoformat()
        try:
            with open(self.file_path, 'w', encoding='utf-8') as f:
                json.dump(self.progress, f, ensure_ascii=False, indent=2)
        except Exception as e:
            log_message(f"ì§„í–‰ ìƒí™© ì €ì¥ ì‹¤íŒ¨: {str(e)}")

    def get_pending_banks(self, all_banks=BANKS):
        """ì²˜ë¦¬í•  ì€í–‰ ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        completed = set(self.progress.get('completed', []))
        return [bank for bank in all_banks if bank not in completed]

# =============================================================================
# ì›¹ ìŠ¤í¬ë˜í•‘ ìœ í‹¸ë¦¬í‹° í´ë˜ìŠ¤
# =============================================================================

class WaitUtils:
    """ëª…ì‹œì  ëŒ€ê¸°ë¥¼ ìœ„í•œ ìœ í‹¸ë¦¬í‹° í´ë˜ìŠ¤ì…ë‹ˆë‹¤."""
    
    @staticmethod
    def wait_for_element(driver, locator, timeout=WAIT_TIMEOUT):
        """ìš”ì†Œê°€ ë‚˜íƒ€ë‚  ë•Œê¹Œì§€ ëª…ì‹œì ìœ¼ë¡œ ëŒ€ê¸°í•©ë‹ˆë‹¤."""
        try:
            element = WebDriverWait(driver, timeout).until(
                EC.presence_of_element_located(locator)
            )
            return element
        except TimeoutException:
            return None

    @staticmethod
    def wait_for_clickable(driver, locator, timeout=WAIT_TIMEOUT):
        """ìš”ì†Œê°€ í´ë¦­ ê°€ëŠ¥í•  ë•Œê¹Œì§€ ëª…ì‹œì ìœ¼ë¡œ ëŒ€ê¸°í•©ë‹ˆë‹¤."""
        try:
            element = WebDriverWait(driver, timeout).until(
                EC.element_to_be_clickable(locator)
            )
            return element
        except TimeoutException:
            return None

    @staticmethod
    def wait_for_page_load(driver, timeout=PAGE_LOAD_TIMEOUT):
        """í˜ì´ì§€ê°€ ì™„ì „íˆ ë¡œë“œë  ë•Œê¹Œì§€ ëŒ€ê¸°í•©ë‹ˆë‹¤."""
        try:
            WebDriverWait(driver, timeout).until(
                lambda d: d.execute_script('return document.readyState') == 'complete'
            )
            return True
        except TimeoutException:
            return False

    @staticmethod
    def wait_with_random(min_time=0.5, max_time=1.5):
        """ë¬´ì‘ìœ„ ì‹œê°„ ë™ì•ˆ ëŒ€ê¸°í•©ë‹ˆë‹¤ (ë´‡ íƒì§€ ë°©ì§€)."""
        time.sleep(random.uniform(min_time, max_time))

# =============================================================================
# í•µì‹¬ ìˆ˜ì • 1: ì—„ê²©í•œ ë‚ ì§œ ì¶”ì¶œ ë¡œì§
# =============================================================================

def extract_date_information(driver, bank_name=None):
    """ì›¹í˜ì´ì§€ì—ì„œ í—ˆìš©ëœ ë‚ ì§œë§Œ ì—„ê²©í•˜ê²Œ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    try:
        log_message(f"{bank_name or 'ì€í–‰'} ë‚ ì§œ ì¶”ì¶œ ì‹œì‘ (ì—„ê²© ëª¨ë“œ)", verbose=False)
        
        # 1ë‹¨ê³„: í˜ì´ì§€ ì†ŒìŠ¤ì—ì„œ ëª¨ë“  ë‚ ì§œ íŒ¨í„´ ì¶”ì¶œ
        page_source = driver.page_source
        found_date = extract_and_validate_date(page_source)
        
        if found_date:
            log_message(f"{bank_name or 'ì€í–‰'} í˜ì´ì§€ ì†ŒìŠ¤ì—ì„œ ìœ íš¨ ë‚ ì§œ ë°œê²¬: {found_date}", verbose=False)
            return found_date
        
        # 2ë‹¨ê³„: HTML ìš”ì†Œë³„ ê²€ìƒ‰ (ìš°ì„ ìˆœìœ„ ìˆœ)
        priority_selectors = [
            "//h1[contains(text(), 'ë…„') and contains(text(), 'ì›”ë§')]",
            "//h2[contains(text(), 'ë…„') and contains(text(), 'ì›”ë§')]", 
            "//h3[contains(text(), 'ë…„') and contains(text(), 'ì›”ë§')]",
            "//th[contains(text(), 'ê¸°ë§') and contains(text(), 'ë…„')]",
            "//td[contains(text(), 'ê¸°ë§') and contains(text(), 'ë…„')]",
            "//*[@class='title' or @class='header'][contains(text(), 'ë…„')]"
        ]
        
        for selector in priority_selectors:
            try:
                elements = driver.find_elements(By.XPATH, selector)
                for element in elements:
                    text = element.text.strip()
                    found_date = extract_and_validate_date(text)
                    if found_date:
                        log_message(f"{bank_name or 'ì€í–‰'} HTML ìš”ì†Œì—ì„œ ìœ íš¨ ë‚ ì§œ ë°œê²¬: {found_date} (ì¶œì²˜: {selector})", verbose=False)
                        return found_date
            except Exception:
                continue
        
        # 3ë‹¨ê³„: JavaScript ì‹¤í–‰ (ìµœí›„ ìˆ˜ë‹¨)
        try:
            js_script = """
            var allowedPatterns = [
                '2024ë…„9ì›”ë§', '2024ë…„09ì›”ë§', '2024ë…„ 9ì›”ë§', '2024ë…„ 09ì›”ë§',
                '2025ë…„3ì›”ë§', '2025ë…„03ì›”ë§', '2025ë…„ 3ì›”ë§', '2025ë…„ 03ì›”ë§'
            ];
            
            var allText = document.body.innerText;
            var dateRegex = /\\d{4}ë…„\\s*\\d{1,2}ì›”ë§/g;
            var matches = allText.match(dateRegex);
            
            if (matches) {
                // í—ˆìš©ëœ íŒ¨í„´ê³¼ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ê²ƒë§Œ ì°¾ê¸°
                for (var i = 0; i < matches.length; i++) {
                    var cleanMatch = matches[i].replace(/\\s+/g, '');
                    for (var j = 0; j < allowedPatterns.length; j++) {
                        var cleanPattern = allowedPatterns[j].replace(/\\s+/g, '');
                        if (cleanMatch === cleanPattern) {
                            return cleanMatch;
                        }
                    }
                }
            }
            
            return '';
            """
            
            js_result = driver.execute_script(js_script)
            if js_result:
                log_message(f"{bank_name or 'ì€í–‰'} JavaScriptì—ì„œ ìœ íš¨ ë‚ ì§œ ë°œê²¬: {js_result}", verbose=False)
                return js_result
                
        except Exception as e:
            log_message(f"{bank_name or 'ì€í–‰'} JavaScript ë‚ ì§œ ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}", verbose=False)
        
        # 4ë‹¨ê³„: ëª¨ë“  ë°©ë²• ì‹¤íŒ¨
        log_message(f"{bank_name or 'ì€í–‰'} í—ˆìš©ëœ ë‚ ì§œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ", verbose=False)
        return "í—ˆìš©ëœ ë‚ ì§œ ì—†ìŒ"

    except Exception as e:
        log_message(f"{bank_name or 'ì€í–‰'} ë‚ ì§œ ì •ë³´ ì¶”ì¶œ ì˜¤ë¥˜: {str(e)}", verbose=False)
        return "ë‚ ì§œ ì¶”ì¶œ ì‹¤íŒ¨"

def validate_extracted_date(extracted_date, expected_dates):
    """ì¶”ì¶œëœ ë‚ ì§œê°€ í—ˆìš©ëœ ë‚ ì§œì¸ì§€ ì—„ê²©í•˜ê²Œ ê²€ì¦í•©ë‹ˆë‹¤."""
    if not extracted_date or extracted_date in ["í—ˆìš©ëœ ë‚ ì§œ ì—†ìŒ", "ë‚ ì§œ ì¶”ì¶œ ì‹¤íŒ¨"]:
        return False, "ìœ íš¨í•œ ë‚ ì§œ ì •ë³´ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŒ"
    
    # í—ˆìš©ëœ ë‚ ì§œì¸ì§€ í™•ì¸
    if is_date_allowed(extracted_date):
        if "2024ë…„9ì›”" in extracted_date:
            return True, f"âœ… ì¼ì¹˜ (ê¸°í•œë‚´ìµœì‹ ): {extracted_date}"
        elif "2025ë…„3ì›”" in extracted_date:
            return True, f"ğŸŸ¢ ì¼ì¹˜ (ì˜ˆì •ë³´ë‹¤ì„ ë°˜ì˜): {extracted_date}"
        else:
            return True, f"í—ˆìš©ëœ ë‚ ì§œ í™•ì¸: {extracted_date}"
    else:
        return False, f"âŒ í—ˆìš©ë˜ì§€ ì•Šì€ ë‚ ì§œ: {extracted_date} (í—ˆìš©: 2024ë…„9ì›”ë§, 2025ë…„3ì›”ë§ë§Œ)"

# ë‚˜ë¨¸ì§€ í•¨ìˆ˜ë“¤ì€ ê¸°ì¡´ê³¼ ë™ì¼í•˜ê²Œ ìœ ì§€ (select_bank, select_category, extract_tables_from_page ë“±)
def select_bank(driver, bank_name):
    """ì •í™•í•œ ì€í–‰ëª… ë§¤ì¹­ì„ ìœ„í•œ ê°œì„ ëœ ì€í–‰ ì„ íƒ í•¨ìˆ˜"""
    try:
        # ë©”ì¸ í˜ì´ì§€ë¡œ ì ‘ì†
        driver.get(BASE_URL)
        WaitUtils.wait_for_page_load(driver)
        WaitUtils.wait_with_random(1, 2)

        # JavaScript ê¸°ë°˜ ì€í–‰ ì„ íƒ
        js_script = f"""
        var targetBank = '{bank_name}';
        var allElements = document.querySelectorAll('a, td, th, span, div');
        var exactMatches = [];
        var limitedMatches = [];
        
        for(var i = 0; i < allElements.length; i++) {{
            var element = allElements[i];
            var text = element.textContent.trim();
            
            if(text === targetBank) {{
                exactMatches.push(element);
            }}
            else if(text.indexOf(targetBank) !== -1 && 
                    text.length <= targetBank.length * 2 && 
                    text.length > targetBank.length) {{
                limitedMatches.push(element);
            }}
        }}
        
        var allCandidates = exactMatches.concat(limitedMatches);
        
        for(var i = 0; i < allCandidates.length; i++) {{
            var element = allCandidates[i];
            
            try {{
                if(element.offsetParent === null) continue;
                
                element.scrollIntoView({{block: 'center'}});
                
                if(element.tagName.toLowerCase() === 'a') {{
                    element.click();
                    return 'direct_link_' + (i < exactMatches.length ? 'exact' : 'limited');
                }}
                
                var links = element.querySelectorAll('a');
                if(links.length > 0) {{
                    links[0].click();
                    return 'nested_link_' + (i < exactMatches.length ? 'exact' : 'limited');
                }}
                
                element.click();
                return 'element_click_' + (i < exactMatches.length ? 'exact' : 'limited');
            }} catch(e) {{
                continue;
            }}
        }}
        
        return false;
        """
        
        result = driver.execute_script(js_script)
        if result:
            log_message(f"{bank_name} ì€í–‰: JavaScript {result} ì„±ê³µ", verbose=False)
            WaitUtils.wait_with_random(1, 2)
            return True

        # Selenium ëŒ€ì²´ ë°©ë²•
        exact_xpaths = [
            f"//td[normalize-space(text())='{bank_name}']//a",
            f"//a[normalize-space(text())='{bank_name}']"
        ]
        
        for xpath in exact_xpaths:
            try:
                elements = driver.find_elements(By.XPATH, xpath)
                for element in elements:
                    if element.is_displayed():
                        driver.execute_script("arguments[0].scrollIntoView({block: 'center'});", element)
                        WaitUtils.wait_with_random(0.5, 1)
                        driver.execute_script("arguments[0].click();", element)
                        WaitUtils.wait_with_random(1, 2)
                        return True
            except Exception:
                continue

        return False

    except Exception as e:
        log_message(f"{bank_name} ì€í–‰ ì„ íƒ ì‹¤íŒ¨: {str(e)}")
        return False

def select_category(driver, category):
    """íŠ¹ì • ì¹´í…Œê³ ë¦¬ íƒ­ì„ í´ë¦­í•©ë‹ˆë‹¤."""
    try:
        js_script = f"""
        var targetCategory = '{category}';
        var allElements = document.querySelectorAll('a, button, span, li, div, tab');
        
        for(var i = 0; i < allElements.length; i++) {{
            var element = allElements[i];
            var text = element.textContent.trim();
            
            if(text === targetCategory && element.offsetParent !== null) {{
                element.scrollIntoView({{block: 'center'}});
                element.click();
                return 'exact_match';
            }}
        }}
        
        for(var i = 0; i < allElements.length; i++) {{
            var element = allElements[i];
            var text = element.textContent.trim();
            
            if(text.includes(targetCategory) && element.offsetParent !== null) {{
                element.scrollIntoView({{block: 'center'}});
                element.click();
                return 'contains_match';
            }}
        }}
        
        return false;
        """
        
        result = driver.execute_script(js_script)
        if result:
            WaitUtils.wait_with_random(1, 2)
            return True

        return False

    except Exception as e:
        log_message(f"{category} íƒ­ í´ë¦­ ì‹¤íŒ¨: {str(e)}", verbose=False)
        return False

def extract_tables_from_page(driver):
    """í˜„ì¬ í˜ì´ì§€ì—ì„œ ëª¨ë“  í…Œì´ë¸”ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    try:
        WaitUtils.wait_for_page_load(driver)
        WaitUtils.wait_with_random(1, 2)

        try:
            html_source = driver.page_source
            dfs = pd.read_html(StringIO(html_source))

            if dfs:
                valid_dfs = []
                seen_hashes = set()

                for df in dfs:
                    if not df.empty and df.shape[0] > 0 and df.shape[1] > 0:
                        if isinstance(df.columns, pd.MultiIndex):
                            new_cols = []
                            for col in df.columns:
                                if isinstance(col, tuple):
                                    clean_parts = [str(c).strip() for c in col if str(c).strip() and str(c).lower() != 'nan']
                                    new_cols.append('_'.join(clean_parts) if clean_parts else f"Column_{len(new_cols)+1}")
                                else:
                                    new_cols.append(str(col))
                            df.columns = new_cols

                        try:
                            df_hash = hash(str(df.shape) + str(list(df.columns)) + str(df.iloc[0].values) if len(df) > 0 else "")
                            if df_hash not in seen_hashes:
                                valid_dfs.append(df)
                                seen_hashes.add(df_hash)
                        except Exception:
                            valid_dfs.append(df)

                return valid_dfs
        except Exception:
            pass

        return []

    except Exception as e:
        log_message(f"í˜ì´ì§€ì—ì„œ í…Œì´ë¸” ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")
        return []

# =============================================================================
# ë©”ì¸ ìŠ¤í¬ë˜í•‘ ë¡œì§
# =============================================================================

def scrape_bank_data(bank_name, driver, progress_manager, expected_dates):
    """ë‹¨ì¼ ì€í–‰ì˜ ë°ì´í„°ë¥¼ ìŠ¤í¬ë˜í•‘í•©ë‹ˆë‹¤."""
    log_message(f"[ì‹œì‘] {bank_name} ì€í–‰ ìŠ¤í¬ë˜í•‘ ì‹œì‘")

    try:
        # ì€í–‰ ì„ íƒ
        if not select_bank(driver, bank_name):
            log_message(f"{bank_name} ì€í–‰ ì„ íƒ ì‹¤íŒ¨")
            return None

        # ì—„ê²©í•œ ë‚ ì§œ ì •ë³´ ì¶”ì¶œ ë° ê²€ì¦
        date_info = extract_date_information(driver, bank_name)
        is_fresh, validation_message = validate_extracted_date(date_info, expected_dates)
        
        # ë°ì´í„° ê²€ì¦ ê²°ê³¼ ê¸°ë¡
        progress_manager.mark_data_validated(bank_name, date_info, is_fresh)
        
        log_message(f"{bank_name} ì€í–‰ ë‚ ì§œ ê²€ì¦: {validation_message}")

        result_data = {
            'ë‚ ì§œì •ë³´': date_info,
            'ê²€ì¦ê²°ê³¼': validation_message,
            'ì‹ ì„ ë„': is_fresh
        }
        
        all_table_hashes = set()

        # ê° ì¹´í…Œê³ ë¦¬ ì²˜ë¦¬
        for category in CATEGORIES:
            try:
                if not select_category(driver, category):
                    log_message(f"{bank_name} ì€í–‰ {category} íƒ­ í´ë¦­ ì‹¤íŒ¨", verbose=False)
                    continue

                tables = extract_tables_from_page(driver)
                if not tables:
                    continue

                valid_tables = []
                for df in tables:
                    try:
                        df_hash = hash(str(df.shape) + str(list(df.columns)) + str(df.iloc[0].values) if len(df) > 0 else "")
                        
                        if df_hash not in all_table_hashes:
                            valid_tables.append(df)
                            all_table_hashes.add(df_hash)
                    except Exception:
                        valid_tables.append(df)

                if valid_tables:
                    result_data[category] = valid_tables
                    log_message(f"{bank_name} {category}: {len(valid_tables)}ê°œ í…Œì´ë¸”", verbose=False)

            except Exception as e:
                log_message(f"{bank_name} {category} ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}", verbose=False)

        # ë°ì´í„° ìˆ˜ì§‘ í™•ì¸
        table_categories = [key for key, data in result_data.items() 
                          if key not in ['ë‚ ì§œì •ë³´', 'ê²€ì¦ê²°ê³¼', 'ì‹ ì„ ë„'] and isinstance(data, list) and data]
        
        if not table_categories:
            log_message(f"{bank_name} í…Œì´ë¸” ë°ì´í„° ì—†ìŒ")
            return None

        log_message(f"[ì™„ë£Œ] {bank_name} ({', '.join(table_categories)})")
        return result_data

    except Exception as e:
        log_message(f"{bank_name} ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
        return None

def save_bank_data(bank_name, data_dict):
    """ìˆ˜ì§‘ëœ ì€í–‰ ë°ì´í„°ë¥¼ ì—‘ì…€ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
    if not data_dict:
        return False

    try:
        date_info = data_dict.get('ë‚ ì§œì •ë³´', 'ë‚ ì§œì •ë³´ì—†ìŒ')
        safe_date_info = re.sub(r'[^\w\-_ë…„ì›”ë§]', '_', date_info)
        excel_path = os.path.join(OUTPUT_DIR, f"{bank_name}_{safe_date_info}.xlsx")

        with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:
            # ê³µì‹œ ì •ë³´ ì‹œíŠ¸
            info_data = {
                'ì€í–‰ëª…': [bank_name],
                'ê³µì‹œ ë‚ ì§œ': [data_dict.get('ë‚ ì§œì •ë³´', '')],
                'ê²€ì¦ ê²°ê³¼': [data_dict.get('ê²€ì¦ê²°ê³¼', '')],
                'ë°ì´í„° ì‹ ì„ ë„': ['ìµœì‹ ' if data_dict.get('ì‹ ì„ ë„', False) else 'êµ¬ë²„ì „'],
                'ì¶”ì¶œ ì¼ì‹œ': [datetime.now().strftime("%Y-%m-%d %H:%M:%S")],
                'ìŠ¤í¬ë˜í•‘ ì‹œìŠ¤í…œ': ['GitHub Actions ì €ì¶•ì€í–‰ ìŠ¤í¬ë˜í¼ v2.3 (ì—„ê²©í•œ ë‚ ì§œ ê²€ì¦)']
            }
            info_df = pd.DataFrame(info_data)
            info_df.to_excel(writer, sheet_name='ê³µì‹œì •ë³´', index=False)

            # ì¹´í…Œê³ ë¦¬ë³„ ë°ì´í„°
            for category, tables in data_dict.items():
                if category in ['ë‚ ì§œì •ë³´', 'ê²€ì¦ê²°ê³¼', 'ì‹ ì„ ë„'] or not isinstance(tables, list):
                    continue

                for i, df in enumerate(tables):
                    sheet_name = category if i == 0 else f"{category}_{i+1}"
                    sheet_name = sheet_name[:31]

                    try:
                        df.to_excel(writer, sheet_name=sheet_name, index=False)
                    except Exception:
                        pass

        return True

    except Exception as e:
        log_message(f"{bank_name} ë°ì´í„° ì €ì¥ ì˜¤ë¥˜: {str(e)}")
        return False

def worker_process_bank(bank_name, driver_manager, progress_manager, expected_dates):
    """ì›Œì»¤ ìŠ¤ë ˆë“œì—ì„œ ì€í–‰ ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
    driver = None
    
    try:
        driver = driver_manager.get_driver()
        
        for attempt in range(MAX_RETRIES):
            try:
                result_data = scrape_bank_data(bank_name, driver, progress_manager, expected_dates)

                if result_data:
                    if save_bank_data(bank_name, result_data):
                        progress_manager.mark_completed(bank_name)
                        return bank_name, True, result_data.get('ê²€ì¦ê²°ê³¼', '')
                    else:
                        if attempt < MAX_RETRIES - 1:
                            WaitUtils.wait_with_random(2, 4)

            except Exception as e:
                if attempt < MAX_RETRIES - 1:
                    WaitUtils.wait_with_random(2, 4)

        progress_manager.mark_failed(bank_name)
        return bank_name, False, "ëª¨ë“  ì‹œë„ ì‹¤íŒ¨"

    except Exception as e:
        progress_manager.mark_failed(bank_name)
        return bank_name, False, f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}"
    
    finally:
        if driver and driver_manager:
            driver_manager.return_driver(driver)

# =============================================================================
# ë¹„ë™ê¸° ì²˜ë¦¬ ë° ë©”ì¸ ì‹¤í–‰ ë¡œì§
# =============================================================================

async def process_banks_async(banks, driver_manager, progress_manager, expected_dates):
    """ì€í–‰ ëª©ë¡ì„ ë³‘ë ¬ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
    log_message(f"ë³‘ë ¬ ì²˜ë¦¬ ì‹œì‘: {len(banks)}ê°œ ì€í–‰, {MAX_WORKERS}ê°œ ì›Œì»¤")
    
    all_results = []
    
    batch_size = max(1, len(banks) // MAX_WORKERS) if len(banks) > MAX_WORKERS else len(banks)
    bank_batches = [banks[i:i + batch_size] for i in range(0, len(banks), batch_size)]

    for batch_idx, batch in enumerate(bank_batches):
        log_message(f"ë°°ì¹˜ {batch_idx+1}/{len(bank_batches)} ì²˜ë¦¬ ì¤‘ ({len(batch)}ê°œ ì€í–‰)")
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=min(MAX_WORKERS, len(batch))) as executor:
            loop = asyncio.get_event_loop()
            futures = [
                loop.run_in_executor(
                    executor,
                    worker_process_bank,
                    bank,
                    driver_manager,
                    progress_manager,
                    expected_dates
                )
                for bank in batch
            ]

            progress_desc = f"ë°°ì¹˜ {batch_idx+1}/{len(bank_batches)}"
            progress_bar = tqdm(asyncio.as_completed(futures), total=len(futures), desc=progress_desc)

            batch_results = []
            for future in progress_bar:
                result = await future
                batch_results.append(result)
                
                success_count = len([r for r in batch_results if r[1]])
                progress_bar.set_postfix_str(f"ì™„ë£Œ: {success_count}/{len(batch_results)}")

            all_results.extend(batch_results)
            
            if batch_idx < len(bank_batches) - 1:
                log_message(f"ë°°ì¹˜ {batch_idx+1} ì™„ë£Œ. ë‹¤ìŒ ë°°ì¹˜ ì „ ì ì‹œ ëŒ€ê¸°...")
                await asyncio.sleep(2)

    return all_results

def process_with_retry(banks, max_retries=1):
    """ì‹¤íŒ¨í•œ ì€í–‰ì„ ì¬ì‹œë„í•˜ëŠ” ë¡œì§ì„ í¬í•¨í•œ ë©”ì¸ ì²˜ë¦¬ í•¨ìˆ˜ì…ë‹ˆë‹¤."""
    expected_dates = validate_data_freshness()
    
    driver_manager = DriverManager(max_drivers=MAX_WORKERS)
    progress_manager = ProgressManager()

    pending_banks = progress_manager.get_pending_banks(banks)
    if not pending_banks:
        pending_banks = banks[:5]

    log_message(f"ì²˜ë¦¬í•  ì€í–‰ ìˆ˜: {len(pending_banks)}/{len(banks)}")

    try:
        if sys.version_info >= (3, 7):
            results = asyncio.run(process_banks_async(pending_banks, driver_manager, progress_manager, expected_dates))
        else:
            loop = asyncio.get_event_loop()
            results = loop.run_until_complete(process_banks_async(pending_banks, driver_manager, progress_manager, expected_dates))

        successful_banks = [r[0] for r in results if r[1]]
        failed_banks = [r[0] for r in results if not r[1]]

        return successful_banks, failed_banks, results

    finally:
        driver_manager.close_all()

def generate_summary_report():
    """ìŠ¤í¬ë˜í•‘ ê²°ê³¼ ìš”ì•½ ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    try:
        progress_manager = ProgressManager()
        validation_data = progress_manager.progress.get('data_validation', [])

        bank_summary = []
        for bank in BANKS:
            bank_files = [f for f in os.listdir(OUTPUT_DIR) if f.startswith(f"{bank}_") and f.endswith(".xlsx")]
            
            if bank_files:
                try:
                    latest_file = sorted(bank_files)[-1]
                    file_path = os.path.join(OUTPUT_DIR, latest_file)
                    
                    info_df = pd.read_excel(file_path, sheet_name='ê³µì‹œì •ë³´')
                    date_info = str(info_df['ê³µì‹œ ë‚ ì§œ'].iloc[0]) if 'ê³µì‹œ ë‚ ì§œ' in info_df.columns else "í™•ì¸ ë¶ˆê°€"
                    data_freshness = str(info_df['ë°ì´í„° ì‹ ì„ ë„'].iloc[0]) if 'ë°ì´í„° ì‹ ì„ ë„' in info_df.columns else "í™•ì¸ ë¶ˆê°€"
                    
                    bank_summary.append({
                        'ì€í–‰ëª…': bank,
                        'ìƒíƒœ': 'ì™„ë£Œ',
                        'ê³µì‹œ ë‚ ì§œ': date_info,
                        'ë°ì´í„° ì‹ ì„ ë„': data_freshness
                    })
                except:
                    bank_summary.append({
                        'ì€í–‰ëª…': bank,
                        'ìƒíƒœ': 'íŒŒì¼ ì˜¤ë¥˜',
                        'ê³µì‹œ ë‚ ì§œ': 'í™•ì¸ ë¶ˆê°€',
                        'ë°ì´í„° ì‹ ì„ ë„': 'í™•ì¸ ë¶ˆê°€'
                    })
            else:
                bank_summary.append({
                    'ì€í–‰ëª…': bank,
                    'ìƒíƒœ': 'ì‹¤íŒ¨',
                    'ê³µì‹œ ë‚ ì§œ': '',
                    'ë°ì´í„° ì‹ ì„ ë„': ''
                })

        summary_df = pd.DataFrame(bank_summary)
        summary_file = os.path.join(OUTPUT_DIR, f"ì—„ê²©í•œ_ë‚ ì§œê²€ì¦_ìš”ì•½_{TODAY}.xlsx")
        summary_df.to_excel(summary_file, index=False)

        stats = {
            'ì „ì²´ ì€í–‰ ìˆ˜': len(BANKS),
            'ì™„ë£Œ ì€í–‰ ìˆ˜': len([r for r in bank_summary if r['ìƒíƒœ'] == 'ì™„ë£Œ']),
            'ì‹¤íŒ¨ ì€í–‰ ìˆ˜': len([r for r in bank_summary if r['ìƒíƒœ'] in ['ì‹¤íŒ¨', 'íŒŒì¼ ì˜¤ë¥˜']]),
            'ì„±ê³µë¥ ': f"{len([r for r in bank_summary if r['ìƒíƒœ'] == 'ì™„ë£Œ']) / len(BANKS) * 100:.1f}%"
        }

        return summary_file, stats, bank_summary

    except Exception as e:
        log_message(f"ìš”ì•½ ë³´ê³ ì„œ ìƒì„± ì˜¤ë¥˜: {str(e)}")
        return None, {}, []

def create_zip_archive():
    """ê²°ê³¼ íŒŒì¼ë“¤ì„ ZIPìœ¼ë¡œ ì••ì¶•í•©ë‹ˆë‹¤."""
    try:
        zip_filename = f'ì €ì¶•ì€í–‰_ë°ì´í„°_{TODAY}.zip'
        zip_path = os.path.join(OUTPUT_BASE_DIR, zip_filename)
        
        if os.path.exists(zip_path):
            os.remove(zip_path)
        
        with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED, compresslevel=6) as zipf:
            file_count = 0
            
            for root, dirs, files in os.walk(OUTPUT_DIR):
                for file in files:
                    file_path = os.path.join(root, file)
                    if os.path.exists(file_path) and os.path.isfile(file_path):
                        arcname = os.path.relpath(file_path, OUTPUT_BASE_DIR)
                        zipf.write(file_path, arcname)
                        file_count += 1
            
            readme_content = f"""ì €ì¶•ì€í–‰ ë°ì´í„° ìŠ¤í¬ë˜í•‘ ê²°ê³¼ (ì—„ê²©í•œ ë‚ ì§œ ê²€ì¦ ë²„ì „)

ìƒì„±ì¼ì‹œ: {datetime.now().strftime('%Yë…„ %mì›” %dì¼ %Hì‹œ %Më¶„')}
í¬í•¨ íŒŒì¼ ìˆ˜: {file_count}ê°œ
í—ˆìš© ë‚ ì§œ: 2024ë…„9ì›”ë§, 2025ë…„3ì›”ë§ë§Œ

âœ… ì—„ê²©í•œ ë‚ ì§œ ê²€ì¦ ì ìš©
âœ… ì˜ëª»ëœ ë‚ ì§œ ì™„ì „ ë°°ì œ
âœ… ZIP íŒŒì¼ ì•ˆì •ì„± ë³´ì¥

GitHub Actions ì €ì¶•ì€í–‰ ìŠ¤í¬ë˜í¼ v2.3 (ì—„ê²©í•œ ë‚ ì§œ ê²€ì¦)
"""
            zipf.writestr(f"README_{TODAY}.txt", readme_content.encode('utf-8'))
        
        if os.path.exists(zip_path):
            with zipfile.ZipFile(zip_path, 'r') as test_zip:
                zip_file_list = test_zip.namelist()
                if len(zip_file_list) > 0:
                    log_message(f"âœ… ZIP íŒŒì¼ ìƒì„± ì™„ë£Œ: {zip_path}")
                    return zip_path
        
        return None
        
    except Exception as e:
        log_message(f"âŒ ZIP ìƒì„± ì‹¤íŒ¨: {str(e)}")
        return None

# =============================================================================
# í•µì‹¬ ìˆ˜ì • 2: ì´ë©”ì¼ ë³¸ë¬¸ì— ìŠ¤í¬ë¦°ìƒ· í˜•íƒœ í…Œì´ë¸” í¬í•¨
# =============================================================================

def create_email_table(bank_summary):
    """ì´ë©”ì¼ ë³¸ë¬¸ì— í¬í•¨í•  ìŠ¤í¬ë¦°ìƒ· í˜•íƒœì˜ í…Œì´ë¸”ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    try:
        current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        # í…ìŠ¤íŠ¸ í…Œì´ë¸” ìƒì„±
        table_lines = []
        table_lines.append("=" * 80)
        table_lines.append("ğŸ“‹ ì€í–‰ë³„ ë‚ ì§œ í™•ì¸ ê²°ê³¼ (ìŠ¤í¬ë¦°ìƒ· í˜•íƒœ)")
        table_lines.append("=" * 80)
        table_lines.append(f"{'ì€í–‰ëª…':<12} {'ê³µì‹œ ë‚ ì§œ(ì›”ë§)':<18} {'ë‚ ì§œ í™•ì¸':<25} {'ì²˜ë¦¬ìƒíƒœ':<12}")
        table_lines.append("-" * 80)
        
        # ìƒíƒœë³„ ì •ë ¬
        sorted_summary = sorted(bank_summary, key=lambda x: (
            0 if x['ìƒíƒœ'] == 'ì™„ë£Œ' else 1 if x['ìƒíƒœ'] == 'íŒŒì¼ ì˜¤ë¥˜' else 2,
            x['ì€í–‰ëª…']
        ))
        
        for bank_data in sorted_summary:
            bank_name = bank_data['ì€í–‰ëª…']
            date_info = bank_data['ê³µì‹œ ë‚ ì§œ']
            status = bank_data['ìƒíƒœ']
            
            # ë‚ ì§œ í™•ì¸ ìƒíƒœ ê²°ì •
            if status == 'ì™„ë£Œ':
                if '2024ë…„9ì›”ë§' in date_info or '2024ë…„09ì›”ë§' in date_info:
                    date_check = "âœ… ì¼ì¹˜ (ê¸°í•œë‚´ìµœì‹ )"
                elif '2025ë…„3ì›”ë§' in date_info or '2025ë…„03ì›”ë§' in date_info:
                    date_check = "ğŸŸ¢ ì¼ì¹˜ (ì˜ˆì •ë³´ë‹¤ì„ ë°˜ì˜)"
                else:
                    date_check = "âš ï¸ í™•ì¸í•„ìš”"
                processing_status = "ì™„ë£Œ"
            elif status == 'íŒŒì¼ ì˜¤ë¥˜':
                date_check = "âŒ íŒŒì¼ì˜¤ë¥˜"
                processing_status = "ì‹¤íŒ¨"
            else:
                date_check = "âŒ ë¯¸ì²˜ë¦¬"
                processing_status = "ì‹¤íŒ¨"
            
            table_lines.append(f"{bank_name:<12} {date_info:<18} {date_check:<25} {processing_status:<12}")
        
        table_lines.append("-" * 80)
        
        # í†µê³„ ìš”ì•½
        total_banks = len(bank_summary)
        completed_banks = len([b for b in bank_summary if b['ìƒíƒœ'] == 'ì™„ë£Œ'])
        september_data = len([b for b in bank_summary if '2024ë…„9ì›”' in b['ê³µì‹œ ë‚ ì§œ']])
        march_data = len([b for b in bank_summary if '2025ë…„3ì›”' in b['ê³µì‹œ ë‚ ì§œ']])
        failed_banks = len([b for b in bank_summary if b['ìƒíƒœ'] in ['ì‹¤íŒ¨', 'íŒŒì¼ ì˜¤ë¥˜']])
        
        table_lines.append(f"ğŸ“Š ì²˜ë¦¬ ìƒíƒœ ìš”ì•½:")
        table_lines.append(f"  â€¢ ì „ì²´ ì€í–‰ ìˆ˜: {total_banks}ê°œ")
        table_lines.append(f"  â€¢ ì™„ë£Œëœ ì€í–‰: {completed_banks}ê°œ")
        table_lines.append(f"  â€¢ 2024ë…„9ì›”ë§ ë°ì´í„°: {september_data}ê°œ")
        table_lines.append(f"  â€¢ 2025ë…„3ì›”ë§ ë°ì´í„°: {march_data}ê°œ")
        table_lines.append(f"  â€¢ ì²˜ë¦¬ ì‹¤íŒ¨: {failed_banks}ê°œ")
        table_lines.append(f"  â€¢ ì„±ê³µë¥ : {completed_banks/total_banks*100:.1f}%")
        
        table_lines.append("=" * 80)
        table_lines.append(f"ğŸ“… í™•ì¸ ì‹œê°„: {current_time}")
        table_lines.append("ğŸ”§ ì—„ê²©í•œ ë‚ ì§œ ê²€ì¦: 2024ë…„9ì›”ë§, 2025ë…„3ì›”ë§ë§Œ í—ˆìš©")
        table_lines.append("=" * 80)
        
        return "\n".join(table_lines)
        
    except Exception as e:
        log_message(f"ì´ë©”ì¼ í…Œì´ë¸” ìƒì„± ì˜¤ë¥˜: {str(e)}")
        return "í…Œì´ë¸” ìƒì„± ì‹¤íŒ¨"

def send_email_notification(subject, body, bank_details=None, attachment_paths=None, is_success=True, expected_dates=None, bank_summary=None):
    """Gmail SMTPë¥¼ í†µí•´ ì´ë©”ì¼ ì•Œë¦¼ì„ ë°œì†¡í•©ë‹ˆë‹¤. (ìŠ¤í¬ë¦°ìƒ· í˜•íƒœ í…Œì´ë¸” í¬í•¨)"""
    if not GMAIL_ADDRESS or not GMAIL_APP_PASSWORD or not RECIPIENT_EMAILS:
        log_message("ì´ë©”ì¼ ì„¤ì •ì´ ë¶ˆì™„ì „í•˜ì—¬ ì•Œë¦¼ì„ ë°œì†¡í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return False
    
    try:
        # ì´ë©”ì¼ ë©”ì‹œì§€ êµ¬ì„±
        msg = MIMEMultipart()
        msg['From'] = GMAIL_ADDRESS
        msg['To'] = ', '.join(RECIPIENT_EMAILS)
        msg['Subject'] = subject
        
        # ê¸°ë³¸ ë³¸ë¬¸ì— ìŠ¤í¬ë¦°ìƒ· í˜•íƒœ í…Œì´ë¸” ì¶”ê°€
        enhanced_body = body
        
        if bank_summary:
            enhanced_body += "\n\n"
            enhanced_body += create_email_table(bank_summary)
        
        # ê¸°ì¡´ ìƒì„¸ ì •ë³´ë„ ìœ ì§€
        if bank_details:
            enhanced_body += "\n\n===== ìƒì„¸ ë¶„ì„ ê²°ê³¼ =====\n"
            
            successful_banks = [bank for bank in bank_details if bank['status'] == 'success']
            if successful_banks:
                enhanced_body += f"\nâœ… ì™„ì „ ì„±ê³µí•œ ì€í–‰ ({len(successful_banks)}ê°œ):\n"
                for bank in successful_banks[:10]:  # ìƒìœ„ 10ê°œë§Œ í‘œì‹œ
                    enhanced_body += f"  â€¢ {bank['name']}: {bank['date_info']}\n"
                if len(successful_banks) > 10:
                    enhanced_body += f"  ... ê¸°íƒ€ {len(successful_banks) - 10}ê°œ ì€í–‰\n"
            
            failed_banks = [bank for bank in bank_details if bank['status'] == 'failed']
            if failed_banks:
                enhanced_body += f"\nâŒ ì‹¤íŒ¨í•œ ì€í–‰ ({len(failed_banks)}ê°œ):\n"
                for bank in failed_banks[:5]:  # ìƒìœ„ 5ê°œë§Œ í‘œì‹œ
                    enhanced_body += f"  â€¢ {bank['name']}: {bank.get('error_reason', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}\n"
                if len(failed_banks) > 5:
                    enhanced_body += f"  ... ê¸°íƒ€ {len(failed_banks) - 5}ê°œ ì€í–‰\n"
        
        # ë³¸ë¬¸ ì¶”ê°€
        msg.attach(MIMEText(enhanced_body, 'plain', 'utf-8'))
        
        # ì²¨ë¶€ íŒŒì¼ ì¶”ê°€
        if attachment_paths:
            for file_path in attachment_paths:
                if os.path.exists(file_path):
                    try:
                        filename = os.path.basename(file_path)
                        
                        if filename.endswith('.zip'):
                            part = MIMEBase('application', 'zip')
                            with open(file_path, "rb") as attachment:
                                part.set_payload(attachment.read())
                            encoders.encode_base64(part)
                            part.add_header('Content-Disposition', f'attachment; filename="{filename}"')
                            part.add_header('Content-Type', 'application/zip')
                        elif filename.endswith('.xlsx'):
                            part = MIMEBase('application', 'vnd.openxmlformats-officedocument.spreadsheetml.sheet')
                            with open(file_path, "rb") as attachment:
                                part.set_payload(attachment.read())
                            encoders.encode_base64(part)
                            part.add_header('Content-Disposition', f'attachment; filename="{filename}"')
                        else:
                            part = MIMEBase('application', 'octet-stream')
                            with open(file_path, "rb") as attachment:
                                part.set_payload(attachment.read())
                            encoders.encode_base64(part)
                            part.add_header('Content-Disposition', f'attachment; filename="{filename}"')
                            
                        msg.attach(part)
                    except Exception as e:
                        log_message(f"ì²¨ë¶€ íŒŒì¼ ì¶”ê°€ ì‹¤íŒ¨ ({file_path}): {str(e)}")
        
        # Gmail SMTP ì„œë²„ ì—°ê²° ë° ë°œì†¡
        with smtplib.SMTP('smtp.gmail.com', 587) as server:
            server.starttls()
            server.login(GMAIL_ADDRESS, GMAIL_APP_PASSWORD)
            server.send_message(msg)
        
        log_message(f"ğŸ“§ ì´ë©”ì¼ ì•Œë¦¼ ë°œì†¡ ì™„ë£Œ: {', '.join(RECIPIENT_EMAILS)}")
        return True
        
    except Exception as e:
        log_message(f"âŒ ì´ë©”ì¼ ë°œì†¡ ì‹¤íŒ¨: {str(e)}")
        return False

def collect_bank_details():
    """ê° ì€í–‰ë³„ ìƒì„¸ ì •ë³´ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤."""
    bank_details = []
    progress_manager = ProgressManager()
    
    try:
        validation_data = progress_manager.progress.get('data_validation', [])
        validation_dict = {item['bank_name']: item for item in validation_data}
        
        for bank in BANKS:
            bank_info = {
                'name': bank,
                'status': 'failed',
                'date_info': 'ë°ì´í„° ì—†ìŒ',
                'is_fresh': False,
                'error_reason': 'ì²˜ë¦¬ë˜ì§€ ì•ŠìŒ'
            }
            
            bank_files = [f for f in os.listdir(OUTPUT_DIR) if f.startswith(f"{bank}_") and f.endswith(".xlsx")]
            
            if bank_files:
                try:
                    latest_file = sorted(bank_files)[-1]
                    file_path = os.path.join(OUTPUT_DIR, latest_file)
                    
                    if 'ê³µì‹œì •ë³´' in pd.ExcelFile(file_path).sheet_names:
                        info_df = pd.read_excel(file_path, sheet_name='ê³µì‹œì •ë³´')
                        if 'ê³µì‹œ ë‚ ì§œ' in info_df.columns and not info_df['ê³µì‹œ ë‚ ì§œ'].empty:
                            bank_info['date_info'] = str(info_df['ê³µì‹œ ë‚ ì§œ'].iloc[0])
                        if 'ë°ì´í„° ì‹ ì„ ë„' in info_df.columns and not info_df['ë°ì´í„° ì‹ ì„ ë„'].empty:
                            bank_info['is_fresh'] = str(info_df['ë°ì´í„° ì‹ ì„ ë„'].iloc[0]) == 'ìµœì‹ '
                    
                    bank_info['status'] = 'success'
                        
                except Exception as e:
                    bank_info['error_reason'] = f'íŒŒì¼ ë¶„ì„ ì˜¤ë¥˜: {str(e)}'
            else:
                if bank in validation_dict:
                    validation_info = validation_dict[bank]
                    bank_info['date_info'] = validation_info.get('date_info', 'ë‚ ì§œ ì •ë³´ ì—†ìŒ')
                    bank_info['is_fresh'] = validation_info.get('is_fresh', False)
                    bank_info['error_reason'] = 'ë°ì´í„° ì¶”ì¶œ ì™„ë£Œë˜ì—ˆìœ¼ë‚˜ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨'
                else:
                    bank_info['error_reason'] = 'ì€í–‰ í˜ì´ì§€ ì ‘ê·¼ ì‹¤íŒ¨'
            
            bank_details.append(bank_info)
        
        return bank_details
        
    except Exception as e:
        log_message(f"ì€í–‰ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}")
        return []

# =============================================================================
# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
# =============================================================================

def main():
    """ì—„ê²©í•œ ë‚ ì§œ ê²€ì¦ê³¼ ì´ë©”ì¼ í…Œì´ë¸”ì„ í¬í•¨í•œ ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    try:
        with open(LOG_FILE, 'w', encoding='utf-8') as f:
            f.write("")
    except Exception as e:
        print(f"ë¡œê·¸ íŒŒì¼ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

    start_time = time.time()
    log_message(f"\nğŸš€ ===== ì €ì¶•ì€í–‰ ìŠ¤í¬ë˜í•‘ ì‹œì‘ (ì—„ê²©í•œ ë‚ ì§œ ê²€ì¦ v2.3) [{TODAY}] =====\n")

    try:
        log_message(f"ğŸ”§ v2.3 ì—„ê²©í•œ ë‚ ì§œ ê²€ì¦ ë²„ì „:")
        log_message(f"  âœ… í—ˆìš© ë‚ ì§œ: 2024ë…„9ì›”ë§, 2025ë…„3ì›”ë§ë§Œ ì¶”ì¶œ")
        log_message(f"  âœ… ì˜ëª»ëœ ë‚ ì§œ ì™„ì „ ë°°ì œ")
        log_message(f"  âœ… ì´ë©”ì¼ì— ìŠ¤í¬ë¦°ìƒ· í˜•íƒœ í…Œì´ë¸” í¬í•¨")
        log_message(f"  âœ… ZIP íŒŒì¼ ì•ˆì •ì„± ë³´ì¥")

        # ì€í–‰ ì²˜ë¦¬ ì‹¤í–‰
        successful_banks, failed_banks, all_results = process_with_retry(BANKS, max_retries=MAX_RETRIES)

        # ê²°ê³¼ ìš”ì•½ ìƒì„±
        summary_file, stats, bank_summary = generate_summary_report()

        # ZIP íŒŒì¼ ìƒì„±
        zip_file = create_zip_archive()

        # ì‹¤í–‰ ì‹œê°„ ê³„ì‚°
        end_time = time.time()
        total_duration = end_time - start_time
        minutes, seconds = divmod(total_duration, 60)
        
        # ê²°ê³¼ ì¶œë ¥
        log_message(f"\nğŸ‰ ===== ìŠ¤í¬ë˜í•‘ ì™„ë£Œ (ì—„ê²©í•œ ë‚ ì§œ ê²€ì¦) =====")
        log_message(f"â° ì´ ì‹¤í–‰ ì‹œê°„: {int(minutes)}ë¶„ {int(seconds)}ì´ˆ")
        log_message(f"âœ… ì„±ê³µ: {len(successful_banks)}ê°œ")
        log_message(f"âŒ ì‹¤íŒ¨: {len(failed_banks)}ê°œ")
        log_message(f"ğŸ“Š ì„±ê³µë¥ : {stats.get('ì„±ê³µë¥ ', '0%')}")
        
        if failed_banks:
            log_message(f"ğŸ” ì‹¤íŒ¨ ì€í–‰: {', '.join(failed_banks[:5])}{'...' if len(failed_banks) > 5 else ''}")

        # ë‚ ì§œë³„ ë¶„ì„
        september_count = len([b for b in bank_summary if '2024ë…„9ì›”' in b['ê³µì‹œ ë‚ ì§œ']])
        march_count = len([b for b in bank_summary if '2025ë…„3ì›”' in b['ê³µì‹œ ë‚ ì§œ']])
        
        log_message(f"\nğŸ“… ë‚ ì§œ ë¶„ì„:")
        log_message(f"  â€¢ 2024ë…„9ì›”ë§ ë°ì´í„°: {september_count}ê°œ")
        log_message(f"  â€¢ 2025ë…„3ì›”ë§ ë°ì´í„°: {march_count}ê°œ")
        log_message(f"  â€¢ ê¸°íƒ€/ì˜¤ë¥˜: {len(successful_banks) - september_count - march_count}ê°œ")

        # ì´ë©”ì¼ ë°œì†¡
        if GMAIL_ADDRESS and GMAIL_APP_PASSWORD and RECIPIENT_EMAILS:
            log_message(f"\nğŸ“§ ì´ë©”ì¼ ì•Œë¦¼ ë°œì†¡ ì¤‘...")
            
            subject = f"ğŸ“Š ì €ì¶•ì€í–‰ ë°ì´í„° ìŠ¤í¬ë˜í•‘ ì™„ë£Œ (ì—„ê²©í•œ ë‚ ì§œê²€ì¦ v2.3) - {int(minutes)}ë¶„{int(seconds)}ì´ˆ"
            
            body = f"""ì €ì¶•ì€í–‰ ì¤‘ì•™íšŒ í†µì¼ê²½ì˜ê³µì‹œ ë°ì´í„° ìŠ¤í¬ë˜í•‘ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.

ğŸ”§ v2.3 ì—„ê²©í•œ ë‚ ì§œ ê²€ì¦ ë²„ì „ì˜ íŠ¹ì§•:
âœ… í—ˆìš© ë‚ ì§œ ì œí•œ: 2024ë…„9ì›”ë§, 2025ë…„3ì›”ë§ë§Œ ì¶”ì¶œ
âœ… ì˜ëª»ëœ ë‚ ì§œ ì™„ì „ ë°°ì œ: ê¸°ì¡´ ë¬¸ì œ ì™„ì „ í•´ê²°
âœ… ìŠ¤í¬ë¦°ìƒ· í˜•íƒœ í…Œì´ë¸”: ì´ë©”ì¼ ë³¸ë¬¸ì— ì§ì ‘ í¬í•¨
âœ… ZIP íŒŒì¼ ì•ˆì •ì„±: .bin ì˜¤ë¥˜ ì—†ëŠ” ì™„ì „í•œ ì••ì¶•

ğŸ“Š ì‹¤í–‰ ì •ë³´:
- ğŸ• ì‹¤í–‰ ë‚ ì§œ: {datetime.now().strftime('%Yë…„ %mì›” %dì¼ %Hì‹œ %Më¶„')}
- â±ï¸ ì´ ì‹¤í–‰ ì‹œê°„: {int(minutes)}ë¶„ {int(seconds)}ì´ˆ
- ğŸ—ï¸ ì²˜ë¦¬ í™˜ê²½: GitHub Actions (ì—„ê²©í•œ ë‚ ì§œ ê²€ì¦)

ğŸ“ˆ ê²°ê³¼ ìš”ì•½:
- ğŸ¦ ì „ì²´ ì€í–‰ ìˆ˜: {len(BANKS)}ê°œ
- âœ… ì™„ë£Œ ì€í–‰ ìˆ˜: {len(successful_banks)}ê°œ
- âŒ ì‹¤íŒ¨ ì€í–‰ ìˆ˜: {len(failed_banks)}ê°œ
- ğŸ“Š ì„±ê³µë¥ : {stats.get('ì„±ê³µë¥ ', '0%')}
- ğŸ“… 2024ë…„9ì›”ë§: {september_count}ê°œ
- ğŸ“… 2025ë…„3ì›”ë§: {march_count}ê°œ

ğŸ”§ ì£¼ìš” ê°œì„ ì‚¬í•­:
â€¢ ì—„ê²©í•œ ë‚ ì§œ í•„í„°ë§ìœ¼ë¡œ ì˜ëª»ëœ ë‚ ì§œ ì™„ì „ ë°°ì œ
â€¢ í—ˆìš©ë˜ì§€ ì•Šì€ ë‚ ì§œ ë°œê²¬ ì‹œ ì¦‰ì‹œ ì¬ê²€ìƒ‰
â€¢ ì´ë©”ì¼ ë³¸ë¬¸ì— ìŠ¤í¬ë¦°ìƒ·ê³¼ ë™ì¼í•œ í…Œì´ë¸” í¬í•¨
â€¢ ë‚ ì§œë³„ ìƒì„¸ ë¶„ì„ ë° í†µê³„ ì œê³µ

ğŸ“¦ ì²¨ë¶€ íŒŒì¼:
1. ğŸ“¦ ZIP ì••ì¶•íŒŒì¼ - ëª¨ë“  ë°ì´í„° (.zip í™•ì¥ì ë³´ì¥)
2. ğŸ“Š ì—„ê²©í•œ ê²€ì¦ ìš”ì•½ ë³´ê³ ì„œ
3. ğŸ“„ ìƒì„¸ ì‹¤í–‰ ë¡œê·¸

ì•„ë˜ì— ìŠ¤í¬ë¦°ìƒ·ê³¼ ë™ì¼í•œ í˜•íƒœì˜ ê²°ê³¼ í…Œì´ë¸”ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
"""

            # ì€í–‰ë³„ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘
            bank_details = collect_bank_details()

            # ì²¨ë¶€ íŒŒì¼ ì¤€ë¹„
            attachments = []
            if zip_file and os.path.exists(zip_file):
                attachments.append(zip_file)
            if summary_file and os.path.exists(summary_file):
                attachments.append(summary_file)
            if os.path.exists(LOG_FILE):
                attachments.append(LOG_FILE)

            # ì˜ˆìƒ ë‚ ì§œ ì •ë³´
            expected_dates = validate_data_freshness()

            # ì´ë©”ì¼ ë°œì†¡ (bank_summary í¬í•¨)
            is_success = len(failed_banks) == 0
            email_success = send_email_notification(
                subject, body, bank_details, attachments, is_success, expected_dates, bank_summary
            )
            
            if email_success:
                log_message(f"   âœ… ì´ë©”ì¼ ë°œì†¡ ì„±ê³µ (ìŠ¤í¬ë¦°ìƒ· í˜•íƒœ í…Œì´ë¸” í¬í•¨)")
            else:
                log_message(f"   âŒ ì´ë©”ì¼ ë°œì†¡ ì‹¤íŒ¨")

        log_message(f"\nğŸŠ ===== ì €ì¶•ì€í–‰ ìŠ¤í¬ë˜í•‘ ì™„ë£Œ (ì—„ê²©í•œ ë‚ ì§œ ê²€ì¦) [{TODAY}] =====")
        log_message(f"ğŸ† ì£¼ìš” ì„±ê³¼:")
        log_message(f"   â€¢ ğŸ¯ í—ˆìš©ëœ ë‚ ì§œë§Œ ì¶”ì¶œ: 2024ë…„9ì›”ë§, 2025ë…„3ì›”ë§")
        log_message(f"   â€¢ ğŸš« ì˜ëª»ëœ ë‚ ì§œ ì™„ì „ ë°°ì œ")
        log_message(f"   â€¢ ğŸ“§ ì´ë©”ì¼ì— ìŠ¤í¬ë¦°ìƒ· í˜•íƒœ í…Œì´ë¸” í¬í•¨")
        log_message(f"   â€¢ ğŸ“¦ ZIP íŒŒì¼ ì•ˆì •ì„± ë³´ì¥")

    except KeyboardInterrupt:
        log_message("\nâ¹ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        log_message(f"\nğŸ’¥ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        log_message(f"ìƒì„¸ ì˜¤ë¥˜ ì •ë³´:\n{traceback.format_exc()}")

if __name__ == "__main__":
    main()
